{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch import nn\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "height = 4\n",
    "width = 4\n",
    "depth = 24\n",
    "\n",
    "all_hists = []\n",
    "labels = []\n",
    "zero_hists = []\n",
    "\n",
    "zone_to_label = {\n",
    "    0: [0, 0, 0],\n",
    "    1: [1, 0, 0],\n",
    "    2: [0, 1, 0],\n",
    "    3: [0, 0, 1],\n",
    "    4: [1, 1, 0],\n",
    "    5: [1, 0, 1],\n",
    "    6: [0, 1, 1],\n",
    "    7: [1, 1, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(4):\n",
    "#     hists = np.load(f'datasets/display-box-3/histograms_{i}.npy')\n",
    "#     all_hists.append(hists)\n",
    "\n",
    "#     if i == 0:\n",
    "#         zero_hists.append(hists)\n",
    "\n",
    "#     labels += [zone_to_label[i]] * len(hists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    hists = np.load(f'datasets/display-box-6/histograms_{i}.npy')\n",
    "\n",
    "    hists = hists.reshape(-1, height, width, depth)\n",
    "    # move depth to the front\n",
    "    hists = np.moveaxis(hists, -1, 1)\n",
    "\n",
    "    # look at first 10 bins\n",
    "    # data = np.array(hists[:, :10, :, :])\n",
    "    # data = np.array(hists[:, :, :, :])\n",
    "    data = hists\n",
    "\n",
    "    # Compute the mean and standard deviation for each position (10, 4, 4) across all samples\n",
    "    mean = data.mean(axis=0)  # Shape: (10, 4, 4)\n",
    "    std = data.std(axis=0)    # Shape: (10, 4, 4)\n",
    "\n",
    "    # Compute the threshold for values being within 3 standard deviations\n",
    "    lower_bound = mean - 3 * std\n",
    "    upper_bound = mean + 3 * std\n",
    "\n",
    "    # Only consider the first n values along the 10-axis (shape: n x 4 x 4)\n",
    "    n = 4\n",
    "    data_to_check = data[:, :n, :, :]  # Shape: (4000, n, 4, 4)\n",
    "    lower_bound_check = lower_bound[:n, :, :]  # Shape: (n, 4, 4)\n",
    "    upper_bound_check = upper_bound[:n, :, :]  # Shape: (n, 4, 4)\n",
    "\n",
    "    # Identify samples where all values in the first 3 indices along the 10-axis are within bounds\n",
    "    valid_mask = np.all((data_to_check >= lower_bound_check) & (data_to_check <= upper_bound_check), axis=(1, 2, 3))\n",
    "\n",
    "    # Apply the mask to filter the samples\n",
    "    filtered_data = data[valid_mask]\n",
    "\n",
    "    hists = filtered_data\n",
    "    \n",
    "    all_hists.append(hists)\n",
    "\n",
    "    if i == 0:\n",
    "        zero_hists.append(hists)\n",
    "\n",
    "    labels += [zone_to_label[i]] * len(hists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_hists = np.concatenate(zero_hists, axis=0)\n",
    "all_hists = np.concatenate(all_hists, axis=0)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# all_hists = all_hists.reshape(-1, height, width, depth)\n",
    "# # move depth to the front\n",
    "# all_hists = np.moveaxis(all_hists, -1, 1)\n",
    "\n",
    "# zero_hists = zero_hists.reshape(-1, height, width, depth)\n",
    "# zero_hists = np.moveaxis(zero_hists, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute the mean and standard deviation for each position (24, 4, 4) across all samples\n",
    "# mean = all_hists.mean(axis=0)  # Shape: (24, 4, 4)\n",
    "# std = all_hists.std(axis=0)    # Shape: (24, 4, 4)\n",
    "\n",
    "# # Compute the threshold for values being within 3 standard deviations\n",
    "# lower_bound = mean - 3 * std\n",
    "# upper_bound = mean + 3 * std\n",
    "\n",
    "# # Only consider the first n values along the depth axis (shape: n x 4 x 4)\n",
    "# n = 4\n",
    "# data_to_check = all_hists[:, :n, :, :]  # Shape: (4000, n, 4, 4)\n",
    "# lower_bound_check = lower_bound[:n, :, :]  # Shape: (n, 4, 4)\n",
    "# upper_bound_check = upper_bound[:n, :, :]  # Shape: (n, 4, 4)\n",
    "\n",
    "# # Identify samples where all values in the first 3 indices along the depth axis are within bounds\n",
    "# valid_mask = np.all((data_to_check >= lower_bound_check) & (data_to_check <= upper_bound_check), axis=(1, 2, 3))\n",
    "\n",
    "# # Apply the mask to filter the samples\n",
    "# filtered_all_hists = all_hists[valid_mask]\n",
    "# filtered_labels = labels[valid_mask]\n",
    "\n",
    "# # Check the shapes of the original and filtered arrays\n",
    "# print(f\"Original shape: {all_hists.shape}\")\n",
    "# print(f\"Filtered shape: {filtered_all_hists.shape}\")\n",
    "# all_hists = filtered_all_hists\n",
    "# labels = filtered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_bin = 4\n",
    "end_bin = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop first bounce bins (first bounce in first 2 bins)\n",
    "# crop bins that are too far and noisy\n",
    "all_hists = all_hists[:, start_bin:end_bin, :, :]\n",
    "zero_hists = zero_hists[:, start_bin:end_bin, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate more data by adding gaussian noise\n",
    "\n",
    "all_hists = np.repeat(all_hists, 5, axis=0)\n",
    "labels = np.repeat(labels, 5, axis=0)\n",
    "\n",
    "# add noise\n",
    "# std = 3 is good for general training?\n",
    "# all_hists += np.random.normal(0, 1, all_hists.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hists = torch.tensor(all_hists, dtype=torch.float32)\n",
    "zero_hists = torch.tensor(zero_hists, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick 20 random zero hists to act as the zero mean\n",
    "num_samples_to_mean = 20\n",
    "\n",
    "random_zero_mean = torch.empty((all_hists.shape[0], all_hists.shape[1], height, width))\n",
    "\n",
    "for i in range(all_hists.shape[0]):\n",
    "    indices = torch.randint(0, zero_hists.shape[0], (num_samples_to_mean,))\n",
    "    random_zero_mean[i] = zero_hists[indices].mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normalize to 0-1 values\n",
    "# all_hist_mins = all_hists.amin(dim=(1, 2, 3), keepdim=True)\n",
    "# all_hist_maxs = all_hists.amax(dim=(1, 2, 3), keepdim=True)\n",
    "# all_hist_ranges = all_hist_maxs - all_hist_mins\n",
    "# all_hist_ranges[all_hist_ranges == 0] = 1\n",
    "# all_hists = (all_hists - all_hist_mins) / all_hist_ranges\n",
    "\n",
    "# # normalize to 0-1 values\n",
    "# random_zero_mean_mins = random_zero_mean.amin(dim=(1, 2, 3), keepdim=True)\n",
    "# random_zero_mean_maxs = random_zero_mean.amax(dim=(1, 2, 3), keepdim=True)\n",
    "# random_zero_mean_ranges = random_zero_mean_maxs - random_zero_mean_mins\n",
    "# random_zero_mean_ranges[random_zero_mean_ranges == 0] = 1\n",
    "# random_zero_mean = (random_zero_mean - random_zero_mean_mins) / random_zero_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hists_rel = all_hists - random_zero_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean all pixels\n",
    "# all_hists_rel = all_hists_rel.mean(dim=(2, 3), keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero_mean = np.mean(zero_hists, axis=0)\n",
    "\n",
    "# # lower bound at 0\n",
    "# # all_hists = np.maximum(all_hists, 0)\n",
    "# # zero_mean = np.maximum(zero_mean, 0)\n",
    "# all_hists_rel = all_hists - zero_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of all_hists: torch.Size([18735, 12, 4, 4])\n",
      "shape of labels: (18735, 3)\n",
      "shape of all_hists_rel: torch.Size([18735, 12, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# chunk sizes\n",
    "print(f'shape of all_hists: {all_hists.shape}')\n",
    "print(f'shape of labels: {labels.shape}')\n",
    "print(f'shape of all_hists_rel: {all_hists_rel.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_all_hists_rel = np.empty((0, end_bin - start_bin, height, width))\n",
    "combined_labels = np.empty((0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_all_hists_rel = np.concatenate([combined_all_hists_rel, all_hists_rel], axis=0)\n",
    "combined_labels = np.concatenate([combined_labels, labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of all_hists_rel: (18735, 12, 4, 4)\n",
      "shape of labels: (18735, 3)\n"
     ]
    }
   ],
   "source": [
    "# final dataset sizes\n",
    "print(f'shape of all_hists_rel: {combined_all_hists_rel.shape}')\n",
    "print(f'shape of labels: {combined_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to PyTorch tensors\n",
    "# all_hists_tensor = torch.tensor(all_hists, dtype=torch.float32)\n",
    "# all_hists_tensor = torch.tensor(all_hists_rel, dtype=torch.float32)\n",
    "all_hists_tensor = torch.tensor(combined_all_hists_rel, dtype=torch.float32)\n",
    "# labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "labels_tensor = torch.tensor(combined_labels, dtype=torch.float32)\n",
    "\n",
    "# all_hists_tensor = torch.sign(all_hists_tensor) * torch.log1p(torch.abs(all_hists_tensor))\n",
    "\n",
    "\n",
    "# epsilon = 0.1  # Smoothing factor\n",
    "# labels_tensor = (1 - epsilon) * labels_tensor + epsilon * 0.5  # Smooth towards uniform distribution\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(all_hists_tensor, labels_tensor)\n",
    "\n",
    "# Define the sizes for training, validation, and test sets\n",
    "train_size = int(0.5 * len(dataset))\n",
    "val_size = int(0.25 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create DataLoaders for each set\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_x shape: torch.Size([32, 12, 4, 4])\n",
      "batch_y shape: torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "for batch_x, batch_y in train_loader:\n",
    "    print(f'batch_x shape: {batch_x.shape}')\n",
    "    print(f'batch_y shape: {batch_y.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CounterCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CounterCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels=(end_bin - start_bin), out_channels=16, kernel_size=3, padding=1)\n",
    "#         self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=1)\n",
    "#         self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "#         # self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "#         self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
    "#         self.fc1_bn = nn.BatchNorm1d(128)\n",
    "#         self.fc2 = nn.Linear(128, 3)  # Assuming 10 classes for the labels\n",
    "#         self.relu = nn.LeakyReLU(negative_slope=0.01)\n",
    "#         self.dropout = nn.Dropout(p=0.7)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # print(f'x shape at start: {x.shape}')\n",
    "#         x = self.relu(self.conv1(x))\n",
    "#         # print(f'x shape after conv1: {x.shape}')\n",
    "#         x = self.batchnorm1(x)\n",
    "#         # x = self.pool(x)\n",
    "#         # print(f'x shape after pool1: {x.shape}')\n",
    "#         x = self.relu(self.conv2(x))\n",
    "#         # print(f'x shape after conv2: {x.shape}')\n",
    "#         x = self.batchnorm2(x)\n",
    "#         # x = self.pool(x)\n",
    "#         # print(f'x shape after pool2: {x.shape}')\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         # print(f'x shape after flatten: {x.shape}')\n",
    "#         x = self.relu(self.fc1(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.fc1_bn(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# # Instantiate the model\n",
    "# model = CounterCNN().to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CounterCNN(\n",
      "  (conv3d): Conv3d(1, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (batchnorm3d): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
      "  (fc1_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
      "  (relu): LeakyReLU(negative_slope=0.01)\n",
      "  (dropout): Dropout(p=0.7, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CounterCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CounterCNN, self).__init__()\n",
    "        # self.conv1 = nn.Conv2d(in_channels=(end_bin - start_bin), out_channels=16, kernel_size=3, padding=1)\n",
    "        # self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        # self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=1)\n",
    "        # self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        out_channels = 4\n",
    "        self.conv3d = nn.Conv3d(in_channels=1, out_channels=out_channels, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.batchnorm3d = nn.BatchNorm3d(out_channels)\n",
    "\n",
    "        self.fc1 = nn.Linear(out_channels * (end_bin - start_bin) * height * width, 128)\n",
    "\n",
    "        # self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
    "        self.fc1_bn = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 3)  # Assuming 10 classes for the labels\n",
    "        self.relu = nn.LeakyReLU(negative_slope=0.01)\n",
    "        self.dropout = nn.Dropout(p=0.7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # # print(f'x shape at start: {x.shape}')\n",
    "        # x = self.relu(self.conv1(x))\n",
    "        # # print(f'x shape after conv1: {x.shape}')\n",
    "        # x = self.batchnorm1(x)\n",
    "        # # x = self.pool(x)\n",
    "        # # print(f'x shape after pool1: {x.shape}')\n",
    "        # x = self.relu(self.conv2(x))\n",
    "        # # print(f'x shape after conv2: {x.shape}')\n",
    "        # x = self.batchnorm2(x)\n",
    "\n",
    "        x = self.relu(self.conv3d(x.unsqueeze(1)))\n",
    "        x = self.batchnorm3d(x)\n",
    "\n",
    "        # x = self.pool(x)\n",
    "        # print(f'x shape after pool2: {x.shape}')\n",
    "        x = torch.flatten(x, 1)\n",
    "        # print(f'x shape after flatten: {x.shape}')\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1_bn(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = CounterCNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CounterCNN(\n",
       "  (conv3d): Conv3d(1, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (batchnorm3d): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (fc1_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
       "  (relu): LeakyReLU(negative_slope=0.01)\n",
       "  (dropout): Dropout(p=0.7, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, torch.nn.Linear) or isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='leaky_relu')\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(), lr=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, counter=False, clipping=False, debug=False):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        if len(X) < batch_size:\n",
    "            continue\n",
    "\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # print(f'X shape: {X.shape}, y shape: {y.shape}')\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        # if counter:\n",
    "            # y = y.unsqueeze(1)\n",
    "        # print(f'pred shape: {pred.shape}, y shape: {y.shape}')\n",
    "        loss = loss_fn(pred, y)\n",
    "        # print(f'loss: {loss.item()}')\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        if clipping:\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Adjust max_norm as needed\n",
    "        \n",
    "        if debug:\n",
    "            # Inspect gradients for each layer\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None:  # Only check if gradient is computed\n",
    "                    print(f\"Layer: {name} | Gradient mean: {param.grad.abs().mean().item()} | Gradient max: {param.grad.abs().max().item()}\")\n",
    "                else:\n",
    "                    print(f\"Layer: {name} has no gradient.\")\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    train_loss /= len(dataloader)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_counter(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            # y = y.unsqueeze_(1)\n",
    "            # print(X.shape)\n",
    "            # print(y.shape)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            final_pred = torch.round(torch.clamp(pred, min=0, max=1))\n",
    "            \n",
    "            # print(final_pred.shape)\n",
    "            # print(\"true\")\n",
    "            # print(y)\n",
    "            # print(\"pred\")\n",
    "            # print(final_pred)\n",
    "            # print(\"diff\")\n",
    "            # print(final_pred - y)\n",
    "            exact_match = torch.all(final_pred == torch.round(y), dim=1)\n",
    "            correct += torch.sum(exact_match).item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_early_stopping(train_loader, val_loader, model, loss_fn, optimizer, \n",
    "    epochs=50, early_stopping=True, patience=5, threshold=0.15, counter=False, clipping=False, debug=False):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loss = train(train_loader, model, loss_fn, optimizer, counter=counter, clipping=clipping, debug=debug)\n",
    "        if counter:\n",
    "            val_loss, correct = test_counter(val_loader, model, loss_fn)\n",
    "        else:\n",
    "            val_loss, correct = test(val_loader, model, loss_fn)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        if early_stopping:\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = model\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                if val_loss / best_val_loss > 1 + threshold:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= patience:\n",
    "                        print(f\"Early stopping at epoch {t+1}\")\n",
    "                        break\n",
    "        # print(f'patience_counter: {patience_counter}')\n",
    "    return best_model, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.883606  [   32/ 9367]\n",
      "loss: 0.478949  [ 3232/ 9367]\n",
      "loss: 0.672768  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 31.8%, Avg loss: 0.491482 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.491540  [   32/ 9367]\n",
      "loss: 0.484997  [ 3232/ 9367]\n",
      "loss: 0.493866  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 32.7%, Avg loss: 0.481170 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.506458  [   32/ 9367]\n",
      "loss: 0.472307  [ 3232/ 9367]\n",
      "loss: 0.479006  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 33.2%, Avg loss: 0.463405 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.483712  [   32/ 9367]\n",
      "loss: 0.377769  [ 3232/ 9367]\n",
      "loss: 0.543679  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 31.7%, Avg loss: 0.447101 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.442946  [   32/ 9367]\n",
      "loss: 0.507126  [ 3232/ 9367]\n",
      "loss: 0.471025  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 32.3%, Avg loss: 0.441233 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.460458  [   32/ 9367]\n",
      "loss: 0.477376  [ 3232/ 9367]\n",
      "loss: 0.430513  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 32.5%, Avg loss: 0.441026 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.458158  [   32/ 9367]\n",
      "loss: 0.407822  [ 3232/ 9367]\n",
      "loss: 0.384881  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 33.5%, Avg loss: 0.433770 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.533036  [   32/ 9367]\n",
      "loss: 0.505282  [ 3232/ 9367]\n",
      "loss: 0.426440  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 32.6%, Avg loss: 0.439155 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.440447  [   32/ 9367]\n",
      "loss: 0.402479  [ 3232/ 9367]\n",
      "loss: 0.458250  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 34.8%, Avg loss: 0.425296 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.494535  [   32/ 9367]\n",
      "loss: 0.470145  [ 3232/ 9367]\n",
      "loss: 0.472409  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 36.0%, Avg loss: 0.415887 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.398123  [   32/ 9367]\n",
      "loss: 0.341824  [ 3232/ 9367]\n",
      "loss: 0.530194  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 39.4%, Avg loss: 0.420546 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.332774  [   32/ 9367]\n",
      "loss: 0.380248  [ 3232/ 9367]\n",
      "loss: 0.475327  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 38.6%, Avg loss: 0.409000 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.356179  [   32/ 9367]\n",
      "loss: 0.408974  [ 3232/ 9367]\n",
      "loss: 0.430191  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 36.5%, Avg loss: 0.409371 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.425496  [   32/ 9367]\n",
      "loss: 0.396302  [ 3232/ 9367]\n",
      "loss: 0.415860  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 39.8%, Avg loss: 0.404513 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.372844  [   32/ 9367]\n",
      "loss: 0.405435  [ 3232/ 9367]\n",
      "loss: 0.466635  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 37.2%, Avg loss: 0.409838 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.407674  [   32/ 9367]\n",
      "loss: 0.361123  [ 3232/ 9367]\n",
      "loss: 0.412868  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 39.6%, Avg loss: 0.393228 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.350537  [   32/ 9367]\n",
      "loss: 0.413911  [ 3232/ 9367]\n",
      "loss: 0.440872  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 37.2%, Avg loss: 0.402123 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.380944  [   32/ 9367]\n",
      "loss: 0.376616  [ 3232/ 9367]\n",
      "loss: 0.571887  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 39.3%, Avg loss: 0.390801 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.443971  [   32/ 9367]\n",
      "loss: 0.325695  [ 3232/ 9367]\n",
      "loss: 0.436164  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 37.1%, Avg loss: 0.394265 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.382995  [   32/ 9367]\n",
      "loss: 0.363554  [ 3232/ 9367]\n",
      "loss: 0.411555  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 39.7%, Avg loss: 0.384866 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.363736  [   32/ 9367]\n",
      "loss: 0.407562  [ 3232/ 9367]\n",
      "loss: 0.452799  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 41.9%, Avg loss: 0.381293 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.389259  [   32/ 9367]\n",
      "loss: 0.400767  [ 3232/ 9367]\n",
      "loss: 0.372924  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 41.5%, Avg loss: 0.376350 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.397953  [   32/ 9367]\n",
      "loss: 0.319383  [ 3232/ 9367]\n",
      "loss: 0.453909  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 43.1%, Avg loss: 0.375158 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.337242  [   32/ 9367]\n",
      "loss: 0.515400  [ 3232/ 9367]\n",
      "loss: 0.451917  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 41.0%, Avg loss: 0.372093 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.350059  [   32/ 9367]\n",
      "loss: 0.440389  [ 3232/ 9367]\n",
      "loss: 0.444384  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 43.1%, Avg loss: 0.371268 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.403515  [   32/ 9367]\n",
      "loss: 0.369975  [ 3232/ 9367]\n",
      "loss: 0.334453  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 42.9%, Avg loss: 0.366298 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.433572  [   32/ 9367]\n",
      "loss: 0.354944  [ 3232/ 9367]\n",
      "loss: 0.377380  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 41.3%, Avg loss: 0.375797 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.374488  [   32/ 9367]\n",
      "loss: 0.414139  [ 3232/ 9367]\n",
      "loss: 0.436191  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.363379 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.325604  [   32/ 9367]\n",
      "loss: 0.387123  [ 3232/ 9367]\n",
      "loss: 0.337081  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.358152 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.372102  [   32/ 9367]\n",
      "loss: 0.344061  [ 3232/ 9367]\n",
      "loss: 0.319214  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 0.358091 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.368169  [   32/ 9367]\n",
      "loss: 0.305333  [ 3232/ 9367]\n",
      "loss: 0.424170  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 44.7%, Avg loss: 0.365878 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.388579  [   32/ 9367]\n",
      "loss: 0.395305  [ 3232/ 9367]\n",
      "loss: 0.412891  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 42.2%, Avg loss: 0.362332 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.323643  [   32/ 9367]\n",
      "loss: 0.480369  [ 3232/ 9367]\n",
      "loss: 0.491845  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 46.1%, Avg loss: 0.353014 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.334038  [   32/ 9367]\n",
      "loss: 0.442711  [ 3232/ 9367]\n",
      "loss: 0.481170  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 45.2%, Avg loss: 0.349313 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.419616  [   32/ 9367]\n",
      "loss: 0.441748  [ 3232/ 9367]\n",
      "loss: 0.454455  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 43.9%, Avg loss: 0.350943 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.354563  [   32/ 9367]\n",
      "loss: 0.400699  [ 3232/ 9367]\n",
      "loss: 0.393464  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 0.347259 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.377877  [   32/ 9367]\n",
      "loss: 0.289217  [ 3232/ 9367]\n",
      "loss: 0.432431  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 48.2%, Avg loss: 0.353058 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.436108  [   32/ 9367]\n",
      "loss: 0.325031  [ 3232/ 9367]\n",
      "loss: 0.342467  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 45.6%, Avg loss: 0.342115 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.393700  [   32/ 9367]\n",
      "loss: 0.406662  [ 3232/ 9367]\n",
      "loss: 0.436423  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 0.340884 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.356768  [   32/ 9367]\n",
      "loss: 0.345169  [ 3232/ 9367]\n",
      "loss: 0.279073  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 47.4%, Avg loss: 0.337865 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.460638  [   32/ 9367]\n",
      "loss: 0.495310  [ 3232/ 9367]\n",
      "loss: 0.321092  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 0.337732 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.370374  [   32/ 9367]\n",
      "loss: 0.416083  [ 3232/ 9367]\n",
      "loss: 0.460234  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 49.3%, Avg loss: 0.328643 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.415827  [   32/ 9367]\n",
      "loss: 0.396597  [ 3232/ 9367]\n",
      "loss: 0.402225  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 48.3%, Avg loss: 0.329716 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.330451  [   32/ 9367]\n",
      "loss: 0.400068  [ 3232/ 9367]\n",
      "loss: 0.380570  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 49.6%, Avg loss: 0.335365 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.322932  [   32/ 9367]\n",
      "loss: 0.306927  [ 3232/ 9367]\n",
      "loss: 0.296396  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 0.328939 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.443831  [   32/ 9367]\n",
      "loss: 0.392192  [ 3232/ 9367]\n",
      "loss: 0.343101  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.324175 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.316314  [   32/ 9367]\n",
      "loss: 0.245600  [ 3232/ 9367]\n",
      "loss: 0.404068  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.317558 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.337870  [   32/ 9367]\n",
      "loss: 0.297542  [ 3232/ 9367]\n",
      "loss: 0.291966  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 48.4%, Avg loss: 0.324080 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.358637  [   32/ 9367]\n",
      "loss: 0.335192  [ 3232/ 9367]\n",
      "loss: 0.406417  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 0.325079 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.329195  [   32/ 9367]\n",
      "loss: 0.273508  [ 3232/ 9367]\n",
      "loss: 0.319342  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 50.9%, Avg loss: 0.331232 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.299492  [   32/ 9367]\n",
      "loss: 0.343696  [ 3232/ 9367]\n",
      "loss: 0.347596  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.316109 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.218200  [   32/ 9367]\n",
      "loss: 0.351598  [ 3232/ 9367]\n",
      "loss: 0.408589  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 0.311997 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.390362  [   32/ 9367]\n",
      "loss: 0.273180  [ 3232/ 9367]\n",
      "loss: 0.314019  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 0.316453 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.386840  [   32/ 9367]\n",
      "loss: 0.264692  [ 3232/ 9367]\n",
      "loss: 0.379794  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 49.6%, Avg loss: 0.318907 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.421615  [   32/ 9367]\n",
      "loss: 0.378067  [ 3232/ 9367]\n",
      "loss: 0.313287  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.308678 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.365021  [   32/ 9367]\n",
      "loss: 0.332849  [ 3232/ 9367]\n",
      "loss: 0.321692  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 49.9%, Avg loss: 0.313721 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.253691  [   32/ 9367]\n",
      "loss: 0.438990  [ 3232/ 9367]\n",
      "loss: 0.334407  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 0.304167 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.235786  [   32/ 9367]\n",
      "loss: 0.272496  [ 3232/ 9367]\n",
      "loss: 0.389555  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 51.1%, Avg loss: 0.311057 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.265668  [   32/ 9367]\n",
      "loss: 0.319107  [ 3232/ 9367]\n",
      "loss: 0.285533  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 0.299261 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.216838  [   32/ 9367]\n",
      "loss: 0.359282  [ 3232/ 9367]\n",
      "loss: 0.309576  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 51.6%, Avg loss: 0.309842 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.303387  [   32/ 9367]\n",
      "loss: 0.256161  [ 3232/ 9367]\n",
      "loss: 0.375476  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 0.302717 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.305115  [   32/ 9367]\n",
      "loss: 0.256535  [ 3232/ 9367]\n",
      "loss: 0.285621  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.296115 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.406676  [   32/ 9367]\n",
      "loss: 0.358511  [ 3232/ 9367]\n",
      "loss: 0.336461  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Avg loss: 0.296102 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.389780  [   32/ 9367]\n",
      "loss: 0.340276  [ 3232/ 9367]\n",
      "loss: 0.324491  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 53.2%, Avg loss: 0.296424 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.228342  [   32/ 9367]\n",
      "loss: 0.405636  [ 3232/ 9367]\n",
      "loss: 0.287129  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 0.290721 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.265319  [   32/ 9367]\n",
      "loss: 0.272399  [ 3232/ 9367]\n",
      "loss: 0.303466  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.296207 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.267367  [   32/ 9367]\n",
      "loss: 0.307104  [ 3232/ 9367]\n",
      "loss: 0.357150  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 0.292170 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.283530  [   32/ 9367]\n",
      "loss: 0.299751  [ 3232/ 9367]\n",
      "loss: 0.312621  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 0.290263 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.314700  [   32/ 9367]\n",
      "loss: 0.335134  [ 3232/ 9367]\n",
      "loss: 0.343501  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.286444 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.267092  [   32/ 9367]\n",
      "loss: 0.399574  [ 3232/ 9367]\n",
      "loss: 0.337996  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.291822 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.367721  [   32/ 9367]\n",
      "loss: 0.246941  [ 3232/ 9367]\n",
      "loss: 0.253187  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 0.283746 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.267325  [   32/ 9367]\n",
      "loss: 0.311632  [ 3232/ 9367]\n",
      "loss: 0.401375  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 0.286155 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.288681  [   32/ 9367]\n",
      "loss: 0.238709  [ 3232/ 9367]\n",
      "loss: 0.349450  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 58.9%, Avg loss: 0.282563 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.427675  [   32/ 9367]\n",
      "loss: 0.348718  [ 3232/ 9367]\n",
      "loss: 0.320432  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 0.289429 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.296838  [   32/ 9367]\n",
      "loss: 0.477429  [ 3232/ 9367]\n",
      "loss: 0.257175  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 0.278210 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.297392  [   32/ 9367]\n",
      "loss: 0.271542  [ 3232/ 9367]\n",
      "loss: 0.399472  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.274480 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.333251  [   32/ 9367]\n",
      "loss: 0.379163  [ 3232/ 9367]\n",
      "loss: 0.305636  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.278110 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.277565  [   32/ 9367]\n",
      "loss: 0.215183  [ 3232/ 9367]\n",
      "loss: 0.273207  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.282114 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.264863  [   32/ 9367]\n",
      "loss: 0.369400  [ 3232/ 9367]\n",
      "loss: 0.302941  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.280273 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.262728  [   32/ 9367]\n",
      "loss: 0.250985  [ 3232/ 9367]\n",
      "loss: 0.278028  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 0.272862 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.247519  [   32/ 9367]\n",
      "loss: 0.417783  [ 3232/ 9367]\n",
      "loss: 0.275037  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.272096 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.312939  [   32/ 9367]\n",
      "loss: 0.338017  [ 3232/ 9367]\n",
      "loss: 0.276785  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.274512 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.316384  [   32/ 9367]\n",
      "loss: 0.237492  [ 3232/ 9367]\n",
      "loss: 0.278619  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 57.8%, Avg loss: 0.273841 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.218321  [   32/ 9367]\n",
      "loss: 0.328468  [ 3232/ 9367]\n",
      "loss: 0.255669  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.272936 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.389643  [   32/ 9367]\n",
      "loss: 0.428540  [ 3232/ 9367]\n",
      "loss: 0.282318  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 0.268987 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.247311  [   32/ 9367]\n",
      "loss: 0.277205  [ 3232/ 9367]\n",
      "loss: 0.400335  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 60.1%, Avg loss: 0.265868 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.336860  [   32/ 9367]\n",
      "loss: 0.248642  [ 3232/ 9367]\n",
      "loss: 0.322924  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 0.268229 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.292020  [   32/ 9367]\n",
      "loss: 0.256895  [ 3232/ 9367]\n",
      "loss: 0.262388  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 60.7%, Avg loss: 0.263245 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.315774  [   32/ 9367]\n",
      "loss: 0.238180  [ 3232/ 9367]\n",
      "loss: 0.192344  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 60.1%, Avg loss: 0.265720 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.218098  [   32/ 9367]\n",
      "loss: 0.296218  [ 3232/ 9367]\n",
      "loss: 0.402594  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Avg loss: 0.266636 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.374906  [   32/ 9367]\n",
      "loss: 0.372828  [ 3232/ 9367]\n",
      "loss: 0.388503  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 0.275636 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.314829  [   32/ 9367]\n",
      "loss: 0.389912  [ 3232/ 9367]\n",
      "loss: 0.224380  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.259528 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.348775  [   32/ 9367]\n",
      "loss: 0.264842  [ 3232/ 9367]\n",
      "loss: 0.267200  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.267157 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.374164  [   32/ 9367]\n",
      "loss: 0.317911  [ 3232/ 9367]\n",
      "loss: 0.365221  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.264142 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.384196  [   32/ 9367]\n",
      "loss: 0.274748  [ 3232/ 9367]\n",
      "loss: 0.462301  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.254290 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.265636  [   32/ 9367]\n",
      "loss: 0.370496  [ 3232/ 9367]\n",
      "loss: 0.232271  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 0.254149 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.278354  [   32/ 9367]\n",
      "loss: 0.281631  [ 3232/ 9367]\n",
      "loss: 0.238320  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 0.259080 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.281509  [   32/ 9367]\n",
      "loss: 0.241271  [ 3232/ 9367]\n",
      "loss: 0.235859  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.260457 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.212622  [   32/ 9367]\n",
      "loss: 0.251309  [ 3232/ 9367]\n",
      "loss: 0.312394  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.260794 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.242647  [   32/ 9367]\n",
      "loss: 0.225944  [ 3232/ 9367]\n",
      "loss: 0.268282  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 64.3%, Avg loss: 0.250296 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.378625  [   32/ 9367]\n",
      "loss: 0.400223  [ 3232/ 9367]\n",
      "loss: 0.257970  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 0.263090 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.421725  [   32/ 9367]\n",
      "loss: 0.316420  [ 3232/ 9367]\n",
      "loss: 0.231023  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 0.243947 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.379909  [   32/ 9367]\n",
      "loss: 0.417821  [ 3232/ 9367]\n",
      "loss: 0.261811  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 66.6%, Avg loss: 0.240662 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.209487  [   32/ 9367]\n",
      "loss: 0.321344  [ 3232/ 9367]\n",
      "loss: 0.266599  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.252695 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.293862  [   32/ 9367]\n",
      "loss: 0.276269  [ 3232/ 9367]\n",
      "loss: 0.350259  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 0.250925 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.184728  [   32/ 9367]\n",
      "loss: 0.334838  [ 3232/ 9367]\n",
      "loss: 0.301192  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 0.247329 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.284648  [   32/ 9367]\n",
      "loss: 0.420600  [ 3232/ 9367]\n",
      "loss: 0.268969  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.269864 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.261323  [   32/ 9367]\n",
      "loss: 0.345446  [ 3232/ 9367]\n",
      "loss: 0.287308  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 62.2%, Avg loss: 0.250006 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.248751  [   32/ 9367]\n",
      "loss: 0.435404  [ 3232/ 9367]\n",
      "loss: 0.344252  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 0.250212 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.234347  [   32/ 9367]\n",
      "loss: 0.191131  [ 3232/ 9367]\n",
      "loss: 0.406658  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.253164 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.242312  [   32/ 9367]\n",
      "loss: 0.208031  [ 3232/ 9367]\n",
      "loss: 0.358217  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.242246 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.268064  [   32/ 9367]\n",
      "loss: 0.266164  [ 3232/ 9367]\n",
      "loss: 0.298413  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 0.242101 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.274883  [   32/ 9367]\n",
      "loss: 0.370552  [ 3232/ 9367]\n",
      "loss: 0.381361  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 0.240720 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.306792  [   32/ 9367]\n",
      "loss: 0.160149  [ 3232/ 9367]\n",
      "loss: 0.332929  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 0.243487 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.242183  [   32/ 9367]\n",
      "loss: 0.258381  [ 3232/ 9367]\n",
      "loss: 0.308895  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.249853 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.270172  [   32/ 9367]\n",
      "loss: 0.248895  [ 3232/ 9367]\n",
      "loss: 0.355615  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.242810 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.249410  [   32/ 9367]\n",
      "loss: 0.365278  [ 3232/ 9367]\n",
      "loss: 0.416915  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.238117 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.241292  [   32/ 9367]\n",
      "loss: 0.373790  [ 3232/ 9367]\n",
      "loss: 0.330841  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 0.247754 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.368735  [   32/ 9367]\n",
      "loss: 0.322132  [ 3232/ 9367]\n",
      "loss: 0.245303  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 0.241433 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.175219  [   32/ 9367]\n",
      "loss: 0.201685  [ 3232/ 9367]\n",
      "loss: 0.198906  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 0.238529 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.307600  [   32/ 9367]\n",
      "loss: 0.253328  [ 3232/ 9367]\n",
      "loss: 0.407586  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.243691 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.284423  [   32/ 9367]\n",
      "loss: 0.246659  [ 3232/ 9367]\n",
      "loss: 0.319225  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 66.2%, Avg loss: 0.240779 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.289058  [   32/ 9367]\n",
      "loss: 0.296544  [ 3232/ 9367]\n",
      "loss: 0.317228  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 64.7%, Avg loss: 0.240842 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.258547  [   32/ 9367]\n",
      "loss: 0.232800  [ 3232/ 9367]\n",
      "loss: 0.327901  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 0.240395 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.277322  [   32/ 9367]\n",
      "loss: 0.230506  [ 3232/ 9367]\n",
      "loss: 0.297045  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.241858 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.353391  [   32/ 9367]\n",
      "loss: 0.263560  [ 3232/ 9367]\n",
      "loss: 0.303470  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 0.224965 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.166489  [   32/ 9367]\n",
      "loss: 0.182542  [ 3232/ 9367]\n",
      "loss: 0.212007  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.233434 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.274133  [   32/ 9367]\n",
      "loss: 0.232816  [ 3232/ 9367]\n",
      "loss: 0.227495  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 0.241004 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.209220  [   32/ 9367]\n",
      "loss: 0.192534  [ 3232/ 9367]\n",
      "loss: 0.295802  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.228907 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.316939  [   32/ 9367]\n",
      "loss: 0.273424  [ 3232/ 9367]\n",
      "loss: 0.366801  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 0.227148 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.327844  [   32/ 9367]\n",
      "loss: 0.235968  [ 3232/ 9367]\n",
      "loss: 0.364594  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.230282 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.295471  [   32/ 9367]\n",
      "loss: 0.225270  [ 3232/ 9367]\n",
      "loss: 0.275144  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 66.6%, Avg loss: 0.236370 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.237008  [   32/ 9367]\n",
      "loss: 0.228510  [ 3232/ 9367]\n",
      "loss: 0.236533  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 0.236391 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.211304  [   32/ 9367]\n",
      "loss: 0.271218  [ 3232/ 9367]\n",
      "loss: 0.305370  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.236401 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.332408  [   32/ 9367]\n",
      "loss: 0.218518  [ 3232/ 9367]\n",
      "loss: 0.273872  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.229013 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.260251  [   32/ 9367]\n",
      "loss: 0.294610  [ 3232/ 9367]\n",
      "loss: 0.299168  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.231597 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.230828  [   32/ 9367]\n",
      "loss: 0.190119  [ 3232/ 9367]\n",
      "loss: 0.215188  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 67.5%, Avg loss: 0.227356 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.346597  [   32/ 9367]\n",
      "loss: 0.414563  [ 3232/ 9367]\n",
      "loss: 0.231093  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 66.2%, Avg loss: 0.235299 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.260205  [   32/ 9367]\n",
      "loss: 0.194991  [ 3232/ 9367]\n",
      "loss: 0.280161  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.226200 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.219571  [   32/ 9367]\n",
      "loss: 0.334456  [ 3232/ 9367]\n",
      "loss: 0.285078  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 0.226765 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.223844  [   32/ 9367]\n",
      "loss: 0.258746  [ 3232/ 9367]\n",
      "loss: 0.196132  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 0.228018 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.231115  [   32/ 9367]\n",
      "loss: 0.389157  [ 3232/ 9367]\n",
      "loss: 0.321450  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.227233 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.217223  [   32/ 9367]\n",
      "loss: 0.290729  [ 3232/ 9367]\n",
      "loss: 0.318784  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 0.221622 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.252421  [   32/ 9367]\n",
      "loss: 0.247883  [ 3232/ 9367]\n",
      "loss: 0.266751  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.233294 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.257059  [   32/ 9367]\n",
      "loss: 0.205534  [ 3232/ 9367]\n",
      "loss: 0.223273  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 0.223058 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.248161  [   32/ 9367]\n",
      "loss: 0.353163  [ 3232/ 9367]\n",
      "loss: 0.360638  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.231691 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.278911  [   32/ 9367]\n",
      "loss: 0.314985  [ 3232/ 9367]\n",
      "loss: 0.373831  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.217593 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.178086  [   32/ 9367]\n",
      "loss: 0.233891  [ 3232/ 9367]\n",
      "loss: 0.203719  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.218659 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.221401  [   32/ 9367]\n",
      "loss: 0.327601  [ 3232/ 9367]\n",
      "loss: 0.263128  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.224838 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.154572  [   32/ 9367]\n",
      "loss: 0.244577  [ 3232/ 9367]\n",
      "loss: 0.202592  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 0.239216 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.307788  [   32/ 9367]\n",
      "loss: 0.414038  [ 3232/ 9367]\n",
      "loss: 0.252529  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.214302 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.340638  [   32/ 9367]\n",
      "loss: 0.299902  [ 3232/ 9367]\n",
      "loss: 0.142433  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 0.228935 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.336543  [   32/ 9367]\n",
      "loss: 0.167560  [ 3232/ 9367]\n",
      "loss: 0.242796  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.226002 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.391094  [   32/ 9367]\n",
      "loss: 0.224454  [ 3232/ 9367]\n",
      "loss: 0.131250  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.220571 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.205607  [   32/ 9367]\n",
      "loss: 0.239863  [ 3232/ 9367]\n",
      "loss: 0.261379  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 0.224677 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.287267  [   32/ 9367]\n",
      "loss: 0.248841  [ 3232/ 9367]\n",
      "loss: 0.131058  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.219043 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.357043  [   32/ 9367]\n",
      "loss: 0.394120  [ 3232/ 9367]\n",
      "loss: 0.194778  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 0.221536 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.159397  [   32/ 9367]\n",
      "loss: 0.234119  [ 3232/ 9367]\n",
      "loss: 0.296837  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.214842 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.157453  [   32/ 9367]\n",
      "loss: 0.291485  [ 3232/ 9367]\n",
      "loss: 0.223751  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.219530 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.178478  [   32/ 9367]\n",
      "loss: 0.233874  [ 3232/ 9367]\n",
      "loss: 0.225436  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 0.212487 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.222817  [   32/ 9367]\n",
      "loss: 0.220452  [ 3232/ 9367]\n",
      "loss: 0.238911  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.207955 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.241785  [   32/ 9367]\n",
      "loss: 0.394395  [ 3232/ 9367]\n",
      "loss: 0.236632  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.213265 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.179228  [   32/ 9367]\n",
      "loss: 0.228847  [ 3232/ 9367]\n",
      "loss: 0.331594  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.218084 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.251026  [   32/ 9367]\n",
      "loss: 0.282328  [ 3232/ 9367]\n",
      "loss: 0.262286  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.236359 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.350264  [   32/ 9367]\n",
      "loss: 0.269047  [ 3232/ 9367]\n",
      "loss: 0.231528  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.216328 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.353679  [   32/ 9367]\n",
      "loss: 0.262264  [ 3232/ 9367]\n",
      "loss: 0.382802  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 0.215657 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.204083  [   32/ 9367]\n",
      "loss: 0.231204  [ 3232/ 9367]\n",
      "loss: 0.184323  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.211803 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.243208  [   32/ 9367]\n",
      "loss: 0.210018  [ 3232/ 9367]\n",
      "loss: 0.156357  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 0.216641 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.246909  [   32/ 9367]\n",
      "loss: 0.254304  [ 3232/ 9367]\n",
      "loss: 0.292710  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.209933 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.185245  [   32/ 9367]\n",
      "loss: 0.187286  [ 3232/ 9367]\n",
      "loss: 0.233343  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.208220 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.165769  [   32/ 9367]\n",
      "loss: 0.226228  [ 3232/ 9367]\n",
      "loss: 0.117290  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.209524 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.216368  [   32/ 9367]\n",
      "loss: 0.258834  [ 3232/ 9367]\n",
      "loss: 0.354669  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.225082 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.412679  [   32/ 9367]\n",
      "loss: 0.143559  [ 3232/ 9367]\n",
      "loss: 0.240749  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.224307 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.171638  [   32/ 9367]\n",
      "loss: 0.294933  [ 3232/ 9367]\n",
      "loss: 0.182530  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 0.218175 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.194943  [   32/ 9367]\n",
      "loss: 0.230527  [ 3232/ 9367]\n",
      "loss: 0.215979  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.217449 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.286992  [   32/ 9367]\n",
      "loss: 0.204005  [ 3232/ 9367]\n",
      "loss: 0.276232  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 0.215897 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.251511  [   32/ 9367]\n",
      "loss: 0.243529  [ 3232/ 9367]\n",
      "loss: 0.231391  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.204074 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.191407  [   32/ 9367]\n",
      "loss: 0.278200  [ 3232/ 9367]\n",
      "loss: 0.201672  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 0.208741 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.221372  [   32/ 9367]\n",
      "loss: 0.247068  [ 3232/ 9367]\n",
      "loss: 0.193980  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.205644 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.275327  [   32/ 9367]\n",
      "loss: 0.227822  [ 3232/ 9367]\n",
      "loss: 0.232309  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.210971 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.297452  [   32/ 9367]\n",
      "loss: 0.190769  [ 3232/ 9367]\n",
      "loss: 0.259929  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.202922 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.215501  [   32/ 9367]\n",
      "loss: 0.271953  [ 3232/ 9367]\n",
      "loss: 0.203774  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.204113 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.209157  [   32/ 9367]\n",
      "loss: 0.193176  [ 3232/ 9367]\n",
      "loss: 0.187984  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.201851 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.241516  [   32/ 9367]\n",
      "loss: 0.237988  [ 3232/ 9367]\n",
      "loss: 0.263814  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 0.215607 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.296927  [   32/ 9367]\n",
      "loss: 0.205814  [ 3232/ 9367]\n",
      "loss: 0.279609  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 0.203741 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.223376  [   32/ 9367]\n",
      "loss: 0.201523  [ 3232/ 9367]\n",
      "loss: 0.193964  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.204851 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.210619  [   32/ 9367]\n",
      "loss: 0.224606  [ 3232/ 9367]\n",
      "loss: 0.250431  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.202251 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.169212  [   32/ 9367]\n",
      "loss: 0.233060  [ 3232/ 9367]\n",
      "loss: 0.214253  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.208741 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.370244  [   32/ 9367]\n",
      "loss: 0.186831  [ 3232/ 9367]\n",
      "loss: 0.305924  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.197591 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.195098  [   32/ 9367]\n",
      "loss: 0.213834  [ 3232/ 9367]\n",
      "loss: 0.180009  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 0.203131 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.247738  [   32/ 9367]\n",
      "loss: 0.179601  [ 3232/ 9367]\n",
      "loss: 0.204807  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.196228 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.240984  [   32/ 9367]\n",
      "loss: 0.247260  [ 3232/ 9367]\n",
      "loss: 0.307863  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.202177 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.344132  [   32/ 9367]\n",
      "loss: 0.209620  [ 3232/ 9367]\n",
      "loss: 0.292524  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.198218 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.280314  [   32/ 9367]\n",
      "loss: 0.237843  [ 3232/ 9367]\n",
      "loss: 0.376002  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 0.198066 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.212632  [   32/ 9367]\n",
      "loss: 0.243452  [ 3232/ 9367]\n",
      "loss: 0.187777  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.200134 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.153307  [   32/ 9367]\n",
      "loss: 0.262178  [ 3232/ 9367]\n",
      "loss: 0.230616  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.206037 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.208588  [   32/ 9367]\n",
      "loss: 0.107023  [ 3232/ 9367]\n",
      "loss: 0.267698  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.200451 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.227153  [   32/ 9367]\n",
      "loss: 0.227209  [ 3232/ 9367]\n",
      "loss: 0.306010  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.194176 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.243994  [   32/ 9367]\n",
      "loss: 0.231430  [ 3232/ 9367]\n",
      "loss: 0.206811  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.196307 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.213168  [   32/ 9367]\n",
      "loss: 0.181387  [ 3232/ 9367]\n",
      "loss: 0.238767  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.193453 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.200576  [   32/ 9367]\n",
      "loss: 0.227154  [ 3232/ 9367]\n",
      "loss: 0.187940  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.204131 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.298574  [   32/ 9367]\n",
      "loss: 0.147692  [ 3232/ 9367]\n",
      "loss: 0.217444  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.197000 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.211619  [   32/ 9367]\n",
      "loss: 0.175383  [ 3232/ 9367]\n",
      "loss: 0.218020  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.208570 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.241190  [   32/ 9367]\n",
      "loss: 0.187360  [ 3232/ 9367]\n",
      "loss: 0.295381  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 0.208152 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.183831  [   32/ 9367]\n",
      "loss: 0.283863  [ 3232/ 9367]\n",
      "loss: 0.197096  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.195309 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.225305  [   32/ 9367]\n",
      "loss: 0.259735  [ 3232/ 9367]\n",
      "loss: 0.163434  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 0.201267 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.183669  [   32/ 9367]\n",
      "loss: 0.259668  [ 3232/ 9367]\n",
      "loss: 0.255891  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.195167 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.255807  [   32/ 9367]\n",
      "loss: 0.201984  [ 3232/ 9367]\n",
      "loss: 0.132464  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 0.202422 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.380665  [   32/ 9367]\n",
      "loss: 0.330444  [ 3232/ 9367]\n",
      "loss: 0.190244  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.197459 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.277474  [   32/ 9367]\n",
      "loss: 0.234319  [ 3232/ 9367]\n",
      "loss: 0.191221  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.197141 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.126582  [   32/ 9367]\n",
      "loss: 0.195976  [ 3232/ 9367]\n",
      "loss: 0.184662  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.197954 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.144439  [   32/ 9367]\n",
      "loss: 0.256345  [ 3232/ 9367]\n",
      "loss: 0.246253  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.195108 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.311445  [   32/ 9367]\n",
      "loss: 0.240599  [ 3232/ 9367]\n",
      "loss: 0.265920  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.186100 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.297568  [   32/ 9367]\n",
      "loss: 0.195782  [ 3232/ 9367]\n",
      "loss: 0.369769  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.204653 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.216076  [   32/ 9367]\n",
      "loss: 0.263686  [ 3232/ 9367]\n",
      "loss: 0.263894  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.201030 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.159086  [   32/ 9367]\n",
      "loss: 0.229492  [ 3232/ 9367]\n",
      "loss: 0.208215  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.193260 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.183628  [   32/ 9367]\n",
      "loss: 0.175827  [ 3232/ 9367]\n",
      "loss: 0.351841  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.206635 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.137625  [   32/ 9367]\n",
      "loss: 0.171584  [ 3232/ 9367]\n",
      "loss: 0.150560  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 0.198544 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.180308  [   32/ 9367]\n",
      "loss: 0.234109  [ 3232/ 9367]\n",
      "loss: 0.220390  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.186594 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.194706  [   32/ 9367]\n",
      "loss: 0.207058  [ 3232/ 9367]\n",
      "loss: 0.135565  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.197786 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.367512  [   32/ 9367]\n",
      "loss: 0.126716  [ 3232/ 9367]\n",
      "loss: 0.190696  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.197522 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.159933  [   32/ 9367]\n",
      "loss: 0.204184  [ 3232/ 9367]\n",
      "loss: 0.124103  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.195809 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.267821  [   32/ 9367]\n",
      "loss: 0.344287  [ 3232/ 9367]\n",
      "loss: 0.188114  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.192244 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.307298  [   32/ 9367]\n",
      "loss: 0.192567  [ 3232/ 9367]\n",
      "loss: 0.347498  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.196724 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.156798  [   32/ 9367]\n",
      "loss: 0.138832  [ 3232/ 9367]\n",
      "loss: 0.314553  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.196622 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.152269  [   32/ 9367]\n",
      "loss: 0.255486  [ 3232/ 9367]\n",
      "loss: 0.202689  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.199095 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.196305  [   32/ 9367]\n",
      "loss: 0.201090  [ 3232/ 9367]\n",
      "loss: 0.160565  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.197419 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.209793  [   32/ 9367]\n",
      "loss: 0.285294  [ 3232/ 9367]\n",
      "loss: 0.170179  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.190313 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.289832  [   32/ 9367]\n",
      "loss: 0.239442  [ 3232/ 9367]\n",
      "loss: 0.337741  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.191670 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.169859  [   32/ 9367]\n",
      "loss: 0.254672  [ 3232/ 9367]\n",
      "loss: 0.149435  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.198861 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.169717  [   32/ 9367]\n",
      "loss: 0.247371  [ 3232/ 9367]\n",
      "loss: 0.226920  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.189269 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.182700  [   32/ 9367]\n",
      "loss: 0.244791  [ 3232/ 9367]\n",
      "loss: 0.321490  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.202560 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.249623  [   32/ 9367]\n",
      "loss: 0.170942  [ 3232/ 9367]\n",
      "loss: 0.207478  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.182680 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.314012  [   32/ 9367]\n",
      "loss: 0.297508  [ 3232/ 9367]\n",
      "loss: 0.244704  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.196816 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.305788  [   32/ 9367]\n",
      "loss: 0.204144  [ 3232/ 9367]\n",
      "loss: 0.228785  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.187171 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.180171  [   32/ 9367]\n",
      "loss: 0.288978  [ 3232/ 9367]\n",
      "loss: 0.243672  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.189400 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.199493  [   32/ 9367]\n",
      "loss: 0.120249  [ 3232/ 9367]\n",
      "loss: 0.133914  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.198348 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.181365  [   32/ 9367]\n",
      "loss: 0.188033  [ 3232/ 9367]\n",
      "loss: 0.177019  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.199127 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.202137  [   32/ 9367]\n",
      "loss: 0.176182  [ 3232/ 9367]\n",
      "loss: 0.158745  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.184630 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.248277  [   32/ 9367]\n",
      "loss: 0.200344  [ 3232/ 9367]\n",
      "loss: 0.211391  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.188529 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.162659  [   32/ 9367]\n",
      "loss: 0.230966  [ 3232/ 9367]\n",
      "loss: 0.198628  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.188631 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.206804  [   32/ 9367]\n",
      "loss: 0.274857  [ 3232/ 9367]\n",
      "loss: 0.200390  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.191429 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.301445  [   32/ 9367]\n",
      "loss: 0.186243  [ 3232/ 9367]\n",
      "loss: 0.192545  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.190219 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.191809  [   32/ 9367]\n",
      "loss: 0.266717  [ 3232/ 9367]\n",
      "loss: 0.239484  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.199883 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.197777  [   32/ 9367]\n",
      "loss: 0.165651  [ 3232/ 9367]\n",
      "loss: 0.260515  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.188974 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.276519  [   32/ 9367]\n",
      "loss: 0.171176  [ 3232/ 9367]\n",
      "loss: 0.305159  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.192690 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.241683  [   32/ 9367]\n",
      "loss: 0.247712  [ 3232/ 9367]\n",
      "loss: 0.207174  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.190745 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.156337  [   32/ 9367]\n",
      "loss: 0.223999  [ 3232/ 9367]\n",
      "loss: 0.168887  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.184934 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.200897  [   32/ 9367]\n",
      "loss: 0.294929  [ 3232/ 9367]\n",
      "loss: 0.216834  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.195889 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.243648  [   32/ 9367]\n",
      "loss: 0.150158  [ 3232/ 9367]\n",
      "loss: 0.308351  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.182220 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.170592  [   32/ 9367]\n",
      "loss: 0.148284  [ 3232/ 9367]\n",
      "loss: 0.270098  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 0.196172 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.178931  [   32/ 9367]\n",
      "loss: 0.068007  [ 3232/ 9367]\n",
      "loss: 0.235467  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.191382 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.194982  [   32/ 9367]\n",
      "loss: 0.241534  [ 3232/ 9367]\n",
      "loss: 0.239827  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.180250 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.095351  [   32/ 9367]\n",
      "loss: 0.208043  [ 3232/ 9367]\n",
      "loss: 0.211685  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.187007 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.197732  [   32/ 9367]\n",
      "loss: 0.181166  [ 3232/ 9367]\n",
      "loss: 0.176727  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.190134 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.276970  [   32/ 9367]\n",
      "loss: 0.139947  [ 3232/ 9367]\n",
      "loss: 0.198146  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.179440 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.168855  [   32/ 9367]\n",
      "loss: 0.232636  [ 3232/ 9367]\n",
      "loss: 0.210244  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.192435 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.210187  [   32/ 9367]\n",
      "loss: 0.237547  [ 3232/ 9367]\n",
      "loss: 0.207724  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.179664 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.210057  [   32/ 9367]\n",
      "loss: 0.141224  [ 3232/ 9367]\n",
      "loss: 0.132089  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.190703 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.230518  [   32/ 9367]\n",
      "loss: 0.161087  [ 3232/ 9367]\n",
      "loss: 0.147647  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.183684 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.221999  [   32/ 9367]\n",
      "loss: 0.190797  [ 3232/ 9367]\n",
      "loss: 0.160290  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.185803 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.237883  [   32/ 9367]\n",
      "loss: 0.254271  [ 3232/ 9367]\n",
      "loss: 0.251954  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.176848 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.200945  [   32/ 9367]\n",
      "loss: 0.270393  [ 3232/ 9367]\n",
      "loss: 0.237663  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.178154 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.317231  [   32/ 9367]\n",
      "loss: 0.267109  [ 3232/ 9367]\n",
      "loss: 0.234933  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.194308 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.252764  [   32/ 9367]\n",
      "loss: 0.249653  [ 3232/ 9367]\n",
      "loss: 0.466587  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.181416 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.418320  [   32/ 9367]\n",
      "loss: 0.177697  [ 3232/ 9367]\n",
      "loss: 0.273298  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.182992 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.219800  [   32/ 9367]\n",
      "loss: 0.113122  [ 3232/ 9367]\n",
      "loss: 0.359305  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.179920 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.266540  [   32/ 9367]\n",
      "loss: 0.225268  [ 3232/ 9367]\n",
      "loss: 0.262623  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.182708 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.107084  [   32/ 9367]\n",
      "loss: 0.282858  [ 3232/ 9367]\n",
      "loss: 0.279447  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.188757 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.269620  [   32/ 9367]\n",
      "loss: 0.298926  [ 3232/ 9367]\n",
      "loss: 0.214420  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.187205 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.158661  [   32/ 9367]\n",
      "loss: 0.521406  [ 3232/ 9367]\n",
      "loss: 0.266090  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.186104 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.209338  [   32/ 9367]\n",
      "loss: 0.292408  [ 3232/ 9367]\n",
      "loss: 0.177237  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.180824 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.274054  [   32/ 9367]\n",
      "loss: 0.224048  [ 3232/ 9367]\n",
      "loss: 0.105522  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.187657 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.194464  [   32/ 9367]\n",
      "loss: 0.224532  [ 3232/ 9367]\n",
      "loss: 0.241884  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.182392 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.138352  [   32/ 9367]\n",
      "loss: 0.188682  [ 3232/ 9367]\n",
      "loss: 0.190101  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.174258 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.233869  [   32/ 9367]\n",
      "loss: 0.235892  [ 3232/ 9367]\n",
      "loss: 0.197282  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.182662 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.107611  [   32/ 9367]\n",
      "loss: 0.160985  [ 3232/ 9367]\n",
      "loss: 0.174396  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.174364 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.193770  [   32/ 9367]\n",
      "loss: 0.221161  [ 3232/ 9367]\n",
      "loss: 0.197522  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.184894 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.203864  [   32/ 9367]\n",
      "loss: 0.297513  [ 3232/ 9367]\n",
      "loss: 0.222503  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.177790 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.112364  [   32/ 9367]\n",
      "loss: 0.228243  [ 3232/ 9367]\n",
      "loss: 0.162042  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.176419 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.281985  [   32/ 9367]\n",
      "loss: 0.326232  [ 3232/ 9367]\n",
      "loss: 0.297639  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.180253 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.224131  [   32/ 9367]\n",
      "loss: 0.216112  [ 3232/ 9367]\n",
      "loss: 0.224604  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.179193 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.100896  [   32/ 9367]\n",
      "loss: 0.255909  [ 3232/ 9367]\n",
      "loss: 0.261957  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.173282 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.133756  [   32/ 9367]\n",
      "loss: 0.193648  [ 3232/ 9367]\n",
      "loss: 0.156823  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.189664 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.244977  [   32/ 9367]\n",
      "loss: 0.207892  [ 3232/ 9367]\n",
      "loss: 0.252095  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.181420 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.183289  [   32/ 9367]\n",
      "loss: 0.193841  [ 3232/ 9367]\n",
      "loss: 0.143846  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.176432 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.185250  [   32/ 9367]\n",
      "loss: 0.136972  [ 3232/ 9367]\n",
      "loss: 0.198265  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.179360 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.242959  [   32/ 9367]\n",
      "loss: 0.127819  [ 3232/ 9367]\n",
      "loss: 0.306857  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.175566 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.262991  [   32/ 9367]\n",
      "loss: 0.231891  [ 3232/ 9367]\n",
      "loss: 0.157866  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.165104 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.171100  [   32/ 9367]\n",
      "loss: 0.272769  [ 3232/ 9367]\n",
      "loss: 0.203835  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.175803 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.239893  [   32/ 9367]\n",
      "loss: 0.256527  [ 3232/ 9367]\n",
      "loss: 0.291655  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.177739 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.248588  [   32/ 9367]\n",
      "loss: 0.308606  [ 3232/ 9367]\n",
      "loss: 0.217726  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.181760 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.182116  [   32/ 9367]\n",
      "loss: 0.120620  [ 3232/ 9367]\n",
      "loss: 0.387749  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.173896 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.280590  [   32/ 9367]\n",
      "loss: 0.240184  [ 3232/ 9367]\n",
      "loss: 0.284915  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.179465 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.209624  [   32/ 9367]\n",
      "loss: 0.203443  [ 3232/ 9367]\n",
      "loss: 0.200219  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.172930 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.152818  [   32/ 9367]\n",
      "loss: 0.169518  [ 3232/ 9367]\n",
      "loss: 0.258852  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.183887 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.157204  [   32/ 9367]\n",
      "loss: 0.206246  [ 3232/ 9367]\n",
      "loss: 0.145233  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.174910 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.158449  [   32/ 9367]\n",
      "loss: 0.201642  [ 3232/ 9367]\n",
      "loss: 0.279234  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.176005 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.200159  [   32/ 9367]\n",
      "loss: 0.309173  [ 3232/ 9367]\n",
      "loss: 0.263773  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.178887 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.276634  [   32/ 9367]\n",
      "loss: 0.129135  [ 3232/ 9367]\n",
      "loss: 0.286956  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.174648 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.323346  [   32/ 9367]\n",
      "loss: 0.092024  [ 3232/ 9367]\n",
      "loss: 0.092708  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.176097 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.215214  [   32/ 9367]\n",
      "loss: 0.209918  [ 3232/ 9367]\n",
      "loss: 0.157569  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.169882 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.232438  [   32/ 9367]\n",
      "loss: 0.162132  [ 3232/ 9367]\n",
      "loss: 0.127979  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.175424 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.306183  [   32/ 9367]\n",
      "loss: 0.252125  [ 3232/ 9367]\n",
      "loss: 0.276391  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.175306 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.244648  [   32/ 9367]\n",
      "loss: 0.153442  [ 3232/ 9367]\n",
      "loss: 0.092484  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.169309 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.185572  [   32/ 9367]\n",
      "loss: 0.117278  [ 3232/ 9367]\n",
      "loss: 0.139267  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.177453 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.277757  [   32/ 9367]\n",
      "loss: 0.163721  [ 3232/ 9367]\n",
      "loss: 0.196760  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.179611 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.152696  [   32/ 9367]\n",
      "loss: 0.146911  [ 3232/ 9367]\n",
      "loss: 0.164227  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.179069 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.207551  [   32/ 9367]\n",
      "loss: 0.256181  [ 3232/ 9367]\n",
      "loss: 0.178435  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.174894 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.215822  [   32/ 9367]\n",
      "loss: 0.180254  [ 3232/ 9367]\n",
      "loss: 0.128411  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.169468 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.152359  [   32/ 9367]\n",
      "loss: 0.142325  [ 3232/ 9367]\n",
      "loss: 0.168879  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.167576 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.125095  [   32/ 9367]\n",
      "loss: 0.209021  [ 3232/ 9367]\n",
      "loss: 0.116793  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.175848 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.106265  [   32/ 9367]\n",
      "loss: 0.270931  [ 3232/ 9367]\n",
      "loss: 0.134897  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.167809 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.279648  [   32/ 9367]\n",
      "loss: 0.159205  [ 3232/ 9367]\n",
      "loss: 0.150772  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.171157 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.229645  [   32/ 9367]\n",
      "loss: 0.155409  [ 3232/ 9367]\n",
      "loss: 0.322724  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.166009 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.159113  [   32/ 9367]\n",
      "loss: 0.204610  [ 3232/ 9367]\n",
      "loss: 0.190733  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.167338 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.342223  [   32/ 9367]\n",
      "loss: 0.170594  [ 3232/ 9367]\n",
      "loss: 0.211434  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.173994 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.385985  [   32/ 9367]\n",
      "loss: 0.206037  [ 3232/ 9367]\n",
      "loss: 0.135526  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.178610 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.199676  [   32/ 9367]\n",
      "loss: 0.232726  [ 3232/ 9367]\n",
      "loss: 0.281921  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.169299 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.216228  [   32/ 9367]\n",
      "loss: 0.127206  [ 3232/ 9367]\n",
      "loss: 0.161029  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.172198 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.143966  [   32/ 9367]\n",
      "loss: 0.231777  [ 3232/ 9367]\n",
      "loss: 0.274505  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.180101 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.165245  [   32/ 9367]\n",
      "loss: 0.117707  [ 3232/ 9367]\n",
      "loss: 0.210267  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.177187 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.120228  [   32/ 9367]\n",
      "loss: 0.186768  [ 3232/ 9367]\n",
      "loss: 0.215842  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.165935 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.207044  [   32/ 9367]\n",
      "loss: 0.150028  [ 3232/ 9367]\n",
      "loss: 0.190385  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.170232 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.344341  [   32/ 9367]\n",
      "loss: 0.307847  [ 3232/ 9367]\n",
      "loss: 0.271620  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.164749 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.225954  [   32/ 9367]\n",
      "loss: 0.118928  [ 3232/ 9367]\n",
      "loss: 0.255287  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.180746 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.165021  [   32/ 9367]\n",
      "loss: 0.177966  [ 3232/ 9367]\n",
      "loss: 0.222132  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.176041 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.150602  [   32/ 9367]\n",
      "loss: 0.207930  [ 3232/ 9367]\n",
      "loss: 0.110955  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.170321 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.178891  [   32/ 9367]\n",
      "loss: 0.128490  [ 3232/ 9367]\n",
      "loss: 0.282426  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.177205 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.363893  [   32/ 9367]\n",
      "loss: 0.197981  [ 3232/ 9367]\n",
      "loss: 0.203719  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.171517 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.153654  [   32/ 9367]\n",
      "loss: 0.259207  [ 3232/ 9367]\n",
      "loss: 0.151220  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.164930 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.199790  [   32/ 9367]\n",
      "loss: 0.172868  [ 3232/ 9367]\n",
      "loss: 0.185980  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.167023 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.175990  [   32/ 9367]\n",
      "loss: 0.310291  [ 3232/ 9367]\n",
      "loss: 0.111820  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.166028 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.191156  [   32/ 9367]\n",
      "loss: 0.274012  [ 3232/ 9367]\n",
      "loss: 0.111061  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.170082 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.162252  [   32/ 9367]\n",
      "loss: 0.277838  [ 3232/ 9367]\n",
      "loss: 0.137780  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.168718 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.188859  [   32/ 9367]\n",
      "loss: 0.207531  [ 3232/ 9367]\n",
      "loss: 0.210430  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.167534 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.192433  [   32/ 9367]\n",
      "loss: 0.173105  [ 3232/ 9367]\n",
      "loss: 0.135525  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.166949 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.152319  [   32/ 9367]\n",
      "loss: 0.149857  [ 3232/ 9367]\n",
      "loss: 0.140232  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.173435 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.145660  [   32/ 9367]\n",
      "loss: 0.221735  [ 3232/ 9367]\n",
      "loss: 0.205620  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.175738 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.298329  [   32/ 9367]\n",
      "loss: 0.157176  [ 3232/ 9367]\n",
      "loss: 0.157564  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.180636 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.126239  [   32/ 9367]\n",
      "loss: 0.208726  [ 3232/ 9367]\n",
      "loss: 0.251250  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.162916 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.230216  [   32/ 9367]\n",
      "loss: 0.217455  [ 3232/ 9367]\n",
      "loss: 0.212284  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.179130 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.123514  [   32/ 9367]\n",
      "loss: 0.126824  [ 3232/ 9367]\n",
      "loss: 0.164041  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.171040 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.187315  [   32/ 9367]\n",
      "loss: 0.148980  [ 3232/ 9367]\n",
      "loss: 0.154866  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.171111 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.210223  [   32/ 9367]\n",
      "loss: 0.161394  [ 3232/ 9367]\n",
      "loss: 0.260207  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.169335 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.141599  [   32/ 9367]\n",
      "loss: 0.102551  [ 3232/ 9367]\n",
      "loss: 0.195721  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.167944 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.089774  [   32/ 9367]\n",
      "loss: 0.182752  [ 3232/ 9367]\n",
      "loss: 0.265439  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.173915 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.149744  [   32/ 9367]\n",
      "loss: 0.231324  [ 3232/ 9367]\n",
      "loss: 0.146552  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.171454 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.146011  [   32/ 9367]\n",
      "loss: 0.099785  [ 3232/ 9367]\n",
      "loss: 0.214230  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.175737 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.302539  [   32/ 9367]\n",
      "loss: 0.210565  [ 3232/ 9367]\n",
      "loss: 0.274795  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.167925 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.192297  [   32/ 9367]\n",
      "loss: 0.213901  [ 3232/ 9367]\n",
      "loss: 0.221316  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.174103 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.126310  [   32/ 9367]\n",
      "loss: 0.323501  [ 3232/ 9367]\n",
      "loss: 0.227684  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.170730 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.178443  [   32/ 9367]\n",
      "loss: 0.138865  [ 3232/ 9367]\n",
      "loss: 0.097220  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.168834 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.189140  [   32/ 9367]\n",
      "loss: 0.182612  [ 3232/ 9367]\n",
      "loss: 0.121179  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.163794 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.443204  [   32/ 9367]\n",
      "loss: 0.129854  [ 3232/ 9367]\n",
      "loss: 0.307085  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.166942 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.207515  [   32/ 9367]\n",
      "loss: 0.236976  [ 3232/ 9367]\n",
      "loss: 0.068681  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.171064 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.198122  [   32/ 9367]\n",
      "loss: 0.076281  [ 3232/ 9367]\n",
      "loss: 0.264710  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.164713 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.163725  [   32/ 9367]\n",
      "loss: 0.126097  [ 3232/ 9367]\n",
      "loss: 0.145379  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.163893 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.091387  [   32/ 9367]\n",
      "loss: 0.218289  [ 3232/ 9367]\n",
      "loss: 0.153829  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.164435 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.096547  [   32/ 9367]\n",
      "loss: 0.160811  [ 3232/ 9367]\n",
      "loss: 0.233364  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.168328 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.271067  [   32/ 9367]\n",
      "loss: 0.183781  [ 3232/ 9367]\n",
      "loss: 0.164966  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.170572 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.171340  [   32/ 9367]\n",
      "loss: 0.229193  [ 3232/ 9367]\n",
      "loss: 0.243732  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.165324 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.252658  [   32/ 9367]\n",
      "loss: 0.161109  [ 3232/ 9367]\n",
      "loss: 0.130831  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.185498 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.226256  [   32/ 9367]\n",
      "loss: 0.148942  [ 3232/ 9367]\n",
      "loss: 0.130500  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.161635 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.182648  [   32/ 9367]\n",
      "loss: 0.151975  [ 3232/ 9367]\n",
      "loss: 0.226002  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.162148 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.138530  [   32/ 9367]\n",
      "loss: 0.248600  [ 3232/ 9367]\n",
      "loss: 0.093923  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.164698 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.131357  [   32/ 9367]\n",
      "loss: 0.211449  [ 3232/ 9367]\n",
      "loss: 0.213368  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.159199 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.163246  [   32/ 9367]\n",
      "loss: 0.146417  [ 3232/ 9367]\n",
      "loss: 0.127539  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.170364 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.151852  [   32/ 9367]\n",
      "loss: 0.236425  [ 3232/ 9367]\n",
      "loss: 0.105401  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.174702 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.187284  [   32/ 9367]\n",
      "loss: 0.352795  [ 3232/ 9367]\n",
      "loss: 0.162391  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.164439 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.113571  [   32/ 9367]\n",
      "loss: 0.190173  [ 3232/ 9367]\n",
      "loss: 0.196476  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.162585 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.109470  [   32/ 9367]\n",
      "loss: 0.106885  [ 3232/ 9367]\n",
      "loss: 0.253525  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.167715 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.150858  [   32/ 9367]\n",
      "loss: 0.173465  [ 3232/ 9367]\n",
      "loss: 0.163692  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.160136 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.248561  [   32/ 9367]\n",
      "loss: 0.145535  [ 3232/ 9367]\n",
      "loss: 0.200532  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.165582 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.239889  [   32/ 9367]\n",
      "loss: 0.263992  [ 3232/ 9367]\n",
      "loss: 0.213117  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.178715 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.152145  [   32/ 9367]\n",
      "loss: 0.162373  [ 3232/ 9367]\n",
      "loss: 0.139499  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.164832 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.155781  [   32/ 9367]\n",
      "loss: 0.192997  [ 3232/ 9367]\n",
      "loss: 0.206792  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.168165 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.145806  [   32/ 9367]\n",
      "loss: 0.152605  [ 3232/ 9367]\n",
      "loss: 0.190835  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.161745 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.263733  [   32/ 9367]\n",
      "loss: 0.244984  [ 3232/ 9367]\n",
      "loss: 0.220398  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.165128 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.255866  [   32/ 9367]\n",
      "loss: 0.110151  [ 3232/ 9367]\n",
      "loss: 0.273028  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.166563 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.164323  [   32/ 9367]\n",
      "loss: 0.234308  [ 3232/ 9367]\n",
      "loss: 0.199903  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.164465 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.127219  [   32/ 9367]\n",
      "loss: 0.130262  [ 3232/ 9367]\n",
      "loss: 0.263639  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.162894 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.280848  [   32/ 9367]\n",
      "loss: 0.211372  [ 3232/ 9367]\n",
      "loss: 0.276518  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.167221 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.277571  [   32/ 9367]\n",
      "loss: 0.198158  [ 3232/ 9367]\n",
      "loss: 0.213237  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.163281 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.093470  [   32/ 9367]\n",
      "loss: 0.231604  [ 3232/ 9367]\n",
      "loss: 0.359558  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.166843 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.185675  [   32/ 9367]\n",
      "loss: 0.177909  [ 3232/ 9367]\n",
      "loss: 0.222209  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.176784 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.178721  [   32/ 9367]\n",
      "loss: 0.170466  [ 3232/ 9367]\n",
      "loss: 0.233794  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.169917 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.175057  [   32/ 9367]\n",
      "loss: 0.174239  [ 3232/ 9367]\n",
      "loss: 0.112287  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.177151 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.122500  [   32/ 9367]\n",
      "loss: 0.252786  [ 3232/ 9367]\n",
      "loss: 0.220557  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.170084 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.212036  [   32/ 9367]\n",
      "loss: 0.136323  [ 3232/ 9367]\n",
      "loss: 0.236316  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.167567 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.237816  [   32/ 9367]\n",
      "loss: 0.125638  [ 3232/ 9367]\n",
      "loss: 0.269290  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.164621 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.175596  [   32/ 9367]\n",
      "loss: 0.144992  [ 3232/ 9367]\n",
      "loss: 0.133648  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.172906 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.183167  [   32/ 9367]\n",
      "loss: 0.159926  [ 3232/ 9367]\n",
      "loss: 0.315326  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.171102 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.153432  [   32/ 9367]\n",
      "loss: 0.313464  [ 3232/ 9367]\n",
      "loss: 0.168458  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.166931 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.207169  [   32/ 9367]\n",
      "loss: 0.179612  [ 3232/ 9367]\n",
      "loss: 0.200274  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.157130 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.131158  [   32/ 9367]\n",
      "loss: 0.145375  [ 3232/ 9367]\n",
      "loss: 0.245047  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.156928 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.252342  [   32/ 9367]\n",
      "loss: 0.179160  [ 3232/ 9367]\n",
      "loss: 0.124612  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.169350 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.234612  [   32/ 9367]\n",
      "loss: 0.122542  [ 3232/ 9367]\n",
      "loss: 0.176388  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.162467 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.196180  [   32/ 9367]\n",
      "loss: 0.093492  [ 3232/ 9367]\n",
      "loss: 0.251772  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.165537 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.285956  [   32/ 9367]\n",
      "loss: 0.219311  [ 3232/ 9367]\n",
      "loss: 0.227412  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.169009 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.156199  [   32/ 9367]\n",
      "loss: 0.254745  [ 3232/ 9367]\n",
      "loss: 0.177502  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.161780 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.143157  [   32/ 9367]\n",
      "loss: 0.232983  [ 3232/ 9367]\n",
      "loss: 0.224621  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.167182 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.148610  [   32/ 9367]\n",
      "loss: 0.252262  [ 3232/ 9367]\n",
      "loss: 0.240094  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.166105 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.167234  [   32/ 9367]\n",
      "loss: 0.316561  [ 3232/ 9367]\n",
      "loss: 0.163410  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.164576 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.145595  [   32/ 9367]\n",
      "loss: 0.232851  [ 3232/ 9367]\n",
      "loss: 0.144562  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.154219 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.150514  [   32/ 9367]\n",
      "loss: 0.132114  [ 3232/ 9367]\n",
      "loss: 0.180028  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.169375 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.120724  [   32/ 9367]\n",
      "loss: 0.203395  [ 3232/ 9367]\n",
      "loss: 0.152917  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.161373 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.204790  [   32/ 9367]\n",
      "loss: 0.119495  [ 3232/ 9367]\n",
      "loss: 0.158649  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.169078 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.126274  [   32/ 9367]\n",
      "loss: 0.102367  [ 3232/ 9367]\n",
      "loss: 0.272559  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.165451 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.141588  [   32/ 9367]\n",
      "loss: 0.132522  [ 3232/ 9367]\n",
      "loss: 0.108161  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.160146 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.198926  [   32/ 9367]\n",
      "loss: 0.130913  [ 3232/ 9367]\n",
      "loss: 0.291250  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.160330 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.187103  [   32/ 9367]\n",
      "loss: 0.148857  [ 3232/ 9367]\n",
      "loss: 0.125216  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.159018 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.198750  [   32/ 9367]\n",
      "loss: 0.197348  [ 3232/ 9367]\n",
      "loss: 0.237353  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.160243 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.183992  [   32/ 9367]\n",
      "loss: 0.157568  [ 3232/ 9367]\n",
      "loss: 0.153473  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.155869 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.260178  [   32/ 9367]\n",
      "loss: 0.152239  [ 3232/ 9367]\n",
      "loss: 0.179379  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.161434 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.188879  [   32/ 9367]\n",
      "loss: 0.128833  [ 3232/ 9367]\n",
      "loss: 0.244578  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.164585 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.252603  [   32/ 9367]\n",
      "loss: 0.178068  [ 3232/ 9367]\n",
      "loss: 0.121745  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.161574 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.204116  [   32/ 9367]\n",
      "loss: 0.145643  [ 3232/ 9367]\n",
      "loss: 0.148270  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.162055 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.153478  [   32/ 9367]\n",
      "loss: 0.174631  [ 3232/ 9367]\n",
      "loss: 0.202884  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.180114 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.140490  [   32/ 9367]\n",
      "loss: 0.118846  [ 3232/ 9367]\n",
      "loss: 0.115930  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.156472 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.121487  [   32/ 9367]\n",
      "loss: 0.152754  [ 3232/ 9367]\n",
      "loss: 0.299913  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.158406 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.231670  [   32/ 9367]\n",
      "loss: 0.101888  [ 3232/ 9367]\n",
      "loss: 0.192443  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.163994 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.319028  [   32/ 9367]\n",
      "loss: 0.110511  [ 3232/ 9367]\n",
      "loss: 0.253473  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.159823 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.115101  [   32/ 9367]\n",
      "loss: 0.127763  [ 3232/ 9367]\n",
      "loss: 0.159352  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.155737 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.234309  [   32/ 9367]\n",
      "loss: 0.123821  [ 3232/ 9367]\n",
      "loss: 0.089524  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.156072 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.174838  [   32/ 9367]\n",
      "loss: 0.359088  [ 3232/ 9367]\n",
      "loss: 0.213374  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.159181 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.180204  [   32/ 9367]\n",
      "loss: 0.156814  [ 3232/ 9367]\n",
      "loss: 0.080427  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.161834 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.153417  [   32/ 9367]\n",
      "loss: 0.219267  [ 3232/ 9367]\n",
      "loss: 0.143901  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.157367 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.133663  [   32/ 9367]\n",
      "loss: 0.155509  [ 3232/ 9367]\n",
      "loss: 0.185071  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.152682 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.161094  [   32/ 9367]\n",
      "loss: 0.158017  [ 3232/ 9367]\n",
      "loss: 0.312700  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.160793 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.088609  [   32/ 9367]\n",
      "loss: 0.187540  [ 3232/ 9367]\n",
      "loss: 0.346123  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.156145 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.233525  [   32/ 9367]\n",
      "loss: 0.070251  [ 3232/ 9367]\n",
      "loss: 0.131021  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.159258 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.188334  [   32/ 9367]\n",
      "loss: 0.244221  [ 3232/ 9367]\n",
      "loss: 0.139536  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.165995 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.128393  [   32/ 9367]\n",
      "loss: 0.177584  [ 3232/ 9367]\n",
      "loss: 0.169037  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.158742 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.145941  [   32/ 9367]\n",
      "loss: 0.225575  [ 3232/ 9367]\n",
      "loss: 0.189319  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.161576 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.151430  [   32/ 9367]\n",
      "loss: 0.101122  [ 3232/ 9367]\n",
      "loss: 0.130975  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.159799 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.100524  [   32/ 9367]\n",
      "loss: 0.222277  [ 3232/ 9367]\n",
      "loss: 0.226841  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.157525 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.227538  [   32/ 9367]\n",
      "loss: 0.165068  [ 3232/ 9367]\n",
      "loss: 0.160242  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.159523 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.267846  [   32/ 9367]\n",
      "loss: 0.211883  [ 3232/ 9367]\n",
      "loss: 0.235129  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.164265 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.155051  [   32/ 9367]\n",
      "loss: 0.283270  [ 3232/ 9367]\n",
      "loss: 0.112067  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.160715 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.160864  [   32/ 9367]\n",
      "loss: 0.196573  [ 3232/ 9367]\n",
      "loss: 0.149293  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.167134 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.183373  [   32/ 9367]\n",
      "loss: 0.196485  [ 3232/ 9367]\n",
      "loss: 0.131875  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.159893 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.223164  [   32/ 9367]\n",
      "loss: 0.127860  [ 3232/ 9367]\n",
      "loss: 0.206158  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.156474 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.097305  [   32/ 9367]\n",
      "loss: 0.212980  [ 3232/ 9367]\n",
      "loss: 0.249733  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.157599 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.160688  [   32/ 9367]\n",
      "loss: 0.234422  [ 3232/ 9367]\n",
      "loss: 0.183642  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.157427 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.191207  [   32/ 9367]\n",
      "loss: 0.191223  [ 3232/ 9367]\n",
      "loss: 0.132855  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.170606 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.172127  [   32/ 9367]\n",
      "loss: 0.113209  [ 3232/ 9367]\n",
      "loss: 0.149124  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.154293 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.248204  [   32/ 9367]\n",
      "loss: 0.293149  [ 3232/ 9367]\n",
      "loss: 0.185130  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.161288 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.197961  [   32/ 9367]\n",
      "loss: 0.120574  [ 3232/ 9367]\n",
      "loss: 0.175906  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.154656 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.121135  [   32/ 9367]\n",
      "loss: 0.168660  [ 3232/ 9367]\n",
      "loss: 0.185850  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.162973 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.159936  [   32/ 9367]\n",
      "loss: 0.275926  [ 3232/ 9367]\n",
      "loss: 0.063403  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.158734 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.309694  [   32/ 9367]\n",
      "loss: 0.259820  [ 3232/ 9367]\n",
      "loss: 0.157162  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.160543 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.249226  [   32/ 9367]\n",
      "loss: 0.200734  [ 3232/ 9367]\n",
      "loss: 0.196149  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.156412 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.168073  [   32/ 9367]\n",
      "loss: 0.177433  [ 3232/ 9367]\n",
      "loss: 0.158332  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.153109 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.292628  [   32/ 9367]\n",
      "loss: 0.166112  [ 3232/ 9367]\n",
      "loss: 0.155865  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.157391 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.105786  [   32/ 9367]\n",
      "loss: 0.082837  [ 3232/ 9367]\n",
      "loss: 0.112734  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.159640 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.194517  [   32/ 9367]\n",
      "loss: 0.288042  [ 3232/ 9367]\n",
      "loss: 0.132072  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.143985 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.106127  [   32/ 9367]\n",
      "loss: 0.145956  [ 3232/ 9367]\n",
      "loss: 0.190499  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.165411 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.183158  [   32/ 9367]\n",
      "loss: 0.158728  [ 3232/ 9367]\n",
      "loss: 0.087753  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.159664 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.172854  [   32/ 9367]\n",
      "loss: 0.170271  [ 3232/ 9367]\n",
      "loss: 0.252634  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.152963 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.208001  [   32/ 9367]\n",
      "loss: 0.120409  [ 3232/ 9367]\n",
      "loss: 0.168308  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.154543 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.177162  [   32/ 9367]\n",
      "loss: 0.273345  [ 3232/ 9367]\n",
      "loss: 0.208686  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.165670 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.180154  [   32/ 9367]\n",
      "loss: 0.192824  [ 3232/ 9367]\n",
      "loss: 0.274958  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.162535 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.116660  [   32/ 9367]\n",
      "loss: 0.294013  [ 3232/ 9367]\n",
      "loss: 0.150586  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.166235 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.199708  [   32/ 9367]\n",
      "loss: 0.138821  [ 3232/ 9367]\n",
      "loss: 0.152084  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.183857 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.401347  [   32/ 9367]\n",
      "loss: 0.174954  [ 3232/ 9367]\n",
      "loss: 0.078127  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.162282 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.179975  [   32/ 9367]\n",
      "loss: 0.156780  [ 3232/ 9367]\n",
      "loss: 0.127980  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.150300 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.300891  [   32/ 9367]\n",
      "loss: 0.172369  [ 3232/ 9367]\n",
      "loss: 0.124220  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.153202 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.099097  [   32/ 9367]\n",
      "loss: 0.198160  [ 3232/ 9367]\n",
      "loss: 0.294519  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.156974 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.174110  [   32/ 9367]\n",
      "loss: 0.239708  [ 3232/ 9367]\n",
      "loss: 0.088351  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.150334 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.225703  [   32/ 9367]\n",
      "loss: 0.147740  [ 3232/ 9367]\n",
      "loss: 0.195203  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.148297 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.113260  [   32/ 9367]\n",
      "loss: 0.169214  [ 3232/ 9367]\n",
      "loss: 0.211908  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.156983 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.081146  [   32/ 9367]\n",
      "loss: 0.166315  [ 3232/ 9367]\n",
      "loss: 0.169963  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.160692 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.184264  [   32/ 9367]\n",
      "loss: 0.105696  [ 3232/ 9367]\n",
      "loss: 0.111407  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.151038 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.201677  [   32/ 9367]\n",
      "loss: 0.339960  [ 3232/ 9367]\n",
      "loss: 0.199184  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.159534 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.197447  [   32/ 9367]\n",
      "loss: 0.140105  [ 3232/ 9367]\n",
      "loss: 0.079158  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.160546 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.112470  [   32/ 9367]\n",
      "loss: 0.246728  [ 3232/ 9367]\n",
      "loss: 0.131501  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.159748 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.218685  [   32/ 9367]\n",
      "loss: 0.179769  [ 3232/ 9367]\n",
      "loss: 0.120652  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.155036 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.172784  [   32/ 9367]\n",
      "loss: 0.167290  [ 3232/ 9367]\n",
      "loss: 0.155894  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.159894 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.243726  [   32/ 9367]\n",
      "loss: 0.172370  [ 3232/ 9367]\n",
      "loss: 0.226120  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.163254 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.204194  [   32/ 9367]\n",
      "loss: 0.172449  [ 3232/ 9367]\n",
      "loss: 0.186718  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.155534 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.233612  [   32/ 9367]\n",
      "loss: 0.112920  [ 3232/ 9367]\n",
      "loss: 0.157542  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.169994 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.101668  [   32/ 9367]\n",
      "loss: 0.218147  [ 3232/ 9367]\n",
      "loss: 0.126367  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.167116 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.265705  [   32/ 9367]\n",
      "loss: 0.165009  [ 3232/ 9367]\n",
      "loss: 0.153966  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.167503 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.203817  [   32/ 9367]\n",
      "loss: 0.128569  [ 3232/ 9367]\n",
      "loss: 0.108771  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.161196 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.212611  [   32/ 9367]\n",
      "loss: 0.124587  [ 3232/ 9367]\n",
      "loss: 0.222885  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.161472 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.159985  [   32/ 9367]\n",
      "loss: 0.343714  [ 3232/ 9367]\n",
      "loss: 0.176834  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.174440 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.099521  [   32/ 9367]\n",
      "loss: 0.093154  [ 3232/ 9367]\n",
      "loss: 0.188196  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.154968 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.234337  [   32/ 9367]\n",
      "loss: 0.187688  [ 3232/ 9367]\n",
      "loss: 0.258942  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.151679 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.110487  [   32/ 9367]\n",
      "loss: 0.248770  [ 3232/ 9367]\n",
      "loss: 0.174327  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.152365 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.131643  [   32/ 9367]\n",
      "loss: 0.128770  [ 3232/ 9367]\n",
      "loss: 0.233854  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.156584 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.194585  [   32/ 9367]\n",
      "loss: 0.095895  [ 3232/ 9367]\n",
      "loss: 0.145050  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.150265 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.111846  [   32/ 9367]\n",
      "loss: 0.140045  [ 3232/ 9367]\n",
      "loss: 0.136081  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.151801 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.127202  [   32/ 9367]\n",
      "loss: 0.170765  [ 3232/ 9367]\n",
      "loss: 0.186537  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.159657 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.127284  [   32/ 9367]\n",
      "loss: 0.231201  [ 3232/ 9367]\n",
      "loss: 0.123853  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.165286 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.284309  [   32/ 9367]\n",
      "loss: 0.168706  [ 3232/ 9367]\n",
      "loss: 0.190705  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.157698 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.270529  [   32/ 9367]\n",
      "loss: 0.071338  [ 3232/ 9367]\n",
      "loss: 0.222652  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.153594 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.177990  [   32/ 9367]\n",
      "loss: 0.274386  [ 3232/ 9367]\n",
      "loss: 0.125868  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.156050 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.391488  [   32/ 9367]\n",
      "loss: 0.217658  [ 3232/ 9367]\n",
      "loss: 0.256777  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.155723 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.157130  [   32/ 9367]\n",
      "loss: 0.084914  [ 3232/ 9367]\n",
      "loss: 0.161918  [ 6432/ 9367]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.162770 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model, train_losses, val_losses = train_early_stopping(\n",
    "    train_loader, val_loader, model, loss_fn, optimizer, epochs=500, early_stopping=True,\n",
    "    threshold=0.2,\n",
    "    counter=True, clipping=True)\n",
    "\n",
    "# plot training and validation losses\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(val_losses, label='val')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'models/display-box-14.mdl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/gwjrml9d76v_zwbyb2x6yc0r0000gn/T/ipykernel_4953/2522857457.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_save_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CounterCNN().to(device)\n",
    "model.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.158976 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.15897621581850407, 0.7974386339381003)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out of sample test\n",
    "model.eval()\n",
    "# test(test_loader, model, loss_fn)\n",
    "test_counter(test_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 2, Actual label: tensor([0., 0., 1.])\n",
      "Predicted class: 0, Actual label: tensor([1., 0., 0.])\n",
      "Predicted class: 2, Actual label: tensor([0., 0., 1.])\n",
      "Predicted class: 1, Actual label: tensor([0., 1., 0.])\n",
      "Predicted class: 0, Actual label: tensor([0., 0., 0.])\n",
      "Predicted class: 2, Actual label: tensor([0., 0., 1.])\n",
      "Predicted class: 1, Actual label: tensor([0., 1., 0.])\n",
      "Predicted class: 1, Actual label: tensor([0., 0., 0.])\n",
      "Predicted class: 2, Actual label: tensor([0., 0., 0.])\n",
      "Predicted class: 2, Actual label: tensor([0., 0., 0.])\n",
      "Predicted class: 0, Actual label: tensor([1., 0., 0.])\n",
      "Predicted class: 2, Actual label: tensor([0., 0., 1.])\n",
      "Predicted class: 2, Actual label: tensor([0., 1., 0.])\n",
      "Predicted class: 0, Actual label: tensor([0., 0., 0.])\n",
      "Predicted class: 1, Actual label: tensor([0., 1., 0.])\n",
      "Predicted class: 2, Actual label: tensor([0., 0., 0.])\n",
      "Predicted class: 0, Actual label: tensor([1., 0., 0.])\n",
      "Predicted class: 1, Actual label: tensor([0., 1., 0.])\n",
      "Predicted class: 2, Actual label: tensor([0., 0., 1.])\n",
      "Predicted class: 2, Actual label: tensor([0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    # Get a single example from the test dataset\n",
    "    example_data, example_label = test_dataset[i]\n",
    "\n",
    "    # Move the example data to the appropriate device\n",
    "    example_data = example_data.unsqueeze(0).to(device)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Get the model's prediction\n",
    "    with torch.no_grad():\n",
    "        example_data = example_data.to(device)\n",
    "        output = model(example_data)\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class = output.argmax(dim=1).item()\n",
    "\n",
    "    # Print the predicted class and the actual label\n",
    "    print(f'Predicted class: {predicted_class}, Actual label: {example_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store predictions\n",
    "predictions = []\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    for X, _ in test_loader:\n",
    "        X = X.to(device)\n",
    "        output = model(X)\n",
    "        # predicted_classes = output.argmax(dim=1)\n",
    "        # predictions.extend(predicted_classes.cpu().numpy())\n",
    "        predicted_zones = torch.round(torch.clamp(output, min=0, max=1))\n",
    "        predictions.extend(predicted_zones.cpu().numpy())\n",
    "\n",
    "# Convert predictions to a numpy array\n",
    "y_preds = np.array(predictions)\n",
    "print(y_preds)\n",
    "\n",
    "y_test = np.array([y for _, y in test_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 2 0 2]\n"
     ]
    }
   ],
   "source": [
    "# FULL DATASET\n",
    "# Create a DataLoader for the entire dataset\n",
    "full_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store the predictions\n",
    "predictions = []\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    for X, _ in full_loader:\n",
    "        X = X.to(device)\n",
    "        output = model(X)\n",
    "        predicted_classes = output.argmax(dim=1)\n",
    "        predictions.extend(predicted_classes.cpu().numpy())\n",
    "\n",
    "# Convert outputs to a numpy array\n",
    "y_preds = np.array(predictions)\n",
    "print(y_preds)\n",
    "\n",
    "y_test = np.array([y for _, y in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test = np.array([y[0] for _, y in test_dataset]).astype(int)\n",
    "y_preds = np.array([p[0] for p in predictions]).astype(int)\n",
    "conf_matrix = confusion_matrix(y_test, y_preds)\n",
    "conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Change figure size and increase dpi for better resolution\n",
    "plt.figure(figsize=(8,6), dpi=100)\n",
    "# Scale up the size of all text\n",
    " \n",
    "# Plot Confusion Matrix using Seaborn heatmap()\n",
    "# Parameters:\n",
    "# first param - confusion matrix in array format   \n",
    "# annot = True: show the numbers in each heatmap cell\n",
    "# fmt = 'd': show numbers as integers. \n",
    "ax = sns.heatmap(conf_matrix_normalized, annot=True, fmt='.2f', )\n",
    " \n",
    "# set x-axis label and ticks. \n",
    "ax.set_xlabel(\"Predicted\", fontsize=14, labelpad=20)\n",
    "# tick_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
    "# tick_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "# tick_labels = [0, 1, 2, 3, 4, 5, 6]\n",
    "# tick_labels = [0, 1, 2]\n",
    "tick_labels = [0, 1]\n",
    "ax.xaxis.set_ticklabels(tick_labels)\n",
    " \n",
    "# set y-axis label and ticks\n",
    "ax.set_ylabel(\"Actual\", fontsize=14, labelpad=20)\n",
    "ax.yaxis.set_ticklabels(tick_labels)\n",
    " \n",
    "# set plot title\n",
    "ax.set_title(\"Confusion Matrix\", fontsize=14, pad=20)\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 1158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 4, 2])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90971185 0.93340448 0.94685165]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of labels (8).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[276], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m tick_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m000\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m001\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m010\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m011\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m100\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m101\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m110\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m111\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# tick_labels = [\"000\", \"001\", \"010\", \"100\"]\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxaxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_ticklabels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtick_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# set y-axis label and ticks\u001b[39;00m\n\u001b[1;32m     37\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m, labelpad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Camera Culture/sensor package/venv/lib/python3.12/site-packages/matplotlib/axis.py:2071\u001b[0m, in \u001b[0;36mAxis.set_ticklabels\u001b[0;34m(self, labels, minor, fontdict, **kwargs)\u001b[0m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(locator, mticker\u001b[38;5;241m.\u001b[39mFixedLocator):\n\u001b[1;32m   2068\u001b[0m     \u001b[38;5;66;03m# Passing [] as a list of labels is often used as a way to\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;66;03m# remove all tick labels, so only error for > 0 labels\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2071\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2072\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of FixedLocator locations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2073\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), usually from a call to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2074\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set_ticks, does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2075\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the number of labels (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2076\u001b[0m     tickd \u001b[38;5;241m=\u001b[39m {loc: lab \u001b[38;5;28;01mfor\u001b[39;00m loc, lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs, labels)}\n\u001b[1;32m   2077\u001b[0m     func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_with_dict, tickd)\n",
      "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of labels (8)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test = np.array([y for _, y in test_dataset]).astype(int)\n",
    "y_preds = np.array([p for p in predictions]).astype(int)\n",
    "\n",
    "# plot accuracy of each zone\n",
    "correct = (y_test == y_preds)\n",
    "zone_correct = np.sum(correct, axis=0)\n",
    "zone_total = np.sum(y_test == y_test, axis=0)\n",
    "\n",
    "zone_accuracy = zone_correct / zone_total\n",
    "print(zone_accuracy)\n",
    "\n",
    "category_y_test = y_test.dot(2**np.arange(2, -1, -1))\n",
    "category_y_preds = y_preds.dot(2**np.arange(2, -1, -1))\n",
    "\n",
    "conf_matrix = confusion_matrix(category_y_test, category_y_preds)\n",
    "conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Change figure size and increase dpi for better resolution\n",
    "plt.figure(figsize=(8,6), dpi=100)\n",
    "# Scale up the size of all text\n",
    " \n",
    "# Plot Confusion Matrix using Seaborn heatmap()\n",
    "# Parameters:\n",
    "# first param - confusion matrix in array format   \n",
    "# annot = True: show the numbers in each heatmap cell\n",
    "# fmt = 'd': show numbers as integers. \n",
    "ax = sns.heatmap(conf_matrix_normalized, annot=True, fmt='.2f', )\n",
    " \n",
    "# set x-axis label and ticks. \n",
    "ax.set_xlabel(\"Predicted\", fontsize=14, labelpad=20)\n",
    "# tick_labels = [\"000\", \"001\", \"010\", \"011\", \"100\", \"101\", \"110\"]\n",
    "tick_labels = [\"000\", \"001\", \"010\", \"011\", \"100\", \"101\", \"110\", \"111\"]\n",
    "# tick_labels = [\"000\", \"001\", \"010\", \"100\"]\n",
    "ax.xaxis.set_ticklabels(tick_labels)\n",
    " \n",
    "# set y-axis label and ticks\n",
    "ax.set_ylabel(\"Actual\", fontsize=14, labelpad=20)\n",
    "ax.yaxis.set_ticklabels(tick_labels)\n",
    " \n",
    "# set plot title\n",
    "ax.set_title(\"Confusion Matrix\", fontsize=14, pad=20)\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
