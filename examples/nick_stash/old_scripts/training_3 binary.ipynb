{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch import nn\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "height = 4\n",
    "width = 4\n",
    "depth = 24\n",
    "\n",
    "all_hists = []\n",
    "labels = []\n",
    "zero_hists = []\n",
    "\n",
    "zone_to_label = {\n",
    "    0: [0],\n",
    "    1: [1],\n",
    "    2: [1],\n",
    "    3: [1],\n",
    "    4: [1],\n",
    "    5: [1],\n",
    "    6: [1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    hists = np.load(f'datasets/display-box-11/histograms_{i}.npy')\n",
    "\n",
    "    hists = hists.reshape(-1, height, width, depth)\n",
    "    # move depth to the front\n",
    "    hists = np.moveaxis(hists, -1, 1)\n",
    "\n",
    "    # look at first 10 bins\n",
    "    # data = np.array(hists[:, :10, :, :])\n",
    "    # data = np.array(hists[:, :, :, :])\n",
    "    data = hists\n",
    "\n",
    "    # Compute the mean and standard deviation for each position (10, 4, 4) across all samples\n",
    "    mean = data.mean(axis=0)  # Shape: (10, 4, 4)\n",
    "    std = data.std(axis=0)    # Shape: (10, 4, 4)\n",
    "\n",
    "    # Compute the threshold for values being within 3 standard deviations\n",
    "    lower_bound = mean - 3 * std\n",
    "    upper_bound = mean + 3 * std\n",
    "\n",
    "    # Only consider the first n values along the 10-axis (shape: n x 4 x 4)\n",
    "    n = 4\n",
    "    data_to_check = data[:, :n, :, :]  # Shape: (4000, n, 4, 4)\n",
    "    lower_bound_check = lower_bound[:n, :, :]  # Shape: (n, 4, 4)\n",
    "    upper_bound_check = upper_bound[:n, :, :]  # Shape: (n, 4, 4)\n",
    "\n",
    "    # Identify samples where all values in the first 3 indices along the 10-axis are within bounds\n",
    "    valid_mask = np.all((data_to_check >= lower_bound_check) & (data_to_check <= upper_bound_check), axis=(1, 2, 3))\n",
    "\n",
    "    # Apply the mask to filter the samples\n",
    "    filtered_data = data[valid_mask]\n",
    "\n",
    "    hists = filtered_data\n",
    "\n",
    "    # sliding window mean smoothing\n",
    "    # Compute the sliding window mean\n",
    "    k = 5\n",
    "    sliding_mean = np.array([\n",
    "        hists[j - k + 1 : j + 1].mean(axis=0)  # Mean of the last k elements\n",
    "        for j in range(k - 1, len(hists))\n",
    "    ])\n",
    "    \n",
    "    hists = sliding_mean\n",
    "\n",
    "    # generate more data by adding gaussian noise with std of the actual data std (changes for bin/pixel)\n",
    "    std = hists.std(axis=0)\n",
    "    hists = np.repeat(hists, 5, axis=0)\n",
    "    hists += np.random.normal(0, std * 0.5, hists.shape)\n",
    "\n",
    "    if i == 0:\n",
    "        zero_hists.append(hists)\n",
    "\n",
    "    \n",
    "    all_hists.append(hists)\n",
    "    labels += [zone_to_label[i]] * len(hists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_hists = np.concatenate(zero_hists, axis=0)\n",
    "all_hists = np.concatenate(all_hists, axis=0)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# all_hists = all_hists.reshape(-1, height, width, depth)\n",
    "# # move depth to the front\n",
    "# all_hists = np.moveaxis(all_hists, -1, 1)\n",
    "\n",
    "# zero_hists = zero_hists.reshape(-1, height, width, depth)\n",
    "# zero_hists = np.moveaxis(zero_hists, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute the mean and standard deviation for each position (24, 4, 4) across all samples\n",
    "# mean = all_hists.mean(axis=0)  # Shape: (24, 4, 4)\n",
    "# std = all_hists.std(axis=0)    # Shape: (24, 4, 4)\n",
    "\n",
    "# # Compute the threshold for values being within 3 standard deviations\n",
    "# lower_bound = mean - 3 * std\n",
    "# upper_bound = mean + 3 * std\n",
    "\n",
    "# # Only consider the first n values along the depth axis (shape: n x 4 x 4)\n",
    "# n = 4\n",
    "# data_to_check = all_hists[:, :n, :, :]  # Shape: (4000, n, 4, 4)\n",
    "# lower_bound_check = lower_bound[:n, :, :]  # Shape: (n, 4, 4)\n",
    "# upper_bound_check = upper_bound[:n, :, :]  # Shape: (n, 4, 4)\n",
    "\n",
    "# # Identify samples where all values in the first 3 indices along the depth axis are within bounds\n",
    "# valid_mask = np.all((data_to_check >= lower_bound_check) & (data_to_check <= upper_bound_check), axis=(1, 2, 3))\n",
    "\n",
    "# # Apply the mask to filter the samples\n",
    "# filtered_all_hists = all_hists[valid_mask]\n",
    "# filtered_labels = labels[valid_mask]\n",
    "\n",
    "# # Check the shapes of the original and filtered arrays\n",
    "# print(f\"Original shape: {all_hists.shape}\")\n",
    "# print(f\"Filtered shape: {filtered_all_hists.shape}\")\n",
    "# all_hists = filtered_all_hists\n",
    "# labels = filtered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_bin = 4\n",
    "end_bin = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop first bounce bins (first bounce in first 2 bins)\n",
    "# crop bins that are too far and noisy\n",
    "all_hists = all_hists[:, start_bin:end_bin, :, :]\n",
    "zero_hists = zero_hists[:, start_bin:end_bin, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate more data by adding gaussian noise\n",
    "\n",
    "# all_hists = np.repeat(all_hists, 5, axis=0)\n",
    "# labels = np.repeat(labels, 5, axis=0)\n",
    "\n",
    "# add noise\n",
    "# std = 3 is good for general training?\n",
    "# all_hists += np.random.normal(0, 1, all_hists.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hists = torch.tensor(all_hists, dtype=torch.float32)\n",
    "zero_hists = torch.tensor(zero_hists, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick 20 random zero hists to act as the zero mean\n",
    "num_samples_to_mean = 20\n",
    "\n",
    "random_zero_mean = torch.empty((all_hists.shape[0], all_hists.shape[1], height, width))\n",
    "\n",
    "for i in range(all_hists.shape[0]):\n",
    "    indices = torch.randint(0, zero_hists.shape[0], (num_samples_to_mean,))\n",
    "    random_zero_mean[i] = zero_hists[indices].mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normalize to 0-1 values\n",
    "# all_hist_mins = all_hists.amin(dim=(1, 2, 3), keepdim=True)\n",
    "# all_hist_maxs = all_hists.amax(dim=(1, 2, 3), keepdim=True)\n",
    "# all_hist_ranges = all_hist_maxs - all_hist_mins\n",
    "# all_hist_ranges[all_hist_ranges == 0] = 1\n",
    "# all_hists = (all_hists - all_hist_mins) / all_hist_ranges\n",
    "\n",
    "# # normalize to 0-1 values\n",
    "# random_zero_mean_mins = random_zero_mean.amin(dim=(1, 2, 3), keepdim=True)\n",
    "# random_zero_mean_maxs = random_zero_mean.amax(dim=(1, 2, 3), keepdim=True)\n",
    "# random_zero_mean_ranges = random_zero_mean_maxs - random_zero_mean_mins\n",
    "# random_zero_mean_ranges[random_zero_mean_ranges == 0] = 1\n",
    "# random_zero_mean = (random_zero_mean - random_zero_mean_mins) / random_zero_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hists_rel = all_hists - random_zero_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean all pixels\n",
    "# all_hists_rel = all_hists_rel.mean(dim=(2, 3), keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero_mean = np.mean(zero_hists, axis=0)\n",
    "\n",
    "# # lower bound at 0\n",
    "# # all_hists = np.maximum(all_hists, 0)\n",
    "# # zero_mean = np.maximum(zero_mean, 0)\n",
    "# all_hists_rel = all_hists - zero_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of all_hists: torch.Size([18445, 12, 4, 4])\n",
      "shape of labels: (18445, 1)\n",
      "shape of all_hists_rel: torch.Size([18445, 12, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# chunk sizes\n",
    "print(f'shape of all_hists: {all_hists.shape}')\n",
    "print(f'shape of labels: {labels.shape}')\n",
    "print(f'shape of all_hists_rel: {all_hists_rel.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_all_hists_rel = np.empty((0, end_bin - start_bin, height, width))\n",
    "combined_labels = np.empty((0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_all_hists_rel = np.concatenate([combined_all_hists_rel, all_hists_rel], axis=0)\n",
    "combined_labels = np.concatenate([combined_labels, labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of all_hists_rel: (113880, 12, 4, 4)\n",
      "shape of labels: (113880, 1)\n"
     ]
    }
   ],
   "source": [
    "# final dataset sizes\n",
    "print(f'shape of all_hists_rel: {combined_all_hists_rel.shape}')\n",
    "print(f'shape of labels: {combined_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to PyTorch tensors\n",
    "# all_hists_tensor = torch.tensor(all_hists, dtype=torch.float32)\n",
    "# all_hists_tensor = torch.tensor(all_hists_rel, dtype=torch.float32)\n",
    "all_hists_tensor = torch.tensor(combined_all_hists_rel, dtype=torch.float32)\n",
    "# labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "labels_tensor = torch.tensor(combined_labels, dtype=torch.float32)\n",
    "\n",
    "# all_hists_tensor = torch.sign(all_hists_tensor) * torch.log1p(torch.abs(all_hists_tensor))\n",
    "\n",
    "\n",
    "# epsilon = 0.1  # Smoothing factor\n",
    "# labels_tensor = (1 - epsilon) * labels_tensor + epsilon * 0.5  # Smooth towards uniform distribution\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(all_hists_tensor, labels_tensor)\n",
    "\n",
    "# Define the sizes for training, validation, and test sets\n",
    "train_size = int(0.5 * len(dataset))\n",
    "val_size = int(0.25 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size], \n",
    "                                                        generator=torch.Generator().manual_seed(1))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create DataLoaders for each set\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_x shape: torch.Size([32, 12, 4, 4])\n",
      "batch_y shape: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "for batch_x, batch_y in train_loader:\n",
    "    print(f'batch_x shape: {batch_x.shape}')\n",
    "    print(f'batch_y shape: {batch_y.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CounterCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CounterCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels=(end_bin - start_bin), out_channels=16, kernel_size=3, padding=1)\n",
    "#         self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=1)\n",
    "#         self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "#         # self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "#         self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
    "#         self.fc1_bn = nn.BatchNorm1d(128)\n",
    "#         self.fc2 = nn.Linear(128, 3)  # Assuming 10 classes for the labels\n",
    "#         self.relu = nn.LeakyReLU(negative_slope=0.01)\n",
    "#         self.dropout = nn.Dropout(p=0.7)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # print(f'x shape at start: {x.shape}')\n",
    "#         x = self.relu(self.conv1(x))\n",
    "#         # print(f'x shape after conv1: {x.shape}')\n",
    "#         x = self.batchnorm1(x)\n",
    "#         # x = self.pool(x)\n",
    "#         # print(f'x shape after pool1: {x.shape}')\n",
    "#         x = self.relu(self.conv2(x))\n",
    "#         # print(f'x shape after conv2: {x.shape}')\n",
    "#         x = self.batchnorm2(x)\n",
    "#         # x = self.pool(x)\n",
    "#         # print(f'x shape after pool2: {x.shape}')\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         # print(f'x shape after flatten: {x.shape}')\n",
    "#         x = self.relu(self.fc1(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.fc1_bn(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# # Instantiate the model\n",
    "# model = CounterCNN().to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CounterCNN(\n",
      "  (conv3d): Conv3d(1, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (batchnorm3d): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
      "  (fc1_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (relu): LeakyReLU(negative_slope=0.01)\n",
      "  (dropout): Dropout(p=0.7, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CounterCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CounterCNN, self).__init__()\n",
    "        # self.conv1 = nn.Conv2d(in_channels=(end_bin - start_bin), out_channels=16, kernel_size=3, padding=1)\n",
    "        # self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        # self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=1)\n",
    "        # self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        out_channels = 4\n",
    "        self.conv3d = nn.Conv3d(in_channels=1, out_channels=out_channels, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.batchnorm3d = nn.BatchNorm3d(out_channels)\n",
    "\n",
    "        self.fc1 = nn.Linear(out_channels * (end_bin - start_bin) * height * width, 128)\n",
    "\n",
    "        # self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
    "        self.fc1_bn = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 1)  # Assuming 10 classes for the labels\n",
    "        self.relu = nn.LeakyReLU(negative_slope=0.01)\n",
    "        self.dropout = nn.Dropout(p=0.7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # # print(f'x shape at start: {x.shape}')\n",
    "        # x = self.relu(self.conv1(x))\n",
    "        # # print(f'x shape after conv1: {x.shape}')\n",
    "        # x = self.batchnorm1(x)\n",
    "        # # x = self.pool(x)\n",
    "        # # print(f'x shape after pool1: {x.shape}')\n",
    "        # x = self.relu(self.conv2(x))\n",
    "        # # print(f'x shape after conv2: {x.shape}')\n",
    "        # x = self.batchnorm2(x)\n",
    "\n",
    "        x = self.relu(self.conv3d(x.unsqueeze(1)))\n",
    "        x = self.batchnorm3d(x)\n",
    "\n",
    "        # x = self.pool(x)\n",
    "        # print(f'x shape after pool2: {x.shape}')\n",
    "        x = torch.flatten(x, 1)\n",
    "        # print(f'x shape after flatten: {x.shape}')\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1_bn(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = CounterCNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CounterCNN(\n",
       "  (conv3d): Conv3d(1, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (batchnorm3d): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (fc1_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (relu): LeakyReLU(negative_slope=0.01)\n",
       "  (dropout): Dropout(p=0.7, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 949,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, torch.nn.Linear) or isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='leaky_relu')\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(), lr=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, counter=False, clipping=False, debug=False):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        if len(X) < batch_size:\n",
    "            continue\n",
    "\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # print(f'X shape: {X.shape}, y shape: {y.shape}')\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        # if counter:\n",
    "            # y = y.unsqueeze(1)\n",
    "        # print(f'pred shape: {pred.shape}, y shape: {y.shape}')\n",
    "        loss = loss_fn(pred, y)\n",
    "        # print(f'loss: {loss.item()}')\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        if clipping:\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Adjust max_norm as needed\n",
    "        \n",
    "        if debug:\n",
    "            # Inspect gradients for each layer\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None:  # Only check if gradient is computed\n",
    "                    print(f\"Layer: {name} | Gradient mean: {param.grad.abs().mean().item()} | Gradient max: {param.grad.abs().max().item()}\")\n",
    "                else:\n",
    "                    print(f\"Layer: {name} has no gradient.\")\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    train_loss /= len(dataloader)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_counter(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            # y = y.unsqueeze_(1)\n",
    "            # print(X.shape)\n",
    "            # print(y.shape)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            final_pred = torch.round(torch.sigmoid(pred))\n",
    "            # final_pred = torch.round(torch.clamp(pred, min=0, max=1))\n",
    "            \n",
    "            # print(final_pred.shape)\n",
    "            # print(\"true\")\n",
    "            # print(y)\n",
    "            # print(\"pred\")\n",
    "            # print(final_pred)\n",
    "            # print(\"diff\")\n",
    "            # print(final_pred - y)\n",
    "            exact_match = torch.all(final_pred == torch.round(y), dim=1)\n",
    "            correct += torch.sum(exact_match).item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_early_stopping(train_loader, val_loader, model, loss_fn, optimizer, \n",
    "    epochs=50, early_stopping=True, patience=5, threshold=0.15, counter=False, clipping=False, debug=False):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loss = train(train_loader, model, loss_fn, optimizer, counter=counter, clipping=clipping, debug=debug)\n",
    "        if counter:\n",
    "            val_loss, correct = test_counter(val_loader, model, loss_fn)\n",
    "        else:\n",
    "            val_loss, correct = test(val_loader, model, loss_fn)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        if early_stopping:\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = model\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                if val_loss / best_val_loss > 1 + threshold:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= patience:\n",
    "                        print(f\"Early stopping at epoch {t+1}\")\n",
    "                        break\n",
    "        # print(f'patience_counter: {patience_counter}')\n",
    "    return best_model, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.885086  [   32/56940]\n",
      "loss: 0.689000  [ 3232/56940]\n",
      "loss: 0.506778  [ 6432/56940]\n",
      "loss: 0.498748  [ 9632/56940]\n",
      "loss: 0.622516  [12832/56940]\n",
      "loss: 0.370573  [16032/56940]\n",
      "loss: 0.514434  [19232/56940]\n",
      "loss: 0.356994  [22432/56940]\n",
      "loss: 0.439236  [25632/56940]\n",
      "loss: 0.349180  [28832/56940]\n",
      "loss: 0.515806  [32032/56940]\n",
      "loss: 0.536542  [35232/56940]\n",
      "loss: 0.408863  [38432/56940]\n",
      "loss: 0.466257  [41632/56940]\n",
      "loss: 0.424191  [44832/56940]\n",
      "loss: 0.832841  [48032/56940]\n",
      "loss: 0.469096  [51232/56940]\n",
      "loss: 0.487211  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.410308 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.503023  [   32/56940]\n",
      "loss: 0.455272  [ 3232/56940]\n",
      "loss: 0.494034  [ 6432/56940]\n",
      "loss: 0.320796  [ 9632/56940]\n",
      "loss: 0.468591  [12832/56940]\n",
      "loss: 0.460885  [16032/56940]\n",
      "loss: 0.410664  [19232/56940]\n",
      "loss: 0.298323  [22432/56940]\n",
      "loss: 0.381121  [25632/56940]\n",
      "loss: 0.387237  [28832/56940]\n",
      "loss: 0.313970  [32032/56940]\n",
      "loss: 0.511066  [35232/56940]\n",
      "loss: 0.449333  [38432/56940]\n",
      "loss: 0.541008  [41632/56940]\n",
      "loss: 0.379699  [44832/56940]\n",
      "loss: 0.353265  [48032/56940]\n",
      "loss: 0.386603  [51232/56940]\n",
      "loss: 0.491452  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.404916 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.583463  [   32/56940]\n",
      "loss: 0.550095  [ 3232/56940]\n",
      "loss: 0.486293  [ 6432/56940]\n",
      "loss: 0.540962  [ 9632/56940]\n",
      "loss: 0.439870  [12832/56940]\n",
      "loss: 0.363512  [16032/56940]\n",
      "loss: 0.546786  [19232/56940]\n",
      "loss: 0.419354  [22432/56940]\n",
      "loss: 0.345093  [25632/56940]\n",
      "loss: 0.343759  [28832/56940]\n",
      "loss: 0.420193  [32032/56940]\n",
      "loss: 0.353820  [35232/56940]\n",
      "loss: 0.458750  [38432/56940]\n",
      "loss: 0.475363  [41632/56940]\n",
      "loss: 0.499505  [44832/56940]\n",
      "loss: 0.414563  [48032/56940]\n",
      "loss: 0.371988  [51232/56940]\n",
      "loss: 0.322107  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.394100 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.391204  [   32/56940]\n",
      "loss: 0.404502  [ 3232/56940]\n",
      "loss: 0.308061  [ 6432/56940]\n",
      "loss: 0.472892  [ 9632/56940]\n",
      "loss: 0.253857  [12832/56940]\n",
      "loss: 0.493367  [16032/56940]\n",
      "loss: 0.482171  [19232/56940]\n",
      "loss: 0.404894  [22432/56940]\n",
      "loss: 0.436564  [25632/56940]\n",
      "loss: 0.543596  [28832/56940]\n",
      "loss: 0.302616  [32032/56940]\n",
      "loss: 0.386891  [35232/56940]\n",
      "loss: 0.311703  [38432/56940]\n",
      "loss: 0.327239  [41632/56940]\n",
      "loss: 0.292435  [44832/56940]\n",
      "loss: 0.565412  [48032/56940]\n",
      "loss: 0.513418  [51232/56940]\n",
      "loss: 0.282360  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.392403 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.339749  [   32/56940]\n",
      "loss: 0.259748  [ 3232/56940]\n",
      "loss: 0.445240  [ 6432/56940]\n",
      "loss: 0.481603  [ 9632/56940]\n",
      "loss: 0.227631  [12832/56940]\n",
      "loss: 0.499178  [16032/56940]\n",
      "loss: 0.528392  [19232/56940]\n",
      "loss: 0.578467  [22432/56940]\n",
      "loss: 0.326399  [25632/56940]\n",
      "loss: 0.504449  [28832/56940]\n",
      "loss: 0.350476  [32032/56940]\n",
      "loss: 0.346628  [35232/56940]\n",
      "loss: 0.339752  [38432/56940]\n",
      "loss: 0.682175  [41632/56940]\n",
      "loss: 0.590738  [44832/56940]\n",
      "loss: 0.517803  [48032/56940]\n",
      "loss: 0.411637  [51232/56940]\n",
      "loss: 0.466542  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.385089 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.340466  [   32/56940]\n",
      "loss: 0.401297  [ 3232/56940]\n",
      "loss: 0.629276  [ 6432/56940]\n",
      "loss: 0.378051  [ 9632/56940]\n",
      "loss: 0.273280  [12832/56940]\n",
      "loss: 0.518148  [16032/56940]\n",
      "loss: 0.382111  [19232/56940]\n",
      "loss: 0.469084  [22432/56940]\n",
      "loss: 0.383291  [25632/56940]\n",
      "loss: 0.461657  [28832/56940]\n",
      "loss: 0.460093  [32032/56940]\n",
      "loss: 0.300729  [35232/56940]\n",
      "loss: 0.381118  [38432/56940]\n",
      "loss: 0.501260  [41632/56940]\n",
      "loss: 0.290994  [44832/56940]\n",
      "loss: 0.352352  [48032/56940]\n",
      "loss: 0.300264  [51232/56940]\n",
      "loss: 0.349786  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.375588 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.481151  [   32/56940]\n",
      "loss: 0.407930  [ 3232/56940]\n",
      "loss: 0.272410  [ 6432/56940]\n",
      "loss: 0.488498  [ 9632/56940]\n",
      "loss: 0.261796  [12832/56940]\n",
      "loss: 0.309529  [16032/56940]\n",
      "loss: 0.376265  [19232/56940]\n",
      "loss: 0.650527  [22432/56940]\n",
      "loss: 0.251830  [25632/56940]\n",
      "loss: 0.354061  [28832/56940]\n",
      "loss: 0.377326  [32032/56940]\n",
      "loss: 0.477865  [35232/56940]\n",
      "loss: 0.426671  [38432/56940]\n",
      "loss: 0.594357  [41632/56940]\n",
      "loss: 0.541330  [44832/56940]\n",
      "loss: 0.475465  [48032/56940]\n",
      "loss: 0.414188  [51232/56940]\n",
      "loss: 0.418801  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.381478 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.512385  [   32/56940]\n",
      "loss: 0.580045  [ 3232/56940]\n",
      "loss: 0.388275  [ 6432/56940]\n",
      "loss: 0.424322  [ 9632/56940]\n",
      "loss: 0.676817  [12832/56940]\n",
      "loss: 0.564394  [16032/56940]\n",
      "loss: 0.375705  [19232/56940]\n",
      "loss: 0.620756  [22432/56940]\n",
      "loss: 0.404478  [25632/56940]\n",
      "loss: 0.432004  [28832/56940]\n",
      "loss: 0.323574  [32032/56940]\n",
      "loss: 0.315504  [35232/56940]\n",
      "loss: 0.403806  [38432/56940]\n",
      "loss: 0.319132  [41632/56940]\n",
      "loss: 0.331727  [44832/56940]\n",
      "loss: 0.347820  [48032/56940]\n",
      "loss: 0.250244  [51232/56940]\n",
      "loss: 0.348631  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.359266 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.513524  [   32/56940]\n",
      "loss: 0.529108  [ 3232/56940]\n",
      "loss: 0.433356  [ 6432/56940]\n",
      "loss: 0.612784  [ 9632/56940]\n",
      "loss: 0.298337  [12832/56940]\n",
      "loss: 0.275985  [16032/56940]\n",
      "loss: 0.377669  [19232/56940]\n",
      "loss: 0.319408  [22432/56940]\n",
      "loss: 0.375061  [25632/56940]\n",
      "loss: 0.360812  [28832/56940]\n",
      "loss: 0.330590  [32032/56940]\n",
      "loss: 0.485102  [35232/56940]\n",
      "loss: 0.310299  [38432/56940]\n",
      "loss: 0.754033  [41632/56940]\n",
      "loss: 0.383647  [44832/56940]\n",
      "loss: 0.485438  [48032/56940]\n",
      "loss: 0.618644  [51232/56940]\n",
      "loss: 0.348487  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.360404 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.435970  [   32/56940]\n",
      "loss: 0.257988  [ 3232/56940]\n",
      "loss: 0.304938  [ 6432/56940]\n",
      "loss: 0.302602  [ 9632/56940]\n",
      "loss: 0.326959  [12832/56940]\n",
      "loss: 0.512533  [16032/56940]\n",
      "loss: 0.341789  [19232/56940]\n",
      "loss: 0.356613  [22432/56940]\n",
      "loss: 0.409760  [25632/56940]\n",
      "loss: 0.300952  [28832/56940]\n",
      "loss: 0.241670  [32032/56940]\n",
      "loss: 0.253014  [35232/56940]\n",
      "loss: 0.359392  [38432/56940]\n",
      "loss: 0.358435  [41632/56940]\n",
      "loss: 0.255970  [44832/56940]\n",
      "loss: 0.503874  [48032/56940]\n",
      "loss: 0.401555  [51232/56940]\n",
      "loss: 0.323954  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.361724 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.433215  [   32/56940]\n",
      "loss: 0.549999  [ 3232/56940]\n",
      "loss: 0.364628  [ 6432/56940]\n",
      "loss: 0.372618  [ 9632/56940]\n",
      "loss: 0.230840  [12832/56940]\n",
      "loss: 0.348664  [16032/56940]\n",
      "loss: 0.406383  [19232/56940]\n",
      "loss: 0.321021  [22432/56940]\n",
      "loss: 0.378928  [25632/56940]\n",
      "loss: 0.309318  [28832/56940]\n",
      "loss: 0.364790  [32032/56940]\n",
      "loss: 0.376790  [35232/56940]\n",
      "loss: 0.356105  [38432/56940]\n",
      "loss: 0.440589  [41632/56940]\n",
      "loss: 0.532572  [44832/56940]\n",
      "loss: 0.224228  [48032/56940]\n",
      "loss: 0.521825  [51232/56940]\n",
      "loss: 0.348642  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.354380 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.329129  [   32/56940]\n",
      "loss: 0.483938  [ 3232/56940]\n",
      "loss: 0.462743  [ 6432/56940]\n",
      "loss: 0.255186  [ 9632/56940]\n",
      "loss: 0.473675  [12832/56940]\n",
      "loss: 0.394920  [16032/56940]\n",
      "loss: 0.617062  [19232/56940]\n",
      "loss: 0.356575  [22432/56940]\n",
      "loss: 0.450251  [25632/56940]\n",
      "loss: 0.481385  [28832/56940]\n",
      "loss: 0.526132  [32032/56940]\n",
      "loss: 0.359719  [35232/56940]\n",
      "loss: 0.320523  [38432/56940]\n",
      "loss: 0.339436  [41632/56940]\n",
      "loss: 0.333806  [44832/56940]\n",
      "loss: 0.321201  [48032/56940]\n",
      "loss: 0.546234  [51232/56940]\n",
      "loss: 0.436985  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.351136 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.545498  [   32/56940]\n",
      "loss: 0.421732  [ 3232/56940]\n",
      "loss: 0.435494  [ 6432/56940]\n",
      "loss: 0.428117  [ 9632/56940]\n",
      "loss: 0.302833  [12832/56940]\n",
      "loss: 0.277519  [16032/56940]\n",
      "loss: 0.337409  [19232/56940]\n",
      "loss: 0.415659  [22432/56940]\n",
      "loss: 0.399260  [25632/56940]\n",
      "loss: 0.443297  [28832/56940]\n",
      "loss: 0.381091  [32032/56940]\n",
      "loss: 0.422145  [35232/56940]\n",
      "loss: 0.292112  [38432/56940]\n",
      "loss: 0.271932  [41632/56940]\n",
      "loss: 0.583151  [44832/56940]\n",
      "loss: 0.342016  [48032/56940]\n",
      "loss: 0.336552  [51232/56940]\n",
      "loss: 0.389205  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.352794 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.344403  [   32/56940]\n",
      "loss: 0.413682  [ 3232/56940]\n",
      "loss: 0.257103  [ 6432/56940]\n",
      "loss: 0.429507  [ 9632/56940]\n",
      "loss: 0.325773  [12832/56940]\n",
      "loss: 0.384469  [16032/56940]\n",
      "loss: 0.253933  [19232/56940]\n",
      "loss: 0.308771  [22432/56940]\n",
      "loss: 0.492987  [25632/56940]\n",
      "loss: 0.359858  [28832/56940]\n",
      "loss: 0.340666  [32032/56940]\n",
      "loss: 0.482441  [35232/56940]\n",
      "loss: 0.200359  [38432/56940]\n",
      "loss: 0.253419  [41632/56940]\n",
      "loss: 0.385769  [44832/56940]\n",
      "loss: 0.320345  [48032/56940]\n",
      "loss: 0.405854  [51232/56940]\n",
      "loss: 0.332322  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.345598 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.358193  [   32/56940]\n",
      "loss: 0.286457  [ 3232/56940]\n",
      "loss: 0.274803  [ 6432/56940]\n",
      "loss: 0.330300  [ 9632/56940]\n",
      "loss: 0.465535  [12832/56940]\n",
      "loss: 0.227477  [16032/56940]\n",
      "loss: 0.399909  [19232/56940]\n",
      "loss: 0.315115  [22432/56940]\n",
      "loss: 0.264978  [25632/56940]\n",
      "loss: 0.265695  [28832/56940]\n",
      "loss: 0.284802  [32032/56940]\n",
      "loss: 0.520432  [35232/56940]\n",
      "loss: 0.268006  [38432/56940]\n",
      "loss: 0.406761  [41632/56940]\n",
      "loss: 0.455372  [44832/56940]\n",
      "loss: 0.357331  [48032/56940]\n",
      "loss: 0.516058  [51232/56940]\n",
      "loss: 0.365768  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.343256 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.391859  [   32/56940]\n",
      "loss: 0.335368  [ 3232/56940]\n",
      "loss: 0.264979  [ 6432/56940]\n",
      "loss: 0.618985  [ 9632/56940]\n",
      "loss: 0.368959  [12832/56940]\n",
      "loss: 0.348481  [16032/56940]\n",
      "loss: 0.321600  [19232/56940]\n",
      "loss: 0.383871  [22432/56940]\n",
      "loss: 0.602177  [25632/56940]\n",
      "loss: 0.428988  [28832/56940]\n",
      "loss: 0.433165  [32032/56940]\n",
      "loss: 0.428894  [35232/56940]\n",
      "loss: 0.341289  [38432/56940]\n",
      "loss: 0.301433  [41632/56940]\n",
      "loss: 0.333943  [44832/56940]\n",
      "loss: 0.625448  [48032/56940]\n",
      "loss: 0.260551  [51232/56940]\n",
      "loss: 0.516823  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.344722 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.536645  [   32/56940]\n",
      "loss: 0.540477  [ 3232/56940]\n",
      "loss: 0.194312  [ 6432/56940]\n",
      "loss: 0.285892  [ 9632/56940]\n",
      "loss: 0.230288  [12832/56940]\n",
      "loss: 0.276456  [16032/56940]\n",
      "loss: 0.458245  [19232/56940]\n",
      "loss: 0.262040  [22432/56940]\n",
      "loss: 0.318518  [25632/56940]\n",
      "loss: 0.335051  [28832/56940]\n",
      "loss: 0.547039  [32032/56940]\n",
      "loss: 0.461271  [35232/56940]\n",
      "loss: 0.307829  [38432/56940]\n",
      "loss: 0.374938  [41632/56940]\n",
      "loss: 0.243999  [44832/56940]\n",
      "loss: 0.366770  [48032/56940]\n",
      "loss: 0.447618  [51232/56940]\n",
      "loss: 0.306498  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.343792 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.364159  [   32/56940]\n",
      "loss: 0.469052  [ 3232/56940]\n",
      "loss: 0.615260  [ 6432/56940]\n",
      "loss: 0.290524  [ 9632/56940]\n",
      "loss: 0.207186  [12832/56940]\n",
      "loss: 0.284266  [16032/56940]\n",
      "loss: 0.303718  [19232/56940]\n",
      "loss: 0.469824  [22432/56940]\n",
      "loss: 0.265000  [25632/56940]\n",
      "loss: 0.334267  [28832/56940]\n",
      "loss: 0.364678  [32032/56940]\n",
      "loss: 0.348086  [35232/56940]\n",
      "loss: 0.377256  [38432/56940]\n",
      "loss: 0.337120  [41632/56940]\n",
      "loss: 0.390054  [44832/56940]\n",
      "loss: 0.325809  [48032/56940]\n",
      "loss: 0.466322  [51232/56940]\n",
      "loss: 0.303621  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.339805 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.397069  [   32/56940]\n",
      "loss: 0.311855  [ 3232/56940]\n",
      "loss: 0.290485  [ 6432/56940]\n",
      "loss: 0.410802  [ 9632/56940]\n",
      "loss: 0.269848  [12832/56940]\n",
      "loss: 0.257851  [16032/56940]\n",
      "loss: 0.340433  [19232/56940]\n",
      "loss: 0.281979  [22432/56940]\n",
      "loss: 0.341080  [25632/56940]\n",
      "loss: 0.304743  [28832/56940]\n",
      "loss: 0.376076  [32032/56940]\n",
      "loss: 0.262787  [35232/56940]\n",
      "loss: 0.451338  [38432/56940]\n",
      "loss: 0.304483  [41632/56940]\n",
      "loss: 0.414781  [44832/56940]\n",
      "loss: 0.361218  [48032/56940]\n",
      "loss: 0.378120  [51232/56940]\n",
      "loss: 0.214732  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.341376 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.258928  [   32/56940]\n",
      "loss: 0.253453  [ 3232/56940]\n",
      "loss: 0.242844  [ 6432/56940]\n",
      "loss: 0.555382  [ 9632/56940]\n",
      "loss: 0.584479  [12832/56940]\n",
      "loss: 0.394617  [16032/56940]\n",
      "loss: 0.341775  [19232/56940]\n",
      "loss: 0.358774  [22432/56940]\n",
      "loss: 0.435469  [25632/56940]\n",
      "loss: 0.222560  [28832/56940]\n",
      "loss: 0.468453  [32032/56940]\n",
      "loss: 0.341484  [35232/56940]\n",
      "loss: 0.324198  [38432/56940]\n",
      "loss: 0.197025  [41632/56940]\n",
      "loss: 0.336692  [44832/56940]\n",
      "loss: 0.313707  [48032/56940]\n",
      "loss: 0.159174  [51232/56940]\n",
      "loss: 0.380774  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.332914 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.421214  [   32/56940]\n",
      "loss: 0.482200  [ 3232/56940]\n",
      "loss: 0.504796  [ 6432/56940]\n",
      "loss: 0.338822  [ 9632/56940]\n",
      "loss: 0.312939  [12832/56940]\n",
      "loss: 0.406612  [16032/56940]\n",
      "loss: 0.265058  [19232/56940]\n",
      "loss: 0.363147  [22432/56940]\n",
      "loss: 0.439752  [25632/56940]\n",
      "loss: 0.344689  [28832/56940]\n",
      "loss: 0.465752  [32032/56940]\n",
      "loss: 0.374450  [35232/56940]\n",
      "loss: 0.400390  [38432/56940]\n",
      "loss: 0.406826  [41632/56940]\n",
      "loss: 0.434095  [44832/56940]\n",
      "loss: 0.270651  [48032/56940]\n",
      "loss: 0.347847  [51232/56940]\n",
      "loss: 0.416984  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.337128 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.311063  [   32/56940]\n",
      "loss: 0.375341  [ 3232/56940]\n",
      "loss: 0.316708  [ 6432/56940]\n",
      "loss: 0.434809  [ 9632/56940]\n",
      "loss: 0.439331  [12832/56940]\n",
      "loss: 0.421726  [16032/56940]\n",
      "loss: 0.363218  [19232/56940]\n",
      "loss: 0.377602  [22432/56940]\n",
      "loss: 0.329940  [25632/56940]\n",
      "loss: 0.538571  [28832/56940]\n",
      "loss: 0.227518  [32032/56940]\n",
      "loss: 0.570388  [35232/56940]\n",
      "loss: 0.433312  [38432/56940]\n",
      "loss: 0.344375  [41632/56940]\n",
      "loss: 0.336104  [44832/56940]\n",
      "loss: 0.226243  [48032/56940]\n",
      "loss: 0.674522  [51232/56940]\n",
      "loss: 0.336653  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.329451 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.242150  [   32/56940]\n",
      "loss: 0.339019  [ 3232/56940]\n",
      "loss: 0.450823  [ 6432/56940]\n",
      "loss: 0.306764  [ 9632/56940]\n",
      "loss: 0.427642  [12832/56940]\n",
      "loss: 0.503964  [16032/56940]\n",
      "loss: 0.552182  [19232/56940]\n",
      "loss: 0.304229  [22432/56940]\n",
      "loss: 0.341355  [25632/56940]\n",
      "loss: 0.508021  [28832/56940]\n",
      "loss: 0.381285  [32032/56940]\n",
      "loss: 0.395446  [35232/56940]\n",
      "loss: 0.513296  [38432/56940]\n",
      "loss: 0.365158  [41632/56940]\n",
      "loss: 0.378836  [44832/56940]\n",
      "loss: 0.362918  [48032/56940]\n",
      "loss: 0.444016  [51232/56940]\n",
      "loss: 0.288674  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.331510 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.273368  [   32/56940]\n",
      "loss: 0.322658  [ 3232/56940]\n",
      "loss: 0.320562  [ 6432/56940]\n",
      "loss: 0.366518  [ 9632/56940]\n",
      "loss: 0.200839  [12832/56940]\n",
      "loss: 0.254294  [16032/56940]\n",
      "loss: 0.356904  [19232/56940]\n",
      "loss: 0.304885  [22432/56940]\n",
      "loss: 0.328156  [25632/56940]\n",
      "loss: 0.338795  [28832/56940]\n",
      "loss: 0.388063  [32032/56940]\n",
      "loss: 0.330517  [35232/56940]\n",
      "loss: 0.359683  [38432/56940]\n",
      "loss: 0.389322  [41632/56940]\n",
      "loss: 0.334413  [44832/56940]\n",
      "loss: 0.346875  [48032/56940]\n",
      "loss: 0.407966  [51232/56940]\n",
      "loss: 0.288223  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.343912 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.502118  [   32/56940]\n",
      "loss: 0.380109  [ 3232/56940]\n",
      "loss: 0.368551  [ 6432/56940]\n",
      "loss: 0.293962  [ 9632/56940]\n",
      "loss: 0.346386  [12832/56940]\n",
      "loss: 0.391475  [16032/56940]\n",
      "loss: 0.445413  [19232/56940]\n",
      "loss: 0.497154  [22432/56940]\n",
      "loss: 0.276979  [25632/56940]\n",
      "loss: 0.398148  [28832/56940]\n",
      "loss: 0.244869  [32032/56940]\n",
      "loss: 0.232134  [35232/56940]\n",
      "loss: 0.344524  [38432/56940]\n",
      "loss: 0.659702  [41632/56940]\n",
      "loss: 0.414052  [44832/56940]\n",
      "loss: 0.445505  [48032/56940]\n",
      "loss: 0.237569  [51232/56940]\n",
      "loss: 0.221573  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.322230 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.238657  [   32/56940]\n",
      "loss: 0.486439  [ 3232/56940]\n",
      "loss: 0.255253  [ 6432/56940]\n",
      "loss: 0.335515  [ 9632/56940]\n",
      "loss: 0.356985  [12832/56940]\n",
      "loss: 0.561876  [16032/56940]\n",
      "loss: 0.281159  [19232/56940]\n",
      "loss: 0.294684  [22432/56940]\n",
      "loss: 0.364413  [25632/56940]\n",
      "loss: 0.336121  [28832/56940]\n",
      "loss: 0.295931  [32032/56940]\n",
      "loss: 0.371673  [35232/56940]\n",
      "loss: 0.518081  [38432/56940]\n",
      "loss: 0.361504  [41632/56940]\n",
      "loss: 0.271385  [44832/56940]\n",
      "loss: 0.457341  [48032/56940]\n",
      "loss: 0.434220  [51232/56940]\n",
      "loss: 0.609446  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.334575 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.434546  [   32/56940]\n",
      "loss: 0.401593  [ 3232/56940]\n",
      "loss: 0.458131  [ 6432/56940]\n",
      "loss: 0.293880  [ 9632/56940]\n",
      "loss: 0.240861  [12832/56940]\n",
      "loss: 0.284654  [16032/56940]\n",
      "loss: 0.415459  [19232/56940]\n",
      "loss: 0.498251  [22432/56940]\n",
      "loss: 0.236503  [25632/56940]\n",
      "loss: 0.273705  [28832/56940]\n",
      "loss: 0.255244  [32032/56940]\n",
      "loss: 0.365567  [35232/56940]\n",
      "loss: 0.515610  [38432/56940]\n",
      "loss: 0.287455  [41632/56940]\n",
      "loss: 0.344762  [44832/56940]\n",
      "loss: 0.259425  [48032/56940]\n",
      "loss: 0.300740  [51232/56940]\n",
      "loss: 0.455127  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.339424 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.299475  [   32/56940]\n",
      "loss: 0.355847  [ 3232/56940]\n",
      "loss: 0.347444  [ 6432/56940]\n",
      "loss: 0.250709  [ 9632/56940]\n",
      "loss: 0.469830  [12832/56940]\n",
      "loss: 0.339933  [16032/56940]\n",
      "loss: 0.333069  [19232/56940]\n",
      "loss: 0.450176  [22432/56940]\n",
      "loss: 0.425629  [25632/56940]\n",
      "loss: 0.311222  [28832/56940]\n",
      "loss: 0.560616  [32032/56940]\n",
      "loss: 0.432031  [35232/56940]\n",
      "loss: 0.297674  [38432/56940]\n",
      "loss: 0.267058  [41632/56940]\n",
      "loss: 0.452253  [44832/56940]\n",
      "loss: 0.219903  [48032/56940]\n",
      "loss: 0.378589  [51232/56940]\n",
      "loss: 0.331219  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.318352 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.342476  [   32/56940]\n",
      "loss: 0.403083  [ 3232/56940]\n",
      "loss: 0.448073  [ 6432/56940]\n",
      "loss: 0.396009  [ 9632/56940]\n",
      "loss: 0.320712  [12832/56940]\n",
      "loss: 0.271599  [16032/56940]\n",
      "loss: 0.404401  [19232/56940]\n",
      "loss: 0.268453  [22432/56940]\n",
      "loss: 0.446187  [25632/56940]\n",
      "loss: 0.333154  [28832/56940]\n",
      "loss: 0.284489  [32032/56940]\n",
      "loss: 0.433474  [35232/56940]\n",
      "loss: 0.479401  [38432/56940]\n",
      "loss: 0.313140  [41632/56940]\n",
      "loss: 0.387858  [44832/56940]\n",
      "loss: 0.314469  [48032/56940]\n",
      "loss: 0.346229  [51232/56940]\n",
      "loss: 0.160952  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.311662 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.453207  [   32/56940]\n",
      "loss: 0.397689  [ 3232/56940]\n",
      "loss: 0.242305  [ 6432/56940]\n",
      "loss: 0.433751  [ 9632/56940]\n",
      "loss: 0.312856  [12832/56940]\n",
      "loss: 0.225805  [16032/56940]\n",
      "loss: 0.293543  [19232/56940]\n",
      "loss: 0.513428  [22432/56940]\n",
      "loss: 0.403003  [25632/56940]\n",
      "loss: 0.272661  [28832/56940]\n",
      "loss: 0.341743  [32032/56940]\n",
      "loss: 0.257767  [35232/56940]\n",
      "loss: 0.280555  [38432/56940]\n",
      "loss: 0.599699  [41632/56940]\n",
      "loss: 0.401672  [44832/56940]\n",
      "loss: 0.467896  [48032/56940]\n",
      "loss: 0.251825  [51232/56940]\n",
      "loss: 0.321277  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.320179 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.387441  [   32/56940]\n",
      "loss: 0.318078  [ 3232/56940]\n",
      "loss: 0.288134  [ 6432/56940]\n",
      "loss: 0.362103  [ 9632/56940]\n",
      "loss: 0.350746  [12832/56940]\n",
      "loss: 0.379111  [16032/56940]\n",
      "loss: 0.377719  [19232/56940]\n",
      "loss: 0.445574  [22432/56940]\n",
      "loss: 0.182934  [25632/56940]\n",
      "loss: 0.321889  [28832/56940]\n",
      "loss: 0.371239  [32032/56940]\n",
      "loss: 0.443523  [35232/56940]\n",
      "loss: 0.308503  [38432/56940]\n",
      "loss: 0.265853  [41632/56940]\n",
      "loss: 0.460401  [44832/56940]\n",
      "loss: 0.313311  [48032/56940]\n",
      "loss: 0.224179  [51232/56940]\n",
      "loss: 0.612816  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.318375 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.316381  [   32/56940]\n",
      "loss: 0.334063  [ 3232/56940]\n",
      "loss: 0.384319  [ 6432/56940]\n",
      "loss: 0.368920  [ 9632/56940]\n",
      "loss: 0.337009  [12832/56940]\n",
      "loss: 0.218440  [16032/56940]\n",
      "loss: 0.261882  [19232/56940]\n",
      "loss: 0.455197  [22432/56940]\n",
      "loss: 0.372535  [25632/56940]\n",
      "loss: 0.286845  [28832/56940]\n",
      "loss: 0.491286  [32032/56940]\n",
      "loss: 0.337209  [35232/56940]\n",
      "loss: 0.244534  [38432/56940]\n",
      "loss: 0.460969  [41632/56940]\n",
      "loss: 0.304227  [44832/56940]\n",
      "loss: 0.222057  [48032/56940]\n",
      "loss: 0.539209  [51232/56940]\n",
      "loss: 0.322242  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.313667 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.219682  [   32/56940]\n",
      "loss: 0.604708  [ 3232/56940]\n",
      "loss: 0.341622  [ 6432/56940]\n",
      "loss: 0.403233  [ 9632/56940]\n",
      "loss: 0.538226  [12832/56940]\n",
      "loss: 0.288758  [16032/56940]\n",
      "loss: 0.293402  [19232/56940]\n",
      "loss: 0.468075  [22432/56940]\n",
      "loss: 0.840322  [25632/56940]\n",
      "loss: 0.307175  [28832/56940]\n",
      "loss: 0.358996  [32032/56940]\n",
      "loss: 0.249780  [35232/56940]\n",
      "loss: 0.210552  [38432/56940]\n",
      "loss: 0.438549  [41632/56940]\n",
      "loss: 0.415144  [44832/56940]\n",
      "loss: 0.373386  [48032/56940]\n",
      "loss: 0.353739  [51232/56940]\n",
      "loss: 0.424787  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.310243 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.253846  [   32/56940]\n",
      "loss: 0.216869  [ 3232/56940]\n",
      "loss: 0.323660  [ 6432/56940]\n",
      "loss: 0.319241  [ 9632/56940]\n",
      "loss: 0.312841  [12832/56940]\n",
      "loss: 0.187926  [16032/56940]\n",
      "loss: 0.350985  [19232/56940]\n",
      "loss: 0.217420  [22432/56940]\n",
      "loss: 0.373923  [25632/56940]\n",
      "loss: 0.316408  [28832/56940]\n",
      "loss: 0.236944  [32032/56940]\n",
      "loss: 0.331411  [35232/56940]\n",
      "loss: 0.379375  [38432/56940]\n",
      "loss: 0.409101  [41632/56940]\n",
      "loss: 0.428053  [44832/56940]\n",
      "loss: 0.335096  [48032/56940]\n",
      "loss: 0.274382  [51232/56940]\n",
      "loss: 0.303253  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.308484 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.269509  [   32/56940]\n",
      "loss: 0.369085  [ 3232/56940]\n",
      "loss: 0.642006  [ 6432/56940]\n",
      "loss: 0.206902  [ 9632/56940]\n",
      "loss: 0.454782  [12832/56940]\n",
      "loss: 0.307601  [16032/56940]\n",
      "loss: 0.224770  [19232/56940]\n",
      "loss: 0.435426  [22432/56940]\n",
      "loss: 0.295784  [25632/56940]\n",
      "loss: 0.335906  [28832/56940]\n",
      "loss: 0.367221  [32032/56940]\n",
      "loss: 0.418769  [35232/56940]\n",
      "loss: 0.231043  [38432/56940]\n",
      "loss: 0.292673  [41632/56940]\n",
      "loss: 0.281387  [44832/56940]\n",
      "loss: 0.353343  [48032/56940]\n",
      "loss: 0.621532  [51232/56940]\n",
      "loss: 0.387688  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.314287 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.488609  [   32/56940]\n",
      "loss: 0.381067  [ 3232/56940]\n",
      "loss: 0.418041  [ 6432/56940]\n",
      "loss: 0.291358  [ 9632/56940]\n",
      "loss: 0.227666  [12832/56940]\n",
      "loss: 0.186580  [16032/56940]\n",
      "loss: 0.320166  [19232/56940]\n",
      "loss: 0.414158  [22432/56940]\n",
      "loss: 0.454346  [25632/56940]\n",
      "loss: 0.452623  [28832/56940]\n",
      "loss: 0.258668  [32032/56940]\n",
      "loss: 0.423255  [35232/56940]\n",
      "loss: 0.319755  [38432/56940]\n",
      "loss: 0.296969  [41632/56940]\n",
      "loss: 0.244435  [44832/56940]\n",
      "loss: 0.426282  [48032/56940]\n",
      "loss: 0.633981  [51232/56940]\n",
      "loss: 0.372748  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.307635 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.269439  [   32/56940]\n",
      "loss: 0.330303  [ 3232/56940]\n",
      "loss: 0.382453  [ 6432/56940]\n",
      "loss: 0.367833  [ 9632/56940]\n",
      "loss: 0.340078  [12832/56940]\n",
      "loss: 0.319080  [16032/56940]\n",
      "loss: 0.218413  [19232/56940]\n",
      "loss: 0.297777  [22432/56940]\n",
      "loss: 0.338064  [25632/56940]\n",
      "loss: 0.356007  [28832/56940]\n",
      "loss: 0.209974  [32032/56940]\n",
      "loss: 0.485776  [35232/56940]\n",
      "loss: 0.318825  [38432/56940]\n",
      "loss: 0.283813  [41632/56940]\n",
      "loss: 0.286755  [44832/56940]\n",
      "loss: 0.207298  [48032/56940]\n",
      "loss: 0.337720  [51232/56940]\n",
      "loss: 0.366517  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.305101 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.305552  [   32/56940]\n",
      "loss: 0.428319  [ 3232/56940]\n",
      "loss: 0.248623  [ 6432/56940]\n",
      "loss: 0.225111  [ 9632/56940]\n",
      "loss: 0.276461  [12832/56940]\n",
      "loss: 0.370138  [16032/56940]\n",
      "loss: 0.343227  [19232/56940]\n",
      "loss: 0.274270  [22432/56940]\n",
      "loss: 0.222073  [25632/56940]\n",
      "loss: 0.334295  [28832/56940]\n",
      "loss: 0.424786  [32032/56940]\n",
      "loss: 0.357397  [35232/56940]\n",
      "loss: 0.328072  [38432/56940]\n",
      "loss: 0.270287  [41632/56940]\n",
      "loss: 0.193383  [44832/56940]\n",
      "loss: 0.298053  [48032/56940]\n",
      "loss: 0.295137  [51232/56940]\n",
      "loss: 0.254292  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.312198 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.181471  [   32/56940]\n",
      "loss: 0.359127  [ 3232/56940]\n",
      "loss: 0.434291  [ 6432/56940]\n",
      "loss: 0.294259  [ 9632/56940]\n",
      "loss: 0.424590  [12832/56940]\n",
      "loss: 0.323399  [16032/56940]\n",
      "loss: 0.256725  [19232/56940]\n",
      "loss: 0.218828  [22432/56940]\n",
      "loss: 0.211437  [25632/56940]\n",
      "loss: 0.189191  [28832/56940]\n",
      "loss: 0.243796  [32032/56940]\n",
      "loss: 0.339205  [35232/56940]\n",
      "loss: 0.371385  [38432/56940]\n",
      "loss: 0.424023  [41632/56940]\n",
      "loss: 0.248450  [44832/56940]\n",
      "loss: 0.348447  [48032/56940]\n",
      "loss: 0.279667  [51232/56940]\n",
      "loss: 0.282144  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.315389 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.423979  [   32/56940]\n",
      "loss: 0.349901  [ 3232/56940]\n",
      "loss: 0.191753  [ 6432/56940]\n",
      "loss: 0.469785  [ 9632/56940]\n",
      "loss: 0.330072  [12832/56940]\n",
      "loss: 0.360544  [16032/56940]\n",
      "loss: 0.448237  [19232/56940]\n",
      "loss: 0.261269  [22432/56940]\n",
      "loss: 0.330994  [25632/56940]\n",
      "loss: 0.289488  [28832/56940]\n",
      "loss: 0.284589  [32032/56940]\n",
      "loss: 0.584566  [35232/56940]\n",
      "loss: 0.392942  [38432/56940]\n",
      "loss: 0.347496  [41632/56940]\n",
      "loss: 0.275323  [44832/56940]\n",
      "loss: 0.316081  [48032/56940]\n",
      "loss: 0.275565  [51232/56940]\n",
      "loss: 0.280449  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.302554 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.270737  [   32/56940]\n",
      "loss: 0.307564  [ 3232/56940]\n",
      "loss: 0.509959  [ 6432/56940]\n",
      "loss: 0.288784  [ 9632/56940]\n",
      "loss: 0.400167  [12832/56940]\n",
      "loss: 0.217720  [16032/56940]\n",
      "loss: 0.350379  [19232/56940]\n",
      "loss: 0.619390  [22432/56940]\n",
      "loss: 0.217473  [25632/56940]\n",
      "loss: 0.467730  [28832/56940]\n",
      "loss: 0.354253  [32032/56940]\n",
      "loss: 0.427262  [35232/56940]\n",
      "loss: 0.247621  [38432/56940]\n",
      "loss: 0.488829  [41632/56940]\n",
      "loss: 0.203003  [44832/56940]\n",
      "loss: 0.471767  [48032/56940]\n",
      "loss: 0.255249  [51232/56940]\n",
      "loss: 0.369451  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.303531 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.468152  [   32/56940]\n",
      "loss: 0.211203  [ 3232/56940]\n",
      "loss: 0.277000  [ 6432/56940]\n",
      "loss: 0.469097  [ 9632/56940]\n",
      "loss: 0.255903  [12832/56940]\n",
      "loss: 0.295442  [16032/56940]\n",
      "loss: 0.364107  [19232/56940]\n",
      "loss: 0.239294  [22432/56940]\n",
      "loss: 0.303366  [25632/56940]\n",
      "loss: 0.837335  [28832/56940]\n",
      "loss: 0.419624  [32032/56940]\n",
      "loss: 0.291498  [35232/56940]\n",
      "loss: 0.460644  [38432/56940]\n",
      "loss: 0.431972  [41632/56940]\n",
      "loss: 0.447400  [44832/56940]\n",
      "loss: 0.360599  [48032/56940]\n",
      "loss: 0.309008  [51232/56940]\n",
      "loss: 0.433859  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.305765 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.384732  [   32/56940]\n",
      "loss: 0.294955  [ 3232/56940]\n",
      "loss: 0.372408  [ 6432/56940]\n",
      "loss: 0.404129  [ 9632/56940]\n",
      "loss: 0.381516  [12832/56940]\n",
      "loss: 0.377312  [16032/56940]\n",
      "loss: 0.296669  [19232/56940]\n",
      "loss: 0.309608  [22432/56940]\n",
      "loss: 0.259256  [25632/56940]\n",
      "loss: 0.392799  [28832/56940]\n",
      "loss: 0.246317  [32032/56940]\n",
      "loss: 0.430836  [35232/56940]\n",
      "loss: 0.324760  [38432/56940]\n",
      "loss: 0.248657  [41632/56940]\n",
      "loss: 0.214868  [44832/56940]\n",
      "loss: 0.291061  [48032/56940]\n",
      "loss: 0.288868  [51232/56940]\n",
      "loss: 0.368944  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.300845 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.359588  [   32/56940]\n",
      "loss: 0.317045  [ 3232/56940]\n",
      "loss: 0.393594  [ 6432/56940]\n",
      "loss: 0.329777  [ 9632/56940]\n",
      "loss: 0.302935  [12832/56940]\n",
      "loss: 0.209465  [16032/56940]\n",
      "loss: 0.279700  [19232/56940]\n",
      "loss: 0.344355  [22432/56940]\n",
      "loss: 0.233701  [25632/56940]\n",
      "loss: 0.392141  [28832/56940]\n",
      "loss: 0.264977  [32032/56940]\n",
      "loss: 0.312261  [35232/56940]\n",
      "loss: 0.272412  [38432/56940]\n",
      "loss: 0.223802  [41632/56940]\n",
      "loss: 0.271686  [44832/56940]\n",
      "loss: 0.352869  [48032/56940]\n",
      "loss: 0.288791  [51232/56940]\n",
      "loss: 0.220781  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.317019 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.316427  [   32/56940]\n",
      "loss: 0.221733  [ 3232/56940]\n",
      "loss: 0.655441  [ 6432/56940]\n",
      "loss: 0.519364  [ 9632/56940]\n",
      "loss: 0.385917  [12832/56940]\n",
      "loss: 0.296307  [16032/56940]\n",
      "loss: 0.219147  [19232/56940]\n",
      "loss: 0.459638  [22432/56940]\n",
      "loss: 0.425224  [25632/56940]\n",
      "loss: 0.419942  [28832/56940]\n",
      "loss: 0.388308  [32032/56940]\n",
      "loss: 0.486701  [35232/56940]\n",
      "loss: 0.289200  [38432/56940]\n",
      "loss: 0.532337  [41632/56940]\n",
      "loss: 0.310090  [44832/56940]\n",
      "loss: 0.200563  [48032/56940]\n",
      "loss: 0.372123  [51232/56940]\n",
      "loss: 0.354993  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.300823 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.332725  [   32/56940]\n",
      "loss: 0.337876  [ 3232/56940]\n",
      "loss: 0.290844  [ 6432/56940]\n",
      "loss: 0.333718  [ 9632/56940]\n",
      "loss: 0.257088  [12832/56940]\n",
      "loss: 0.369032  [16032/56940]\n",
      "loss: 0.380945  [19232/56940]\n",
      "loss: 0.299279  [22432/56940]\n",
      "loss: 0.333233  [25632/56940]\n",
      "loss: 0.394907  [28832/56940]\n",
      "loss: 0.252027  [32032/56940]\n",
      "loss: 0.400198  [35232/56940]\n",
      "loss: 0.330882  [38432/56940]\n",
      "loss: 0.350579  [41632/56940]\n",
      "loss: 0.264081  [44832/56940]\n",
      "loss: 0.273098  [48032/56940]\n",
      "loss: 0.357098  [51232/56940]\n",
      "loss: 0.364019  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.298757 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.281809  [   32/56940]\n",
      "loss: 0.370544  [ 3232/56940]\n",
      "loss: 0.394340  [ 6432/56940]\n",
      "loss: 0.379323  [ 9632/56940]\n",
      "loss: 0.237219  [12832/56940]\n",
      "loss: 0.461376  [16032/56940]\n",
      "loss: 0.248979  [19232/56940]\n",
      "loss: 0.284962  [22432/56940]\n",
      "loss: 0.384487  [25632/56940]\n",
      "loss: 0.276817  [28832/56940]\n",
      "loss: 0.168031  [32032/56940]\n",
      "loss: 0.217197  [35232/56940]\n",
      "loss: 0.313435  [38432/56940]\n",
      "loss: 0.360992  [41632/56940]\n",
      "loss: 0.179836  [44832/56940]\n",
      "loss: 0.327331  [48032/56940]\n",
      "loss: 0.420231  [51232/56940]\n",
      "loss: 0.326475  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.297675 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.297924  [   32/56940]\n",
      "loss: 0.264554  [ 3232/56940]\n",
      "loss: 0.328657  [ 6432/56940]\n",
      "loss: 0.238791  [ 9632/56940]\n",
      "loss: 0.269611  [12832/56940]\n",
      "loss: 0.366534  [16032/56940]\n",
      "loss: 0.210703  [19232/56940]\n",
      "loss: 0.385215  [22432/56940]\n",
      "loss: 0.583149  [25632/56940]\n",
      "loss: 0.592480  [28832/56940]\n",
      "loss: 0.297925  [32032/56940]\n",
      "loss: 0.317788  [35232/56940]\n",
      "loss: 0.376399  [38432/56940]\n",
      "loss: 0.222771  [41632/56940]\n",
      "loss: 0.325738  [44832/56940]\n",
      "loss: 0.417878  [48032/56940]\n",
      "loss: 0.178697  [51232/56940]\n",
      "loss: 0.390032  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.301639 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.310303  [   32/56940]\n",
      "loss: 0.396292  [ 3232/56940]\n",
      "loss: 0.341890  [ 6432/56940]\n",
      "loss: 0.300635  [ 9632/56940]\n",
      "loss: 0.367066  [12832/56940]\n",
      "loss: 0.309701  [16032/56940]\n",
      "loss: 0.243620  [19232/56940]\n",
      "loss: 0.435343  [22432/56940]\n",
      "loss: 0.154952  [25632/56940]\n",
      "loss: 0.266962  [28832/56940]\n",
      "loss: 0.348127  [32032/56940]\n",
      "loss: 0.161612  [35232/56940]\n",
      "loss: 0.371901  [38432/56940]\n",
      "loss: 0.268199  [41632/56940]\n",
      "loss: 0.358282  [44832/56940]\n",
      "loss: 0.312956  [48032/56940]\n",
      "loss: 0.336471  [51232/56940]\n",
      "loss: 0.234844  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.294972 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.225637  [   32/56940]\n",
      "loss: 0.235484  [ 3232/56940]\n",
      "loss: 0.641761  [ 6432/56940]\n",
      "loss: 0.426802  [ 9632/56940]\n",
      "loss: 0.415221  [12832/56940]\n",
      "loss: 0.338572  [16032/56940]\n",
      "loss: 0.337833  [19232/56940]\n",
      "loss: 0.302082  [22432/56940]\n",
      "loss: 0.590365  [25632/56940]\n",
      "loss: 0.288804  [28832/56940]\n",
      "loss: 0.550756  [32032/56940]\n",
      "loss: 0.224625  [35232/56940]\n",
      "loss: 0.237191  [38432/56940]\n",
      "loss: 0.408543  [41632/56940]\n",
      "loss: 0.225901  [44832/56940]\n",
      "loss: 0.306004  [48032/56940]\n",
      "loss: 0.273418  [51232/56940]\n",
      "loss: 0.273011  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.289603 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.346558  [   32/56940]\n",
      "loss: 0.492630  [ 3232/56940]\n",
      "loss: 0.675132  [ 6432/56940]\n",
      "loss: 0.253788  [ 9632/56940]\n",
      "loss: 0.243580  [12832/56940]\n",
      "loss: 0.353785  [16032/56940]\n",
      "loss: 0.349352  [19232/56940]\n",
      "loss: 0.312510  [22432/56940]\n",
      "loss: 0.648262  [25632/56940]\n",
      "loss: 0.313851  [28832/56940]\n",
      "loss: 0.198749  [32032/56940]\n",
      "loss: 0.420361  [35232/56940]\n",
      "loss: 0.312242  [38432/56940]\n",
      "loss: 0.288634  [41632/56940]\n",
      "loss: 0.330915  [44832/56940]\n",
      "loss: 0.251056  [48032/56940]\n",
      "loss: 0.335591  [51232/56940]\n",
      "loss: 0.214752  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.320096 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.436293  [   32/56940]\n",
      "loss: 0.282265  [ 3232/56940]\n",
      "loss: 0.220985  [ 6432/56940]\n",
      "loss: 0.264728  [ 9632/56940]\n",
      "loss: 0.314415  [12832/56940]\n",
      "loss: 0.306939  [16032/56940]\n",
      "loss: 0.412553  [19232/56940]\n",
      "loss: 0.448184  [22432/56940]\n",
      "loss: 0.319869  [25632/56940]\n",
      "loss: 0.283725  [28832/56940]\n",
      "loss: 0.272116  [32032/56940]\n",
      "loss: 0.375436  [35232/56940]\n",
      "loss: 0.337889  [38432/56940]\n",
      "loss: 0.211798  [41632/56940]\n",
      "loss: 0.245508  [44832/56940]\n",
      "loss: 0.245169  [48032/56940]\n",
      "loss: 0.273302  [51232/56940]\n",
      "loss: 0.359839  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.294933 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.290945  [   32/56940]\n",
      "loss: 0.425154  [ 3232/56940]\n",
      "loss: 0.349878  [ 6432/56940]\n",
      "loss: 0.518039  [ 9632/56940]\n",
      "loss: 0.480562  [12832/56940]\n",
      "loss: 0.433946  [16032/56940]\n",
      "loss: 0.284698  [19232/56940]\n",
      "loss: 0.570596  [22432/56940]\n",
      "loss: 0.212659  [25632/56940]\n",
      "loss: 0.240266  [28832/56940]\n",
      "loss: 0.412261  [32032/56940]\n",
      "loss: 0.289775  [35232/56940]\n",
      "loss: 0.380798  [38432/56940]\n",
      "loss: 0.515033  [41632/56940]\n",
      "loss: 0.309992  [44832/56940]\n",
      "loss: 0.596783  [48032/56940]\n",
      "loss: 0.261680  [51232/56940]\n",
      "loss: 0.292757  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.299346 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.318622  [   32/56940]\n",
      "loss: 0.279067  [ 3232/56940]\n",
      "loss: 0.286818  [ 6432/56940]\n",
      "loss: 0.385219  [ 9632/56940]\n",
      "loss: 0.326838  [12832/56940]\n",
      "loss: 0.243506  [16032/56940]\n",
      "loss: 0.427356  [19232/56940]\n",
      "loss: 0.234455  [22432/56940]\n",
      "loss: 0.310470  [25632/56940]\n",
      "loss: 0.289547  [28832/56940]\n",
      "loss: 0.206510  [32032/56940]\n",
      "loss: 0.340725  [35232/56940]\n",
      "loss: 0.247906  [38432/56940]\n",
      "loss: 0.314110  [41632/56940]\n",
      "loss: 0.407250  [44832/56940]\n",
      "loss: 0.289237  [48032/56940]\n",
      "loss: 0.258855  [51232/56940]\n",
      "loss: 0.284028  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.307595 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.278778  [   32/56940]\n",
      "loss: 0.221955  [ 3232/56940]\n",
      "loss: 0.359319  [ 6432/56940]\n",
      "loss: 0.251746  [ 9632/56940]\n",
      "loss: 0.428778  [12832/56940]\n",
      "loss: 0.362902  [16032/56940]\n",
      "loss: 0.424454  [19232/56940]\n",
      "loss: 0.344191  [22432/56940]\n",
      "loss: 0.402413  [25632/56940]\n",
      "loss: 0.239559  [28832/56940]\n",
      "loss: 0.464583  [32032/56940]\n",
      "loss: 0.304875  [35232/56940]\n",
      "loss: 0.280267  [38432/56940]\n",
      "loss: 0.150101  [41632/56940]\n",
      "loss: 0.231216  [44832/56940]\n",
      "loss: 0.192375  [48032/56940]\n",
      "loss: 0.333025  [51232/56940]\n",
      "loss: 0.277496  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.285452 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.256016  [   32/56940]\n",
      "loss: 0.242741  [ 3232/56940]\n",
      "loss: 0.173737  [ 6432/56940]\n",
      "loss: 0.294302  [ 9632/56940]\n",
      "loss: 0.280877  [12832/56940]\n",
      "loss: 0.442806  [16032/56940]\n",
      "loss: 0.222017  [19232/56940]\n",
      "loss: 0.344217  [22432/56940]\n",
      "loss: 0.270860  [25632/56940]\n",
      "loss: 0.420598  [28832/56940]\n",
      "loss: 0.366173  [32032/56940]\n",
      "loss: 0.462180  [35232/56940]\n",
      "loss: 0.416080  [38432/56940]\n",
      "loss: 0.234165  [41632/56940]\n",
      "loss: 0.210224  [44832/56940]\n",
      "loss: 0.349056  [48032/56940]\n",
      "loss: 0.333349  [51232/56940]\n",
      "loss: 0.459242  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.288191 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.324670  [   32/56940]\n",
      "loss: 0.279250  [ 3232/56940]\n",
      "loss: 0.374169  [ 6432/56940]\n",
      "loss: 0.311072  [ 9632/56940]\n",
      "loss: 0.412694  [12832/56940]\n",
      "loss: 0.316403  [16032/56940]\n",
      "loss: 0.544606  [19232/56940]\n",
      "loss: 0.259033  [22432/56940]\n",
      "loss: 0.437711  [25632/56940]\n",
      "loss: 0.392407  [28832/56940]\n",
      "loss: 0.244307  [32032/56940]\n",
      "loss: 0.162222  [35232/56940]\n",
      "loss: 0.215941  [38432/56940]\n",
      "loss: 0.530689  [41632/56940]\n",
      "loss: 0.346716  [44832/56940]\n",
      "loss: 0.599697  [48032/56940]\n",
      "loss: 0.198795  [51232/56940]\n",
      "loss: 0.481725  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.306863 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.200679  [   32/56940]\n",
      "loss: 0.303355  [ 3232/56940]\n",
      "loss: 0.372316  [ 6432/56940]\n",
      "loss: 0.560946  [ 9632/56940]\n",
      "loss: 0.109682  [12832/56940]\n",
      "loss: 0.248209  [16032/56940]\n",
      "loss: 0.324878  [19232/56940]\n",
      "loss: 0.514531  [22432/56940]\n",
      "loss: 0.313708  [25632/56940]\n",
      "loss: 0.181917  [28832/56940]\n",
      "loss: 0.155147  [32032/56940]\n",
      "loss: 0.342267  [35232/56940]\n",
      "loss: 0.501526  [38432/56940]\n",
      "loss: 0.448457  [41632/56940]\n",
      "loss: 0.293019  [44832/56940]\n",
      "loss: 0.546237  [48032/56940]\n",
      "loss: 0.392744  [51232/56940]\n",
      "loss: 0.212304  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.296260 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.233199  [   32/56940]\n",
      "loss: 0.400568  [ 3232/56940]\n",
      "loss: 0.266174  [ 6432/56940]\n",
      "loss: 0.334215  [ 9632/56940]\n",
      "loss: 0.394715  [12832/56940]\n",
      "loss: 0.309505  [16032/56940]\n",
      "loss: 0.353490  [19232/56940]\n",
      "loss: 0.251206  [22432/56940]\n",
      "loss: 0.272223  [25632/56940]\n",
      "loss: 0.260969  [28832/56940]\n",
      "loss: 0.214741  [32032/56940]\n",
      "loss: 0.338467  [35232/56940]\n",
      "loss: 0.508243  [38432/56940]\n",
      "loss: 0.402380  [41632/56940]\n",
      "loss: 0.327089  [44832/56940]\n",
      "loss: 0.282822  [48032/56940]\n",
      "loss: 0.360571  [51232/56940]\n",
      "loss: 0.379015  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.288217 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.349182  [   32/56940]\n",
      "loss: 0.399687  [ 3232/56940]\n",
      "loss: 0.319946  [ 6432/56940]\n",
      "loss: 0.316240  [ 9632/56940]\n",
      "loss: 0.265285  [12832/56940]\n",
      "loss: 0.316136  [16032/56940]\n",
      "loss: 0.232145  [19232/56940]\n",
      "loss: 0.371463  [22432/56940]\n",
      "loss: 0.327806  [25632/56940]\n",
      "loss: 0.467322  [28832/56940]\n",
      "loss: 0.173749  [32032/56940]\n",
      "loss: 0.306115  [35232/56940]\n",
      "loss: 0.384629  [38432/56940]\n",
      "loss: 0.202223  [41632/56940]\n",
      "loss: 0.321439  [44832/56940]\n",
      "loss: 0.334591  [48032/56940]\n",
      "loss: 0.317208  [51232/56940]\n",
      "loss: 0.394097  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.287490 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.237437  [   32/56940]\n",
      "loss: 0.332082  [ 3232/56940]\n",
      "loss: 0.447242  [ 6432/56940]\n",
      "loss: 0.291291  [ 9632/56940]\n",
      "loss: 0.327260  [12832/56940]\n",
      "loss: 0.787573  [16032/56940]\n",
      "loss: 0.428100  [19232/56940]\n",
      "loss: 0.464198  [22432/56940]\n",
      "loss: 0.526762  [25632/56940]\n",
      "loss: 0.379554  [28832/56940]\n",
      "loss: 0.234480  [32032/56940]\n",
      "loss: 0.260838  [35232/56940]\n",
      "loss: 0.495147  [38432/56940]\n",
      "loss: 0.272336  [41632/56940]\n",
      "loss: 0.329461  [44832/56940]\n",
      "loss: 0.433170  [48032/56940]\n",
      "loss: 0.182909  [51232/56940]\n",
      "loss: 0.395528  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.282711 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.394553  [   32/56940]\n",
      "loss: 0.285775  [ 3232/56940]\n",
      "loss: 0.331437  [ 6432/56940]\n",
      "loss: 0.216922  [ 9632/56940]\n",
      "loss: 0.193961  [12832/56940]\n",
      "loss: 0.245712  [16032/56940]\n",
      "loss: 0.209464  [19232/56940]\n",
      "loss: 0.324081  [22432/56940]\n",
      "loss: 0.623949  [25632/56940]\n",
      "loss: 0.204596  [28832/56940]\n",
      "loss: 0.364857  [32032/56940]\n",
      "loss: 0.297383  [35232/56940]\n",
      "loss: 0.236738  [38432/56940]\n",
      "loss: 0.429280  [41632/56940]\n",
      "loss: 0.280562  [44832/56940]\n",
      "loss: 0.246994  [48032/56940]\n",
      "loss: 0.451770  [51232/56940]\n",
      "loss: 0.224755  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.297782 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.386958  [   32/56940]\n",
      "loss: 0.196175  [ 3232/56940]\n",
      "loss: 0.175227  [ 6432/56940]\n",
      "loss: 0.282487  [ 9632/56940]\n",
      "loss: 0.518855  [12832/56940]\n",
      "loss: 0.246606  [16032/56940]\n",
      "loss: 0.171744  [19232/56940]\n",
      "loss: 0.280143  [22432/56940]\n",
      "loss: 0.280550  [25632/56940]\n",
      "loss: 0.477525  [28832/56940]\n",
      "loss: 0.257480  [32032/56940]\n",
      "loss: 0.405272  [35232/56940]\n",
      "loss: 0.386613  [38432/56940]\n",
      "loss: 0.195864  [41632/56940]\n",
      "loss: 0.450551  [44832/56940]\n",
      "loss: 0.511747  [48032/56940]\n",
      "loss: 0.337763  [51232/56940]\n",
      "loss: 0.420330  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.287402 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.491674  [   32/56940]\n",
      "loss: 0.228344  [ 3232/56940]\n",
      "loss: 0.276450  [ 6432/56940]\n",
      "loss: 0.379245  [ 9632/56940]\n",
      "loss: 0.244219  [12832/56940]\n",
      "loss: 0.404594  [16032/56940]\n",
      "loss: 0.201637  [19232/56940]\n",
      "loss: 0.364856  [22432/56940]\n",
      "loss: 0.184923  [25632/56940]\n",
      "loss: 0.263774  [28832/56940]\n",
      "loss: 0.264597  [32032/56940]\n",
      "loss: 0.373168  [35232/56940]\n",
      "loss: 0.267074  [38432/56940]\n",
      "loss: 0.300159  [41632/56940]\n",
      "loss: 0.286358  [44832/56940]\n",
      "loss: 0.256290  [48032/56940]\n",
      "loss: 0.166522  [51232/56940]\n",
      "loss: 0.262706  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.296146 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.252494  [   32/56940]\n",
      "loss: 0.451661  [ 3232/56940]\n",
      "loss: 0.503839  [ 6432/56940]\n",
      "loss: 0.236454  [ 9632/56940]\n",
      "loss: 0.251834  [12832/56940]\n",
      "loss: 0.261065  [16032/56940]\n",
      "loss: 0.217477  [19232/56940]\n",
      "loss: 0.352658  [22432/56940]\n",
      "loss: 0.198473  [25632/56940]\n",
      "loss: 0.296277  [28832/56940]\n",
      "loss: 0.319840  [32032/56940]\n",
      "loss: 0.270865  [35232/56940]\n",
      "loss: 0.251889  [38432/56940]\n",
      "loss: 0.399105  [41632/56940]\n",
      "loss: 0.484483  [44832/56940]\n",
      "loss: 0.270383  [48032/56940]\n",
      "loss: 0.355510  [51232/56940]\n",
      "loss: 0.336617  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.284754 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.436984  [   32/56940]\n",
      "loss: 0.273859  [ 3232/56940]\n",
      "loss: 0.304256  [ 6432/56940]\n",
      "loss: 0.263589  [ 9632/56940]\n",
      "loss: 0.458455  [12832/56940]\n",
      "loss: 0.279072  [16032/56940]\n",
      "loss: 0.254097  [19232/56940]\n",
      "loss: 0.377946  [22432/56940]\n",
      "loss: 0.141391  [25632/56940]\n",
      "loss: 0.260184  [28832/56940]\n",
      "loss: 0.287471  [32032/56940]\n",
      "loss: 0.481469  [35232/56940]\n",
      "loss: 0.241686  [38432/56940]\n",
      "loss: 0.277394  [41632/56940]\n",
      "loss: 0.193231  [44832/56940]\n",
      "loss: 0.238846  [48032/56940]\n",
      "loss: 0.353996  [51232/56940]\n",
      "loss: 0.262755  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.276592 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.367314  [   32/56940]\n",
      "loss: 0.340638  [ 3232/56940]\n",
      "loss: 0.270164  [ 6432/56940]\n",
      "loss: 0.160998  [ 9632/56940]\n",
      "loss: 0.170939  [12832/56940]\n",
      "loss: 0.276786  [16032/56940]\n",
      "loss: 0.312692  [19232/56940]\n",
      "loss: 0.306828  [22432/56940]\n",
      "loss: 0.363365  [25632/56940]\n",
      "loss: 0.346999  [28832/56940]\n",
      "loss: 0.374338  [32032/56940]\n",
      "loss: 0.364806  [35232/56940]\n",
      "loss: 0.252614  [38432/56940]\n",
      "loss: 0.212707  [41632/56940]\n",
      "loss: 0.493839  [44832/56940]\n",
      "loss: 0.268032  [48032/56940]\n",
      "loss: 0.229234  [51232/56940]\n",
      "loss: 0.270168  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.276958 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.306429  [   32/56940]\n",
      "loss: 0.227822  [ 3232/56940]\n",
      "loss: 0.362814  [ 6432/56940]\n",
      "loss: 0.473896  [ 9632/56940]\n",
      "loss: 0.334401  [12832/56940]\n",
      "loss: 0.342026  [16032/56940]\n",
      "loss: 0.203679  [19232/56940]\n",
      "loss: 0.301936  [22432/56940]\n",
      "loss: 0.279973  [25632/56940]\n",
      "loss: 0.262408  [28832/56940]\n",
      "loss: 0.202374  [32032/56940]\n",
      "loss: 0.179842  [35232/56940]\n",
      "loss: 0.320205  [38432/56940]\n",
      "loss: 0.300274  [41632/56940]\n",
      "loss: 0.319348  [44832/56940]\n",
      "loss: 0.250719  [48032/56940]\n",
      "loss: 0.239226  [51232/56940]\n",
      "loss: 0.358742  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.282089 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.202531  [   32/56940]\n",
      "loss: 0.307385  [ 3232/56940]\n",
      "loss: 0.402688  [ 6432/56940]\n",
      "loss: 0.238660  [ 9632/56940]\n",
      "loss: 0.229415  [12832/56940]\n",
      "loss: 0.276245  [16032/56940]\n",
      "loss: 0.383492  [19232/56940]\n",
      "loss: 0.170372  [22432/56940]\n",
      "loss: 0.150070  [25632/56940]\n",
      "loss: 0.379752  [28832/56940]\n",
      "loss: 0.555711  [32032/56940]\n",
      "loss: 0.307593  [35232/56940]\n",
      "loss: 0.315208  [38432/56940]\n",
      "loss: 0.326885  [41632/56940]\n",
      "loss: 0.383492  [44832/56940]\n",
      "loss: 0.464678  [48032/56940]\n",
      "loss: 0.329608  [51232/56940]\n",
      "loss: 0.302103  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.279814 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.378070  [   32/56940]\n",
      "loss: 0.201702  [ 3232/56940]\n",
      "loss: 0.325733  [ 6432/56940]\n",
      "loss: 0.292998  [ 9632/56940]\n",
      "loss: 0.302485  [12832/56940]\n",
      "loss: 0.299044  [16032/56940]\n",
      "loss: 0.607026  [19232/56940]\n",
      "loss: 0.259407  [22432/56940]\n",
      "loss: 0.252753  [25632/56940]\n",
      "loss: 0.176480  [28832/56940]\n",
      "loss: 0.533728  [32032/56940]\n",
      "loss: 0.247332  [35232/56940]\n",
      "loss: 0.160698  [38432/56940]\n",
      "loss: 0.342287  [41632/56940]\n",
      "loss: 0.381521  [44832/56940]\n",
      "loss: 0.348290  [48032/56940]\n",
      "loss: 0.191713  [51232/56940]\n",
      "loss: 0.240376  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.280823 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.391488  [   32/56940]\n",
      "loss: 0.254531  [ 3232/56940]\n",
      "loss: 0.548252  [ 6432/56940]\n",
      "loss: 0.278487  [ 9632/56940]\n",
      "loss: 0.342997  [12832/56940]\n",
      "loss: 0.356271  [16032/56940]\n",
      "loss: 0.366970  [19232/56940]\n",
      "loss: 0.352532  [22432/56940]\n",
      "loss: 0.323526  [25632/56940]\n",
      "loss: 0.385744  [28832/56940]\n",
      "loss: 0.349677  [32032/56940]\n",
      "loss: 0.227707  [35232/56940]\n",
      "loss: 0.333707  [38432/56940]\n",
      "loss: 0.315515  [41632/56940]\n",
      "loss: 0.239827  [44832/56940]\n",
      "loss: 0.259462  [48032/56940]\n",
      "loss: 0.386514  [51232/56940]\n",
      "loss: 0.491130  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.276924 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.208039  [   32/56940]\n",
      "loss: 0.464543  [ 3232/56940]\n",
      "loss: 0.337905  [ 6432/56940]\n",
      "loss: 0.374366  [ 9632/56940]\n",
      "loss: 0.342955  [12832/56940]\n",
      "loss: 0.363409  [16032/56940]\n",
      "loss: 0.288807  [19232/56940]\n",
      "loss: 0.278864  [22432/56940]\n",
      "loss: 0.339707  [25632/56940]\n",
      "loss: 0.397384  [28832/56940]\n",
      "loss: 0.489969  [32032/56940]\n",
      "loss: 0.224188  [35232/56940]\n",
      "loss: 0.387278  [38432/56940]\n",
      "loss: 0.183720  [41632/56940]\n",
      "loss: 0.258219  [44832/56940]\n",
      "loss: 0.497024  [48032/56940]\n",
      "loss: 0.211789  [51232/56940]\n",
      "loss: 0.325126  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.279922 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.231754  [   32/56940]\n",
      "loss: 0.401657  [ 3232/56940]\n",
      "loss: 0.223743  [ 6432/56940]\n",
      "loss: 0.189540  [ 9632/56940]\n",
      "loss: 0.376000  [12832/56940]\n",
      "loss: 0.300988  [16032/56940]\n",
      "loss: 0.272940  [19232/56940]\n",
      "loss: 0.252779  [22432/56940]\n",
      "loss: 0.241048  [25632/56940]\n",
      "loss: 0.357372  [28832/56940]\n",
      "loss: 0.357169  [32032/56940]\n",
      "loss: 0.396608  [35232/56940]\n",
      "loss: 0.420479  [38432/56940]\n",
      "loss: 0.272818  [41632/56940]\n",
      "loss: 0.258185  [44832/56940]\n",
      "loss: 0.233975  [48032/56940]\n",
      "loss: 0.332646  [51232/56940]\n",
      "loss: 0.218163  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.298047 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.218388  [   32/56940]\n",
      "loss: 0.163263  [ 3232/56940]\n",
      "loss: 0.603954  [ 6432/56940]\n",
      "loss: 0.536884  [ 9632/56940]\n",
      "loss: 0.272530  [12832/56940]\n",
      "loss: 0.378002  [16032/56940]\n",
      "loss: 0.248510  [19232/56940]\n",
      "loss: 0.272285  [22432/56940]\n",
      "loss: 0.347026  [25632/56940]\n",
      "loss: 0.486183  [28832/56940]\n",
      "loss: 0.397040  [32032/56940]\n",
      "loss: 0.206233  [35232/56940]\n",
      "loss: 0.386508  [38432/56940]\n",
      "loss: 0.337271  [41632/56940]\n",
      "loss: 0.281114  [44832/56940]\n",
      "loss: 0.246496  [48032/56940]\n",
      "loss: 0.481850  [51232/56940]\n",
      "loss: 0.211799  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.273035 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.315025  [   32/56940]\n",
      "loss: 0.196629  [ 3232/56940]\n",
      "loss: 0.305981  [ 6432/56940]\n",
      "loss: 0.454184  [ 9632/56940]\n",
      "loss: 0.353532  [12832/56940]\n",
      "loss: 0.406385  [16032/56940]\n",
      "loss: 0.322986  [19232/56940]\n",
      "loss: 0.207093  [22432/56940]\n",
      "loss: 0.534169  [25632/56940]\n",
      "loss: 0.188463  [28832/56940]\n",
      "loss: 0.272869  [32032/56940]\n",
      "loss: 0.235319  [35232/56940]\n",
      "loss: 0.285117  [38432/56940]\n",
      "loss: 0.331483  [41632/56940]\n",
      "loss: 0.338327  [44832/56940]\n",
      "loss: 0.234574  [48032/56940]\n",
      "loss: 0.231492  [51232/56940]\n",
      "loss: 0.140517  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.279826 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.323686  [   32/56940]\n",
      "loss: 0.277560  [ 3232/56940]\n",
      "loss: 0.537824  [ 6432/56940]\n",
      "loss: 0.293625  [ 9632/56940]\n",
      "loss: 0.342045  [12832/56940]\n",
      "loss: 0.370165  [16032/56940]\n",
      "loss: 0.338478  [19232/56940]\n",
      "loss: 0.211336  [22432/56940]\n",
      "loss: 0.343844  [25632/56940]\n",
      "loss: 0.586461  [28832/56940]\n",
      "loss: 0.337847  [32032/56940]\n",
      "loss: 0.340935  [35232/56940]\n",
      "loss: 0.227550  [38432/56940]\n",
      "loss: 0.282091  [41632/56940]\n",
      "loss: 0.236991  [44832/56940]\n",
      "loss: 0.322380  [48032/56940]\n",
      "loss: 0.208114  [51232/56940]\n",
      "loss: 0.685242  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.271122 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.234877  [   32/56940]\n",
      "loss: 0.230727  [ 3232/56940]\n",
      "loss: 0.442742  [ 6432/56940]\n",
      "loss: 0.177889  [ 9632/56940]\n",
      "loss: 0.368895  [12832/56940]\n",
      "loss: 0.297272  [16032/56940]\n",
      "loss: 0.258518  [19232/56940]\n",
      "loss: 0.424400  [22432/56940]\n",
      "loss: 0.201889  [25632/56940]\n",
      "loss: 0.366406  [28832/56940]\n",
      "loss: 0.394163  [32032/56940]\n",
      "loss: 0.295803  [35232/56940]\n",
      "loss: 0.284320  [38432/56940]\n",
      "loss: 0.247557  [41632/56940]\n",
      "loss: 0.334619  [44832/56940]\n",
      "loss: 0.272085  [48032/56940]\n",
      "loss: 0.315286  [51232/56940]\n",
      "loss: 0.359488  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.293353 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.284363  [   32/56940]\n",
      "loss: 0.347291  [ 3232/56940]\n",
      "loss: 0.284519  [ 6432/56940]\n",
      "loss: 0.296707  [ 9632/56940]\n",
      "loss: 0.178313  [12832/56940]\n",
      "loss: 0.297629  [16032/56940]\n",
      "loss: 0.322892  [19232/56940]\n",
      "loss: 0.328266  [22432/56940]\n",
      "loss: 0.185566  [25632/56940]\n",
      "loss: 0.438923  [28832/56940]\n",
      "loss: 0.281035  [32032/56940]\n",
      "loss: 0.220515  [35232/56940]\n",
      "loss: 0.544518  [38432/56940]\n",
      "loss: 0.319851  [41632/56940]\n",
      "loss: 0.320926  [44832/56940]\n",
      "loss: 0.264581  [48032/56940]\n",
      "loss: 0.296807  [51232/56940]\n",
      "loss: 0.293193  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.271937 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.371663  [   32/56940]\n",
      "loss: 0.247839  [ 3232/56940]\n",
      "loss: 0.195856  [ 6432/56940]\n",
      "loss: 0.431369  [ 9632/56940]\n",
      "loss: 0.313068  [12832/56940]\n",
      "loss: 0.270005  [16032/56940]\n",
      "loss: 0.386937  [19232/56940]\n",
      "loss: 0.422662  [22432/56940]\n",
      "loss: 0.160415  [25632/56940]\n",
      "loss: 0.493632  [28832/56940]\n",
      "loss: 0.375909  [32032/56940]\n",
      "loss: 0.285400  [35232/56940]\n",
      "loss: 0.247188  [38432/56940]\n",
      "loss: 0.326160  [41632/56940]\n",
      "loss: 0.324163  [44832/56940]\n",
      "loss: 0.203732  [48032/56940]\n",
      "loss: 0.208668  [51232/56940]\n",
      "loss: 0.419922  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.267468 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.217354  [   32/56940]\n",
      "loss: 0.356645  [ 3232/56940]\n",
      "loss: 0.295073  [ 6432/56940]\n",
      "loss: 0.460913  [ 9632/56940]\n",
      "loss: 0.201776  [12832/56940]\n",
      "loss: 0.184994  [16032/56940]\n",
      "loss: 0.242104  [19232/56940]\n",
      "loss: 0.505299  [22432/56940]\n",
      "loss: 0.479440  [25632/56940]\n",
      "loss: 0.335448  [28832/56940]\n",
      "loss: 0.291186  [32032/56940]\n",
      "loss: 0.222679  [35232/56940]\n",
      "loss: 0.423542  [38432/56940]\n",
      "loss: 0.266521  [41632/56940]\n",
      "loss: 0.285813  [44832/56940]\n",
      "loss: 0.186042  [48032/56940]\n",
      "loss: 0.305404  [51232/56940]\n",
      "loss: 0.176039  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.271388 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.188268  [   32/56940]\n",
      "loss: 0.480980  [ 3232/56940]\n",
      "loss: 0.216217  [ 6432/56940]\n",
      "loss: 0.231707  [ 9632/56940]\n",
      "loss: 0.183222  [12832/56940]\n",
      "loss: 0.287888  [16032/56940]\n",
      "loss: 0.235694  [19232/56940]\n",
      "loss: 0.233033  [22432/56940]\n",
      "loss: 0.467909  [25632/56940]\n",
      "loss: 0.340198  [28832/56940]\n",
      "loss: 0.332069  [32032/56940]\n",
      "loss: 0.511601  [35232/56940]\n",
      "loss: 0.397104  [38432/56940]\n",
      "loss: 0.266719  [41632/56940]\n",
      "loss: 0.406592  [44832/56940]\n",
      "loss: 0.224223  [48032/56940]\n",
      "loss: 0.272797  [51232/56940]\n",
      "loss: 0.237653  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.278649 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.389429  [   32/56940]\n",
      "loss: 0.331823  [ 3232/56940]\n",
      "loss: 0.409455  [ 6432/56940]\n",
      "loss: 0.329919  [ 9632/56940]\n",
      "loss: 0.382151  [12832/56940]\n",
      "loss: 0.314324  [16032/56940]\n",
      "loss: 0.215793  [19232/56940]\n",
      "loss: 0.244336  [22432/56940]\n",
      "loss: 0.196338  [25632/56940]\n",
      "loss: 0.258245  [28832/56940]\n",
      "loss: 0.203185  [32032/56940]\n",
      "loss: 0.370690  [35232/56940]\n",
      "loss: 0.394186  [38432/56940]\n",
      "loss: 0.342961  [41632/56940]\n",
      "loss: 0.443659  [44832/56940]\n",
      "loss: 0.416401  [48032/56940]\n",
      "loss: 0.351801  [51232/56940]\n",
      "loss: 0.527305  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.279416 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.296800  [   32/56940]\n",
      "loss: 0.243399  [ 3232/56940]\n",
      "loss: 0.466030  [ 6432/56940]\n",
      "loss: 0.467539  [ 9632/56940]\n",
      "loss: 0.449268  [12832/56940]\n",
      "loss: 0.249167  [16032/56940]\n",
      "loss: 0.379467  [19232/56940]\n",
      "loss: 0.365692  [22432/56940]\n",
      "loss: 0.239593  [25632/56940]\n",
      "loss: 0.403337  [28832/56940]\n",
      "loss: 0.414253  [32032/56940]\n",
      "loss: 0.249143  [35232/56940]\n",
      "loss: 0.490503  [38432/56940]\n",
      "loss: 0.370391  [41632/56940]\n",
      "loss: 0.242476  [44832/56940]\n",
      "loss: 0.273287  [48032/56940]\n",
      "loss: 0.276345  [51232/56940]\n",
      "loss: 0.299644  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.272399 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.260623  [   32/56940]\n",
      "loss: 0.410504  [ 3232/56940]\n",
      "loss: 0.320307  [ 6432/56940]\n",
      "loss: 0.574408  [ 9632/56940]\n",
      "loss: 0.218975  [12832/56940]\n",
      "loss: 0.167242  [16032/56940]\n",
      "loss: 0.556801  [19232/56940]\n",
      "loss: 0.228576  [22432/56940]\n",
      "loss: 0.204665  [25632/56940]\n",
      "loss: 0.282725  [28832/56940]\n",
      "loss: 0.201268  [32032/56940]\n",
      "loss: 0.206286  [35232/56940]\n",
      "loss: 0.302830  [38432/56940]\n",
      "loss: 0.155265  [41632/56940]\n",
      "loss: 0.268581  [44832/56940]\n",
      "loss: 0.399138  [48032/56940]\n",
      "loss: 0.236768  [51232/56940]\n",
      "loss: 0.374985  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.268960 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.267422  [   32/56940]\n",
      "loss: 0.322446  [ 3232/56940]\n",
      "loss: 0.393473  [ 6432/56940]\n",
      "loss: 0.280792  [ 9632/56940]\n",
      "loss: 0.327697  [12832/56940]\n",
      "loss: 0.281402  [16032/56940]\n",
      "loss: 0.389494  [19232/56940]\n",
      "loss: 0.260247  [22432/56940]\n",
      "loss: 0.562334  [25632/56940]\n",
      "loss: 0.342901  [28832/56940]\n",
      "loss: 0.371434  [32032/56940]\n",
      "loss: 0.197326  [35232/56940]\n",
      "loss: 0.217459  [38432/56940]\n",
      "loss: 0.259821  [41632/56940]\n",
      "loss: 0.421713  [44832/56940]\n",
      "loss: 0.448939  [48032/56940]\n",
      "loss: 0.286326  [51232/56940]\n",
      "loss: 0.320790  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.264252 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.263701  [   32/56940]\n",
      "loss: 0.317631  [ 3232/56940]\n",
      "loss: 0.177841  [ 6432/56940]\n",
      "loss: 0.309719  [ 9632/56940]\n",
      "loss: 0.192068  [12832/56940]\n",
      "loss: 0.355588  [16032/56940]\n",
      "loss: 0.182571  [19232/56940]\n",
      "loss: 0.284697  [22432/56940]\n",
      "loss: 0.524165  [25632/56940]\n",
      "loss: 0.250066  [28832/56940]\n",
      "loss: 0.402512  [32032/56940]\n",
      "loss: 0.552120  [35232/56940]\n",
      "loss: 0.455023  [38432/56940]\n",
      "loss: 0.184572  [41632/56940]\n",
      "loss: 0.254042  [44832/56940]\n",
      "loss: 0.197854  [48032/56940]\n",
      "loss: 0.470645  [51232/56940]\n",
      "loss: 0.277983  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.277868 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.253153  [   32/56940]\n",
      "loss: 0.240972  [ 3232/56940]\n",
      "loss: 0.244914  [ 6432/56940]\n",
      "loss: 0.302879  [ 9632/56940]\n",
      "loss: 0.593092  [12832/56940]\n",
      "loss: 0.132582  [16032/56940]\n",
      "loss: 0.213058  [19232/56940]\n",
      "loss: 0.283662  [22432/56940]\n",
      "loss: 0.490673  [25632/56940]\n",
      "loss: 0.405473  [28832/56940]\n",
      "loss: 0.387553  [32032/56940]\n",
      "loss: 0.363122  [35232/56940]\n",
      "loss: 0.271399  [38432/56940]\n",
      "loss: 0.516903  [41632/56940]\n",
      "loss: 0.280446  [44832/56940]\n",
      "loss: 0.354056  [48032/56940]\n",
      "loss: 0.184968  [51232/56940]\n",
      "loss: 0.220278  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.292065 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.393703  [   32/56940]\n",
      "loss: 0.177675  [ 3232/56940]\n",
      "loss: 0.358558  [ 6432/56940]\n",
      "loss: 0.179528  [ 9632/56940]\n",
      "loss: 0.206798  [12832/56940]\n",
      "loss: 0.242904  [16032/56940]\n",
      "loss: 0.393072  [19232/56940]\n",
      "loss: 0.340850  [22432/56940]\n",
      "loss: 0.221968  [25632/56940]\n",
      "loss: 0.274356  [28832/56940]\n",
      "loss: 0.418505  [32032/56940]\n",
      "loss: 0.482194  [35232/56940]\n",
      "loss: 0.295151  [38432/56940]\n",
      "loss: 0.443301  [41632/56940]\n",
      "loss: 0.219416  [44832/56940]\n",
      "loss: 0.186101  [48032/56940]\n",
      "loss: 0.203254  [51232/56940]\n",
      "loss: 0.167369  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.268696 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.309615  [   32/56940]\n",
      "loss: 0.274057  [ 3232/56940]\n",
      "loss: 0.474401  [ 6432/56940]\n",
      "loss: 0.412301  [ 9632/56940]\n",
      "loss: 0.362478  [12832/56940]\n",
      "loss: 0.189957  [16032/56940]\n",
      "loss: 0.158803  [19232/56940]\n",
      "loss: 0.407931  [22432/56940]\n",
      "loss: 0.518908  [25632/56940]\n",
      "loss: 0.494024  [28832/56940]\n",
      "loss: 0.196126  [32032/56940]\n",
      "loss: 0.610543  [35232/56940]\n",
      "loss: 0.364359  [38432/56940]\n",
      "loss: 0.295557  [41632/56940]\n",
      "loss: 0.184217  [44832/56940]\n",
      "loss: 0.312187  [48032/56940]\n",
      "loss: 0.372305  [51232/56940]\n",
      "loss: 0.223540  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.266791 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.245901  [   32/56940]\n",
      "loss: 0.159035  [ 3232/56940]\n",
      "loss: 0.256628  [ 6432/56940]\n",
      "loss: 0.360660  [ 9632/56940]\n",
      "loss: 0.183013  [12832/56940]\n",
      "loss: 0.334883  [16032/56940]\n",
      "loss: 0.287479  [19232/56940]\n",
      "loss: 0.222698  [22432/56940]\n",
      "loss: 0.401120  [25632/56940]\n",
      "loss: 0.311349  [28832/56940]\n",
      "loss: 0.197821  [32032/56940]\n",
      "loss: 0.243386  [35232/56940]\n",
      "loss: 0.262877  [38432/56940]\n",
      "loss: 0.491249  [41632/56940]\n",
      "loss: 0.441526  [44832/56940]\n",
      "loss: 0.342535  [48032/56940]\n",
      "loss: 0.283470  [51232/56940]\n",
      "loss: 0.456111  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.268058 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.365941  [   32/56940]\n",
      "loss: 0.273269  [ 3232/56940]\n",
      "loss: 0.536498  [ 6432/56940]\n",
      "loss: 0.374488  [ 9632/56940]\n",
      "loss: 0.386607  [12832/56940]\n",
      "loss: 0.176939  [16032/56940]\n",
      "loss: 0.328623  [19232/56940]\n",
      "loss: 0.400359  [22432/56940]\n",
      "loss: 0.289937  [25632/56940]\n",
      "loss: 0.427185  [28832/56940]\n",
      "loss: 0.214536  [32032/56940]\n",
      "loss: 0.575773  [35232/56940]\n",
      "loss: 0.396606  [38432/56940]\n",
      "loss: 0.251561  [41632/56940]\n",
      "loss: 0.268108  [44832/56940]\n",
      "loss: 0.318404  [48032/56940]\n",
      "loss: 0.376417  [51232/56940]\n",
      "loss: 0.276084  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.269658 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.389633  [   32/56940]\n",
      "loss: 0.491001  [ 3232/56940]\n",
      "loss: 0.585919  [ 6432/56940]\n",
      "loss: 0.252429  [ 9632/56940]\n",
      "loss: 0.323953  [12832/56940]\n",
      "loss: 0.245821  [16032/56940]\n",
      "loss: 0.392303  [19232/56940]\n",
      "loss: 0.212952  [22432/56940]\n",
      "loss: 0.393919  [25632/56940]\n",
      "loss: 0.360256  [28832/56940]\n",
      "loss: 0.246706  [32032/56940]\n",
      "loss: 0.317547  [35232/56940]\n",
      "loss: 0.189098  [38432/56940]\n",
      "loss: 0.270030  [41632/56940]\n",
      "loss: 0.256134  [44832/56940]\n",
      "loss: 0.260127  [48032/56940]\n",
      "loss: 0.294274  [51232/56940]\n",
      "loss: 0.133654  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.265285 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.194112  [   32/56940]\n",
      "loss: 0.357351  [ 3232/56940]\n",
      "loss: 0.451727  [ 6432/56940]\n",
      "loss: 0.605517  [ 9632/56940]\n",
      "loss: 0.275201  [12832/56940]\n",
      "loss: 0.320360  [16032/56940]\n",
      "loss: 0.249733  [19232/56940]\n",
      "loss: 0.481912  [22432/56940]\n",
      "loss: 0.275123  [25632/56940]\n",
      "loss: 0.261189  [28832/56940]\n",
      "loss: 0.367532  [32032/56940]\n",
      "loss: 0.632377  [35232/56940]\n",
      "loss: 0.455912  [38432/56940]\n",
      "loss: 0.354492  [41632/56940]\n",
      "loss: 0.352741  [44832/56940]\n",
      "loss: 0.354491  [48032/56940]\n",
      "loss: 0.286360  [51232/56940]\n",
      "loss: 0.244658  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.265292 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.362125  [   32/56940]\n",
      "loss: 0.572089  [ 3232/56940]\n",
      "loss: 0.236626  [ 6432/56940]\n",
      "loss: 0.396070  [ 9632/56940]\n",
      "loss: 0.325718  [12832/56940]\n",
      "loss: 0.351805  [16032/56940]\n",
      "loss: 0.407070  [19232/56940]\n",
      "loss: 0.296192  [22432/56940]\n",
      "loss: 0.313091  [25632/56940]\n",
      "loss: 0.477485  [28832/56940]\n",
      "loss: 0.428596  [32032/56940]\n",
      "loss: 0.386092  [35232/56940]\n",
      "loss: 0.189076  [38432/56940]\n",
      "loss: 0.368367  [41632/56940]\n",
      "loss: 0.304525  [44832/56940]\n",
      "loss: 0.237272  [48032/56940]\n",
      "loss: 0.172525  [51232/56940]\n",
      "loss: 0.347476  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.276825 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.264246  [   32/56940]\n",
      "loss: 0.194123  [ 3232/56940]\n",
      "loss: 0.208645  [ 6432/56940]\n",
      "loss: 0.310386  [ 9632/56940]\n",
      "loss: 0.396932  [12832/56940]\n",
      "loss: 0.166074  [16032/56940]\n",
      "loss: 0.308034  [19232/56940]\n",
      "loss: 0.418725  [22432/56940]\n",
      "loss: 0.737115  [25632/56940]\n",
      "loss: 0.179295  [28832/56940]\n",
      "loss: 0.256259  [32032/56940]\n",
      "loss: 0.188245  [35232/56940]\n",
      "loss: 0.312603  [38432/56940]\n",
      "loss: 0.244656  [41632/56940]\n",
      "loss: 0.536565  [44832/56940]\n",
      "loss: 0.178878  [48032/56940]\n",
      "loss: 0.184705  [51232/56940]\n",
      "loss: 0.199051  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.266133 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.287939  [   32/56940]\n",
      "loss: 0.241624  [ 3232/56940]\n",
      "loss: 0.244334  [ 6432/56940]\n",
      "loss: 0.330708  [ 9632/56940]\n",
      "loss: 0.308437  [12832/56940]\n",
      "loss: 0.277206  [16032/56940]\n",
      "loss: 0.292943  [19232/56940]\n",
      "loss: 0.287852  [22432/56940]\n",
      "loss: 0.280484  [25632/56940]\n",
      "loss: 0.474445  [28832/56940]\n",
      "loss: 0.273693  [32032/56940]\n",
      "loss: 0.333339  [35232/56940]\n",
      "loss: 0.425551  [38432/56940]\n",
      "loss: 0.341410  [41632/56940]\n",
      "loss: 0.309835  [44832/56940]\n",
      "loss: 0.236085  [48032/56940]\n",
      "loss: 0.160325  [51232/56940]\n",
      "loss: 0.297865  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.276816 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.125336  [   32/56940]\n",
      "loss: 0.353227  [ 3232/56940]\n",
      "loss: 0.306226  [ 6432/56940]\n",
      "loss: 0.341543  [ 9632/56940]\n",
      "loss: 0.252453  [12832/56940]\n",
      "loss: 0.263861  [16032/56940]\n",
      "loss: 0.252345  [19232/56940]\n",
      "loss: 0.260565  [22432/56940]\n",
      "loss: 0.347245  [25632/56940]\n",
      "loss: 0.345181  [28832/56940]\n",
      "loss: 0.223772  [32032/56940]\n",
      "loss: 0.279184  [35232/56940]\n",
      "loss: 0.407369  [38432/56940]\n",
      "loss: 0.249992  [41632/56940]\n",
      "loss: 0.209100  [44832/56940]\n",
      "loss: 0.171994  [48032/56940]\n",
      "loss: 0.165233  [51232/56940]\n",
      "loss: 0.323365  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.279843 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.495492  [   32/56940]\n",
      "loss: 0.327256  [ 3232/56940]\n",
      "loss: 0.301314  [ 6432/56940]\n",
      "loss: 0.543667  [ 9632/56940]\n",
      "loss: 0.197218  [12832/56940]\n",
      "loss: 0.379499  [16032/56940]\n",
      "loss: 0.282402  [19232/56940]\n",
      "loss: 0.197360  [22432/56940]\n",
      "loss: 0.205046  [25632/56940]\n",
      "loss: 0.339394  [28832/56940]\n",
      "loss: 0.240993  [32032/56940]\n",
      "loss: 0.295530  [35232/56940]\n",
      "loss: 0.162216  [38432/56940]\n",
      "loss: 0.306610  [41632/56940]\n",
      "loss: 0.219848  [44832/56940]\n",
      "loss: 0.585789  [48032/56940]\n",
      "loss: 0.263126  [51232/56940]\n",
      "loss: 0.308427  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.260301 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.222084  [   32/56940]\n",
      "loss: 0.306552  [ 3232/56940]\n",
      "loss: 0.160506  [ 6432/56940]\n",
      "loss: 0.415101  [ 9632/56940]\n",
      "loss: 0.314662  [12832/56940]\n",
      "loss: 0.203735  [16032/56940]\n",
      "loss: 0.349910  [19232/56940]\n",
      "loss: 0.168840  [22432/56940]\n",
      "loss: 0.213710  [25632/56940]\n",
      "loss: 0.254701  [28832/56940]\n",
      "loss: 0.327238  [32032/56940]\n",
      "loss: 0.316601  [35232/56940]\n",
      "loss: 0.161523  [38432/56940]\n",
      "loss: 0.299087  [41632/56940]\n",
      "loss: 0.218939  [44832/56940]\n",
      "loss: 0.288787  [48032/56940]\n",
      "loss: 0.233986  [51232/56940]\n",
      "loss: 0.366719  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.274333 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.291849  [   32/56940]\n",
      "loss: 0.390431  [ 3232/56940]\n",
      "loss: 0.440565  [ 6432/56940]\n",
      "loss: 0.375475  [ 9632/56940]\n",
      "loss: 0.398792  [12832/56940]\n",
      "loss: 0.321825  [16032/56940]\n",
      "loss: 0.238754  [19232/56940]\n",
      "loss: 0.303291  [22432/56940]\n",
      "loss: 0.398318  [25632/56940]\n",
      "loss: 0.366810  [28832/56940]\n",
      "loss: 0.333317  [32032/56940]\n",
      "loss: 0.305379  [35232/56940]\n",
      "loss: 0.346012  [38432/56940]\n",
      "loss: 0.248578  [41632/56940]\n",
      "loss: 0.245771  [44832/56940]\n",
      "loss: 0.318527  [48032/56940]\n",
      "loss: 0.514388  [51232/56940]\n",
      "loss: 0.376916  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.260035 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.404600  [   32/56940]\n",
      "loss: 0.359168  [ 3232/56940]\n",
      "loss: 0.274080  [ 6432/56940]\n",
      "loss: 0.323508  [ 9632/56940]\n",
      "loss: 0.325122  [12832/56940]\n",
      "loss: 0.228124  [16032/56940]\n",
      "loss: 0.387293  [19232/56940]\n",
      "loss: 0.192457  [22432/56940]\n",
      "loss: 0.457521  [25632/56940]\n",
      "loss: 0.196192  [28832/56940]\n",
      "loss: 0.331828  [32032/56940]\n",
      "loss: 0.329221  [35232/56940]\n",
      "loss: 0.140033  [38432/56940]\n",
      "loss: 0.406200  [41632/56940]\n",
      "loss: 0.674275  [44832/56940]\n",
      "loss: 0.211125  [48032/56940]\n",
      "loss: 0.346987  [51232/56940]\n",
      "loss: 0.227930  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.257338 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.159948  [   32/56940]\n",
      "loss: 0.306652  [ 3232/56940]\n",
      "loss: 0.203117  [ 6432/56940]\n",
      "loss: 0.302867  [ 9632/56940]\n",
      "loss: 0.225865  [12832/56940]\n",
      "loss: 0.264346  [16032/56940]\n",
      "loss: 0.156261  [19232/56940]\n",
      "loss: 0.566291  [22432/56940]\n",
      "loss: 0.308214  [25632/56940]\n",
      "loss: 0.360726  [28832/56940]\n",
      "loss: 0.308581  [32032/56940]\n",
      "loss: 0.360790  [35232/56940]\n",
      "loss: 0.166681  [38432/56940]\n",
      "loss: 0.535326  [41632/56940]\n",
      "loss: 0.424291  [44832/56940]\n",
      "loss: 0.156427  [48032/56940]\n",
      "loss: 0.231261  [51232/56940]\n",
      "loss: 0.259734  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.262440 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.321233  [   32/56940]\n",
      "loss: 0.308948  [ 3232/56940]\n",
      "loss: 0.306187  [ 6432/56940]\n",
      "loss: 0.211670  [ 9632/56940]\n",
      "loss: 0.304739  [12832/56940]\n",
      "loss: 0.242522  [16032/56940]\n",
      "loss: 0.327049  [19232/56940]\n",
      "loss: 0.248298  [22432/56940]\n",
      "loss: 0.289634  [25632/56940]\n",
      "loss: 0.375523  [28832/56940]\n",
      "loss: 0.339059  [32032/56940]\n",
      "loss: 0.343556  [35232/56940]\n",
      "loss: 0.279085  [38432/56940]\n",
      "loss: 0.361680  [41632/56940]\n",
      "loss: 0.151611  [44832/56940]\n",
      "loss: 0.305478  [48032/56940]\n",
      "loss: 0.438523  [51232/56940]\n",
      "loss: 0.190214  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.259334 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.227511  [   32/56940]\n",
      "loss: 0.501961  [ 3232/56940]\n",
      "loss: 0.297280  [ 6432/56940]\n",
      "loss: 0.369559  [ 9632/56940]\n",
      "loss: 0.287914  [12832/56940]\n",
      "loss: 0.220797  [16032/56940]\n",
      "loss: 0.224748  [19232/56940]\n",
      "loss: 0.330492  [22432/56940]\n",
      "loss: 0.211910  [25632/56940]\n",
      "loss: 0.209200  [28832/56940]\n",
      "loss: 0.210019  [32032/56940]\n",
      "loss: 0.256226  [35232/56940]\n",
      "loss: 0.254760  [38432/56940]\n",
      "loss: 0.286680  [41632/56940]\n",
      "loss: 0.315825  [44832/56940]\n",
      "loss: 0.250444  [48032/56940]\n",
      "loss: 0.239016  [51232/56940]\n",
      "loss: 0.137806  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.263981 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.271172  [   32/56940]\n",
      "loss: 0.298088  [ 3232/56940]\n",
      "loss: 0.283290  [ 6432/56940]\n",
      "loss: 0.249783  [ 9632/56940]\n",
      "loss: 0.238865  [12832/56940]\n",
      "loss: 0.523472  [16032/56940]\n",
      "loss: 0.526223  [19232/56940]\n",
      "loss: 0.292790  [22432/56940]\n",
      "loss: 0.170901  [25632/56940]\n",
      "loss: 0.177348  [28832/56940]\n",
      "loss: 0.288124  [32032/56940]\n",
      "loss: 0.376978  [35232/56940]\n",
      "loss: 0.226230  [38432/56940]\n",
      "loss: 0.215346  [41632/56940]\n",
      "loss: 0.207224  [44832/56940]\n",
      "loss: 0.252719  [48032/56940]\n",
      "loss: 0.336920  [51232/56940]\n",
      "loss: 0.425357  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.273383 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.258996  [   32/56940]\n",
      "loss: 0.455293  [ 3232/56940]\n",
      "loss: 0.320385  [ 6432/56940]\n",
      "loss: 0.317077  [ 9632/56940]\n",
      "loss: 0.334960  [12832/56940]\n",
      "loss: 0.290187  [16032/56940]\n",
      "loss: 0.175405  [19232/56940]\n",
      "loss: 0.364201  [22432/56940]\n",
      "loss: 0.264072  [25632/56940]\n",
      "loss: 0.231661  [28832/56940]\n",
      "loss: 0.381895  [32032/56940]\n",
      "loss: 0.306968  [35232/56940]\n",
      "loss: 0.208198  [38432/56940]\n",
      "loss: 0.236629  [41632/56940]\n",
      "loss: 0.422120  [44832/56940]\n",
      "loss: 0.239508  [48032/56940]\n",
      "loss: 0.294028  [51232/56940]\n",
      "loss: 0.408441  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.262522 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.171581  [   32/56940]\n",
      "loss: 0.348122  [ 3232/56940]\n",
      "loss: 0.362384  [ 6432/56940]\n",
      "loss: 0.267053  [ 9632/56940]\n",
      "loss: 0.186850  [12832/56940]\n",
      "loss: 0.255153  [16032/56940]\n",
      "loss: 0.244033  [19232/56940]\n",
      "loss: 0.276888  [22432/56940]\n",
      "loss: 0.270974  [25632/56940]\n",
      "loss: 0.458511  [28832/56940]\n",
      "loss: 0.267014  [32032/56940]\n",
      "loss: 0.197348  [35232/56940]\n",
      "loss: 0.240798  [38432/56940]\n",
      "loss: 0.249449  [41632/56940]\n",
      "loss: 0.399899  [44832/56940]\n",
      "loss: 0.498154  [48032/56940]\n",
      "loss: 0.261979  [51232/56940]\n",
      "loss: 0.348545  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.257023 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.338225  [   32/56940]\n",
      "loss: 0.353121  [ 3232/56940]\n",
      "loss: 0.226181  [ 6432/56940]\n",
      "loss: 0.185083  [ 9632/56940]\n",
      "loss: 0.196576  [12832/56940]\n",
      "loss: 0.239688  [16032/56940]\n",
      "loss: 0.242447  [19232/56940]\n",
      "loss: 0.264758  [22432/56940]\n",
      "loss: 0.198551  [25632/56940]\n",
      "loss: 0.402111  [28832/56940]\n",
      "loss: 0.262732  [32032/56940]\n",
      "loss: 0.319234  [35232/56940]\n",
      "loss: 0.340669  [38432/56940]\n",
      "loss: 0.294116  [41632/56940]\n",
      "loss: 0.214074  [44832/56940]\n",
      "loss: 0.227773  [48032/56940]\n",
      "loss: 0.254916  [51232/56940]\n",
      "loss: 0.308582  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.255216 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.424043  [   32/56940]\n",
      "loss: 0.295730  [ 3232/56940]\n",
      "loss: 0.215834  [ 6432/56940]\n",
      "loss: 0.460925  [ 9632/56940]\n",
      "loss: 0.300775  [12832/56940]\n",
      "loss: 0.304241  [16032/56940]\n",
      "loss: 0.159121  [19232/56940]\n",
      "loss: 0.354392  [22432/56940]\n",
      "loss: 0.291495  [25632/56940]\n",
      "loss: 0.367696  [28832/56940]\n",
      "loss: 0.196291  [32032/56940]\n",
      "loss: 0.244414  [35232/56940]\n",
      "loss: 0.254276  [38432/56940]\n",
      "loss: 0.145157  [41632/56940]\n",
      "loss: 0.109055  [44832/56940]\n",
      "loss: 0.173740  [48032/56940]\n",
      "loss: 0.203280  [51232/56940]\n",
      "loss: 0.446246  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.260104 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.597735  [   32/56940]\n",
      "loss: 0.407028  [ 3232/56940]\n",
      "loss: 0.126518  [ 6432/56940]\n",
      "loss: 0.175194  [ 9632/56940]\n",
      "loss: 0.298500  [12832/56940]\n",
      "loss: 0.139039  [16032/56940]\n",
      "loss: 0.354922  [19232/56940]\n",
      "loss: 0.256798  [22432/56940]\n",
      "loss: 0.332268  [25632/56940]\n",
      "loss: 0.530037  [28832/56940]\n",
      "loss: 0.312696  [32032/56940]\n",
      "loss: 0.361524  [35232/56940]\n",
      "loss: 0.219817  [38432/56940]\n",
      "loss: 0.268106  [41632/56940]\n",
      "loss: 0.573588  [44832/56940]\n",
      "loss: 0.309706  [48032/56940]\n",
      "loss: 0.348537  [51232/56940]\n",
      "loss: 0.139924  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.275553 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.257243  [   32/56940]\n",
      "loss: 0.307478  [ 3232/56940]\n",
      "loss: 0.168920  [ 6432/56940]\n",
      "loss: 0.328909  [ 9632/56940]\n",
      "loss: 0.235109  [12832/56940]\n",
      "loss: 0.251999  [16032/56940]\n",
      "loss: 0.303278  [19232/56940]\n",
      "loss: 0.237903  [22432/56940]\n",
      "loss: 0.684268  [25632/56940]\n",
      "loss: 0.459514  [28832/56940]\n",
      "loss: 0.164995  [32032/56940]\n",
      "loss: 0.360039  [35232/56940]\n",
      "loss: 0.199144  [38432/56940]\n",
      "loss: 0.244172  [41632/56940]\n",
      "loss: 0.239142  [44832/56940]\n",
      "loss: 0.207884  [48032/56940]\n",
      "loss: 0.314989  [51232/56940]\n",
      "loss: 0.351397  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.258864 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.239797  [   32/56940]\n",
      "loss: 0.225583  [ 3232/56940]\n",
      "loss: 0.219968  [ 6432/56940]\n",
      "loss: 0.381451  [ 9632/56940]\n",
      "loss: 0.335933  [12832/56940]\n",
      "loss: 0.416005  [16032/56940]\n",
      "loss: 0.232712  [19232/56940]\n",
      "loss: 0.463954  [22432/56940]\n",
      "loss: 0.195610  [25632/56940]\n",
      "loss: 0.374703  [28832/56940]\n",
      "loss: 0.214969  [32032/56940]\n",
      "loss: 0.326124  [35232/56940]\n",
      "loss: 0.292319  [38432/56940]\n",
      "loss: 0.293132  [41632/56940]\n",
      "loss: 0.268525  [44832/56940]\n",
      "loss: 0.327480  [48032/56940]\n",
      "loss: 0.276300  [51232/56940]\n",
      "loss: 0.350182  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.251963 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.197211  [   32/56940]\n",
      "loss: 0.163415  [ 3232/56940]\n",
      "loss: 0.297120  [ 6432/56940]\n",
      "loss: 0.121745  [ 9632/56940]\n",
      "loss: 0.217652  [12832/56940]\n",
      "loss: 0.398158  [16032/56940]\n",
      "loss: 0.291372  [19232/56940]\n",
      "loss: 0.272455  [22432/56940]\n",
      "loss: 0.171831  [25632/56940]\n",
      "loss: 0.166253  [28832/56940]\n",
      "loss: 0.191440  [32032/56940]\n",
      "loss: 0.301128  [35232/56940]\n",
      "loss: 0.342225  [38432/56940]\n",
      "loss: 0.237918  [41632/56940]\n",
      "loss: 0.415179  [44832/56940]\n",
      "loss: 0.269477  [48032/56940]\n",
      "loss: 0.256957  [51232/56940]\n",
      "loss: 0.204587  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.260709 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.309287  [   32/56940]\n",
      "loss: 0.184765  [ 3232/56940]\n",
      "loss: 0.330905  [ 6432/56940]\n",
      "loss: 0.209175  [ 9632/56940]\n",
      "loss: 0.454538  [12832/56940]\n",
      "loss: 0.275012  [16032/56940]\n",
      "loss: 0.461171  [19232/56940]\n",
      "loss: 0.263293  [22432/56940]\n",
      "loss: 0.400174  [25632/56940]\n",
      "loss: 0.191819  [28832/56940]\n",
      "loss: 0.118021  [32032/56940]\n",
      "loss: 0.233141  [35232/56940]\n",
      "loss: 0.146835  [38432/56940]\n",
      "loss: 0.259996  [41632/56940]\n",
      "loss: 0.449547  [44832/56940]\n",
      "loss: 0.487277  [48032/56940]\n",
      "loss: 0.416608  [51232/56940]\n",
      "loss: 0.484074  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.251693 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.222098  [   32/56940]\n",
      "loss: 0.271013  [ 3232/56940]\n",
      "loss: 0.238485  [ 6432/56940]\n",
      "loss: 0.244859  [ 9632/56940]\n",
      "loss: 0.244463  [12832/56940]\n",
      "loss: 0.142540  [16032/56940]\n",
      "loss: 0.230096  [19232/56940]\n",
      "loss: 0.208384  [22432/56940]\n",
      "loss: 0.174299  [25632/56940]\n",
      "loss: 0.266936  [28832/56940]\n",
      "loss: 0.245495  [32032/56940]\n",
      "loss: 0.236608  [35232/56940]\n",
      "loss: 0.196551  [38432/56940]\n",
      "loss: 0.465524  [41632/56940]\n",
      "loss: 0.308196  [44832/56940]\n",
      "loss: 0.237714  [48032/56940]\n",
      "loss: 0.296596  [51232/56940]\n",
      "loss: 0.350700  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.261477 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.197720  [   32/56940]\n",
      "loss: 0.274116  [ 3232/56940]\n",
      "loss: 0.463879  [ 6432/56940]\n",
      "loss: 0.318076  [ 9632/56940]\n",
      "loss: 0.230717  [12832/56940]\n",
      "loss: 0.319238  [16032/56940]\n",
      "loss: 0.222590  [19232/56940]\n",
      "loss: 0.296479  [22432/56940]\n",
      "loss: 0.270559  [25632/56940]\n",
      "loss: 0.196071  [28832/56940]\n",
      "loss: 0.312642  [32032/56940]\n",
      "loss: 0.188315  [35232/56940]\n",
      "loss: 0.185454  [38432/56940]\n",
      "loss: 0.110458  [41632/56940]\n",
      "loss: 0.330986  [44832/56940]\n",
      "loss: 0.261639  [48032/56940]\n",
      "loss: 0.388744  [51232/56940]\n",
      "loss: 0.192506  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.253408 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.187867  [   32/56940]\n",
      "loss: 0.260050  [ 3232/56940]\n",
      "loss: 0.341284  [ 6432/56940]\n",
      "loss: 0.313607  [ 9632/56940]\n",
      "loss: 0.253631  [12832/56940]\n",
      "loss: 0.208457  [16032/56940]\n",
      "loss: 0.297484  [19232/56940]\n",
      "loss: 0.303816  [22432/56940]\n",
      "loss: 0.205464  [25632/56940]\n",
      "loss: 0.227643  [28832/56940]\n",
      "loss: 0.332445  [32032/56940]\n",
      "loss: 0.215357  [35232/56940]\n",
      "loss: 0.369663  [38432/56940]\n",
      "loss: 0.132512  [41632/56940]\n",
      "loss: 0.252922  [44832/56940]\n",
      "loss: 0.256851  [48032/56940]\n",
      "loss: 0.260415  [51232/56940]\n",
      "loss: 0.207096  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.253980 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.212669  [   32/56940]\n",
      "loss: 0.215174  [ 3232/56940]\n",
      "loss: 0.322132  [ 6432/56940]\n",
      "loss: 0.226313  [ 9632/56940]\n",
      "loss: 0.196639  [12832/56940]\n",
      "loss: 0.253819  [16032/56940]\n",
      "loss: 0.241112  [19232/56940]\n",
      "loss: 0.459946  [22432/56940]\n",
      "loss: 0.402788  [25632/56940]\n",
      "loss: 0.238620  [28832/56940]\n",
      "loss: 0.212895  [32032/56940]\n",
      "loss: 0.276363  [35232/56940]\n",
      "loss: 0.409674  [38432/56940]\n",
      "loss: 0.262272  [41632/56940]\n",
      "loss: 0.125746  [44832/56940]\n",
      "loss: 0.218522  [48032/56940]\n",
      "loss: 0.207909  [51232/56940]\n",
      "loss: 0.170318  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.254717 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.162523  [   32/56940]\n",
      "loss: 0.375184  [ 3232/56940]\n",
      "loss: 0.290866  [ 6432/56940]\n",
      "loss: 0.306802  [ 9632/56940]\n",
      "loss: 0.346091  [12832/56940]\n",
      "loss: 0.268306  [16032/56940]\n",
      "loss: 0.308378  [19232/56940]\n",
      "loss: 0.346077  [22432/56940]\n",
      "loss: 0.526159  [25632/56940]\n",
      "loss: 0.330817  [28832/56940]\n",
      "loss: 0.193517  [32032/56940]\n",
      "loss: 0.195595  [35232/56940]\n",
      "loss: 0.331627  [38432/56940]\n",
      "loss: 0.386852  [41632/56940]\n",
      "loss: 0.206566  [44832/56940]\n",
      "loss: 0.262089  [48032/56940]\n",
      "loss: 0.329873  [51232/56940]\n",
      "loss: 0.334495  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.258205 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.477843  [   32/56940]\n",
      "loss: 0.349746  [ 3232/56940]\n",
      "loss: 0.273686  [ 6432/56940]\n",
      "loss: 0.349912  [ 9632/56940]\n",
      "loss: 0.416617  [12832/56940]\n",
      "loss: 0.772332  [16032/56940]\n",
      "loss: 0.345389  [19232/56940]\n",
      "loss: 0.237828  [22432/56940]\n",
      "loss: 0.250496  [25632/56940]\n",
      "loss: 0.298512  [28832/56940]\n",
      "loss: 0.242650  [32032/56940]\n",
      "loss: 0.243822  [35232/56940]\n",
      "loss: 0.198355  [38432/56940]\n",
      "loss: 0.221644  [41632/56940]\n",
      "loss: 0.320509  [44832/56940]\n",
      "loss: 0.354785  [48032/56940]\n",
      "loss: 0.346974  [51232/56940]\n",
      "loss: 0.371882  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.252698 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.142024  [   32/56940]\n",
      "loss: 0.196116  [ 3232/56940]\n",
      "loss: 0.243031  [ 6432/56940]\n",
      "loss: 0.501700  [ 9632/56940]\n",
      "loss: 0.256510  [12832/56940]\n",
      "loss: 0.395421  [16032/56940]\n",
      "loss: 0.397872  [19232/56940]\n",
      "loss: 0.284837  [22432/56940]\n",
      "loss: 0.327453  [25632/56940]\n",
      "loss: 0.310820  [28832/56940]\n",
      "loss: 0.315737  [32032/56940]\n",
      "loss: 0.282023  [35232/56940]\n",
      "loss: 0.347225  [38432/56940]\n",
      "loss: 0.425967  [41632/56940]\n",
      "loss: 0.180694  [44832/56940]\n",
      "loss: 0.288971  [48032/56940]\n",
      "loss: 0.183015  [51232/56940]\n",
      "loss: 0.652212  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.258461 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.185831  [   32/56940]\n",
      "loss: 0.157688  [ 3232/56940]\n",
      "loss: 0.220669  [ 6432/56940]\n",
      "loss: 0.341006  [ 9632/56940]\n",
      "loss: 0.245380  [12832/56940]\n",
      "loss: 0.465628  [16032/56940]\n",
      "loss: 0.366734  [19232/56940]\n",
      "loss: 0.140083  [22432/56940]\n",
      "loss: 0.392604  [25632/56940]\n",
      "loss: 0.277609  [28832/56940]\n",
      "loss: 0.342407  [32032/56940]\n",
      "loss: 0.394439  [35232/56940]\n",
      "loss: 0.230119  [38432/56940]\n",
      "loss: 0.201629  [41632/56940]\n",
      "loss: 0.280821  [44832/56940]\n",
      "loss: 0.308056  [48032/56940]\n",
      "loss: 0.331759  [51232/56940]\n",
      "loss: 0.157483  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.252843 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.186461  [   32/56940]\n",
      "loss: 0.235021  [ 3232/56940]\n",
      "loss: 0.176896  [ 6432/56940]\n",
      "loss: 0.223838  [ 9632/56940]\n",
      "loss: 0.340954  [12832/56940]\n",
      "loss: 0.301943  [16032/56940]\n",
      "loss: 0.336020  [19232/56940]\n",
      "loss: 0.236697  [22432/56940]\n",
      "loss: 0.183365  [25632/56940]\n",
      "loss: 0.136920  [28832/56940]\n",
      "loss: 0.430113  [32032/56940]\n",
      "loss: 0.313962  [35232/56940]\n",
      "loss: 0.180845  [38432/56940]\n",
      "loss: 0.551463  [41632/56940]\n",
      "loss: 0.308206  [44832/56940]\n",
      "loss: 0.349571  [48032/56940]\n",
      "loss: 0.340666  [51232/56940]\n",
      "loss: 0.359315  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.251513 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.282711  [   32/56940]\n",
      "loss: 0.447601  [ 3232/56940]\n",
      "loss: 0.374609  [ 6432/56940]\n",
      "loss: 0.300702  [ 9632/56940]\n",
      "loss: 0.308031  [12832/56940]\n",
      "loss: 0.200237  [16032/56940]\n",
      "loss: 0.218505  [19232/56940]\n",
      "loss: 0.436602  [22432/56940]\n",
      "loss: 0.376756  [25632/56940]\n",
      "loss: 0.203743  [28832/56940]\n",
      "loss: 0.385604  [32032/56940]\n",
      "loss: 0.326153  [35232/56940]\n",
      "loss: 0.233717  [38432/56940]\n",
      "loss: 0.224968  [41632/56940]\n",
      "loss: 0.237161  [44832/56940]\n",
      "loss: 0.310737  [48032/56940]\n",
      "loss: 0.202070  [51232/56940]\n",
      "loss: 0.176378  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.252658 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.428396  [   32/56940]\n",
      "loss: 0.250001  [ 3232/56940]\n",
      "loss: 0.277593  [ 6432/56940]\n",
      "loss: 0.274490  [ 9632/56940]\n",
      "loss: 0.243661  [12832/56940]\n",
      "loss: 0.167272  [16032/56940]\n",
      "loss: 0.394396  [19232/56940]\n",
      "loss: 0.187626  [22432/56940]\n",
      "loss: 0.308706  [25632/56940]\n",
      "loss: 0.206164  [28832/56940]\n",
      "loss: 0.141566  [32032/56940]\n",
      "loss: 0.327659  [35232/56940]\n",
      "loss: 0.406972  [38432/56940]\n",
      "loss: 0.277492  [41632/56940]\n",
      "loss: 0.351780  [44832/56940]\n",
      "loss: 0.165677  [48032/56940]\n",
      "loss: 0.255181  [51232/56940]\n",
      "loss: 0.211634  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.246543 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.242092  [   32/56940]\n",
      "loss: 0.283276  [ 3232/56940]\n",
      "loss: 0.219025  [ 6432/56940]\n",
      "loss: 0.238416  [ 9632/56940]\n",
      "loss: 0.306106  [12832/56940]\n",
      "loss: 0.391616  [16032/56940]\n",
      "loss: 0.527337  [19232/56940]\n",
      "loss: 0.252350  [22432/56940]\n",
      "loss: 0.365281  [25632/56940]\n",
      "loss: 0.212380  [28832/56940]\n",
      "loss: 0.210994  [32032/56940]\n",
      "loss: 0.230304  [35232/56940]\n",
      "loss: 0.200365  [38432/56940]\n",
      "loss: 0.093754  [41632/56940]\n",
      "loss: 0.304303  [44832/56940]\n",
      "loss: 0.247141  [48032/56940]\n",
      "loss: 0.417953  [51232/56940]\n",
      "loss: 0.284923  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.251640 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.235099  [   32/56940]\n",
      "loss: 0.225463  [ 3232/56940]\n",
      "loss: 0.156379  [ 6432/56940]\n",
      "loss: 0.298468  [ 9632/56940]\n",
      "loss: 0.286690  [12832/56940]\n",
      "loss: 0.330132  [16032/56940]\n",
      "loss: 0.286303  [19232/56940]\n",
      "loss: 0.461596  [22432/56940]\n",
      "loss: 0.267188  [25632/56940]\n",
      "loss: 0.587971  [28832/56940]\n",
      "loss: 0.409257  [32032/56940]\n",
      "loss: 0.189469  [35232/56940]\n",
      "loss: 0.277984  [38432/56940]\n",
      "loss: 0.246136  [41632/56940]\n",
      "loss: 0.441785  [44832/56940]\n",
      "loss: 0.419089  [48032/56940]\n",
      "loss: 0.197224  [51232/56940]\n",
      "loss: 0.197653  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.249109 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.242428  [   32/56940]\n",
      "loss: 0.276547  [ 3232/56940]\n",
      "loss: 0.330300  [ 6432/56940]\n",
      "loss: 0.159283  [ 9632/56940]\n",
      "loss: 0.219027  [12832/56940]\n",
      "loss: 0.167648  [16032/56940]\n",
      "loss: 0.416839  [19232/56940]\n",
      "loss: 0.504184  [22432/56940]\n",
      "loss: 0.251177  [25632/56940]\n",
      "loss: 0.354334  [28832/56940]\n",
      "loss: 0.211232  [32032/56940]\n",
      "loss: 0.523709  [35232/56940]\n",
      "loss: 0.586291  [38432/56940]\n",
      "loss: 0.241650  [41632/56940]\n",
      "loss: 0.297892  [44832/56940]\n",
      "loss: 0.253692  [48032/56940]\n",
      "loss: 0.122244  [51232/56940]\n",
      "loss: 0.318843  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.247450 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.233292  [   32/56940]\n",
      "loss: 0.243916  [ 3232/56940]\n",
      "loss: 0.300222  [ 6432/56940]\n",
      "loss: 0.266888  [ 9632/56940]\n",
      "loss: 0.321301  [12832/56940]\n",
      "loss: 0.244228  [16032/56940]\n",
      "loss: 0.195279  [19232/56940]\n",
      "loss: 0.254558  [22432/56940]\n",
      "loss: 0.174514  [25632/56940]\n",
      "loss: 0.193634  [28832/56940]\n",
      "loss: 0.238299  [32032/56940]\n",
      "loss: 0.199826  [35232/56940]\n",
      "loss: 1.162056  [38432/56940]\n",
      "loss: 0.318977  [41632/56940]\n",
      "loss: 0.266544  [44832/56940]\n",
      "loss: 0.296248  [48032/56940]\n",
      "loss: 0.244293  [51232/56940]\n",
      "loss: 0.210756  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.254594 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.366414  [   32/56940]\n",
      "loss: 0.344451  [ 3232/56940]\n",
      "loss: 0.458305  [ 6432/56940]\n",
      "loss: 0.306283  [ 9632/56940]\n",
      "loss: 0.245824  [12832/56940]\n",
      "loss: 0.224960  [16032/56940]\n",
      "loss: 0.290060  [19232/56940]\n",
      "loss: 0.554598  [22432/56940]\n",
      "loss: 0.202562  [25632/56940]\n",
      "loss: 0.458953  [28832/56940]\n",
      "loss: 0.397182  [32032/56940]\n",
      "loss: 0.257381  [35232/56940]\n",
      "loss: 0.210077  [38432/56940]\n",
      "loss: 0.426818  [41632/56940]\n",
      "loss: 0.270191  [44832/56940]\n",
      "loss: 0.330540  [48032/56940]\n",
      "loss: 0.190351  [51232/56940]\n",
      "loss: 0.293130  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.252427 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.323826  [   32/56940]\n",
      "loss: 0.323916  [ 3232/56940]\n",
      "loss: 0.280990  [ 6432/56940]\n",
      "loss: 0.196388  [ 9632/56940]\n",
      "loss: 0.320293  [12832/56940]\n",
      "loss: 0.203467  [16032/56940]\n",
      "loss: 0.181649  [19232/56940]\n",
      "loss: 0.381501  [22432/56940]\n",
      "loss: 0.214033  [25632/56940]\n",
      "loss: 0.353665  [28832/56940]\n",
      "loss: 0.173686  [32032/56940]\n",
      "loss: 0.216636  [35232/56940]\n",
      "loss: 0.327677  [38432/56940]\n",
      "loss: 0.247644  [41632/56940]\n",
      "loss: 0.283002  [44832/56940]\n",
      "loss: 0.328433  [48032/56940]\n",
      "loss: 0.414626  [51232/56940]\n",
      "loss: 0.194419  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.248359 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.265645  [   32/56940]\n",
      "loss: 0.210927  [ 3232/56940]\n",
      "loss: 0.274303  [ 6432/56940]\n",
      "loss: 0.224122  [ 9632/56940]\n",
      "loss: 0.383988  [12832/56940]\n",
      "loss: 0.460531  [16032/56940]\n",
      "loss: 0.248205  [19232/56940]\n",
      "loss: 0.150066  [22432/56940]\n",
      "loss: 0.526116  [25632/56940]\n",
      "loss: 0.368212  [28832/56940]\n",
      "loss: 0.435869  [32032/56940]\n",
      "loss: 0.344280  [35232/56940]\n",
      "loss: 0.275189  [38432/56940]\n",
      "loss: 0.206052  [41632/56940]\n",
      "loss: 0.297843  [44832/56940]\n",
      "loss: 0.303117  [48032/56940]\n",
      "loss: 0.238364  [51232/56940]\n",
      "loss: 0.155324  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.258788 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.255235  [   32/56940]\n",
      "loss: 0.295792  [ 3232/56940]\n",
      "loss: 0.447305  [ 6432/56940]\n",
      "loss: 0.198563  [ 9632/56940]\n",
      "loss: 0.213442  [12832/56940]\n",
      "loss: 0.562178  [16032/56940]\n",
      "loss: 0.365054  [19232/56940]\n",
      "loss: 0.176452  [22432/56940]\n",
      "loss: 0.235685  [25632/56940]\n",
      "loss: 0.418887  [28832/56940]\n",
      "loss: 0.324389  [32032/56940]\n",
      "loss: 0.242303  [35232/56940]\n",
      "loss: 0.245782  [38432/56940]\n",
      "loss: 0.328217  [41632/56940]\n",
      "loss: 0.621541  [44832/56940]\n",
      "loss: 0.333405  [48032/56940]\n",
      "loss: 0.255553  [51232/56940]\n",
      "loss: 0.337660  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.260754 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.514085  [   32/56940]\n",
      "loss: 0.217748  [ 3232/56940]\n",
      "loss: 0.129222  [ 6432/56940]\n",
      "loss: 0.155683  [ 9632/56940]\n",
      "loss: 0.219850  [12832/56940]\n",
      "loss: 0.471131  [16032/56940]\n",
      "loss: 0.329233  [19232/56940]\n",
      "loss: 0.221326  [22432/56940]\n",
      "loss: 0.322439  [25632/56940]\n",
      "loss: 0.205619  [28832/56940]\n",
      "loss: 0.278582  [32032/56940]\n",
      "loss: 0.199496  [35232/56940]\n",
      "loss: 0.358858  [38432/56940]\n",
      "loss: 0.176626  [41632/56940]\n",
      "loss: 0.227612  [44832/56940]\n",
      "loss: 0.320779  [48032/56940]\n",
      "loss: 0.313989  [51232/56940]\n",
      "loss: 0.216885  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.254425 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.338015  [   32/56940]\n",
      "loss: 0.279678  [ 3232/56940]\n",
      "loss: 0.384667  [ 6432/56940]\n",
      "loss: 0.375312  [ 9632/56940]\n",
      "loss: 0.206808  [12832/56940]\n",
      "loss: 0.287216  [16032/56940]\n",
      "loss: 0.316636  [19232/56940]\n",
      "loss: 0.275880  [22432/56940]\n",
      "loss: 0.218371  [25632/56940]\n",
      "loss: 0.379094  [28832/56940]\n",
      "loss: 0.208786  [32032/56940]\n",
      "loss: 0.273875  [35232/56940]\n",
      "loss: 0.340290  [38432/56940]\n",
      "loss: 0.219741  [41632/56940]\n",
      "loss: 0.328679  [44832/56940]\n",
      "loss: 0.243812  [48032/56940]\n",
      "loss: 0.307976  [51232/56940]\n",
      "loss: 0.324891  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.290263 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.334282  [   32/56940]\n",
      "loss: 0.620518  [ 3232/56940]\n",
      "loss: 0.365264  [ 6432/56940]\n",
      "loss: 0.401723  [ 9632/56940]\n",
      "loss: 0.231236  [12832/56940]\n",
      "loss: 0.267229  [16032/56940]\n",
      "loss: 0.342260  [19232/56940]\n",
      "loss: 0.413738  [22432/56940]\n",
      "loss: 0.173224  [25632/56940]\n",
      "loss: 0.410852  [28832/56940]\n",
      "loss: 0.303632  [32032/56940]\n",
      "loss: 0.192451  [35232/56940]\n",
      "loss: 0.233361  [38432/56940]\n",
      "loss: 0.195806  [41632/56940]\n",
      "loss: 0.181029  [44832/56940]\n",
      "loss: 0.184245  [48032/56940]\n",
      "loss: 0.302777  [51232/56940]\n",
      "loss: 0.343449  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.263053 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.275018  [   32/56940]\n",
      "loss: 0.316208  [ 3232/56940]\n",
      "loss: 0.364229  [ 6432/56940]\n",
      "loss: 0.360930  [ 9632/56940]\n",
      "loss: 0.401885  [12832/56940]\n",
      "loss: 0.390882  [16032/56940]\n",
      "loss: 0.287019  [19232/56940]\n",
      "loss: 0.171778  [22432/56940]\n",
      "loss: 0.389809  [25632/56940]\n",
      "loss: 0.234016  [28832/56940]\n",
      "loss: 0.210552  [32032/56940]\n",
      "loss: 0.247827  [35232/56940]\n",
      "loss: 0.248420  [38432/56940]\n",
      "loss: 0.284731  [41632/56940]\n",
      "loss: 0.295397  [44832/56940]\n",
      "loss: 0.195193  [48032/56940]\n",
      "loss: 0.348847  [51232/56940]\n",
      "loss: 0.241379  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.252897 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.164671  [   32/56940]\n",
      "loss: 0.327757  [ 3232/56940]\n",
      "loss: 0.120519  [ 6432/56940]\n",
      "loss: 0.484750  [ 9632/56940]\n",
      "loss: 0.165881  [12832/56940]\n",
      "loss: 0.201173  [16032/56940]\n",
      "loss: 0.550368  [19232/56940]\n",
      "loss: 0.256084  [22432/56940]\n",
      "loss: 0.351037  [25632/56940]\n",
      "loss: 0.365589  [28832/56940]\n",
      "loss: 0.283970  [32032/56940]\n",
      "loss: 0.201529  [35232/56940]\n",
      "loss: 0.191926  [38432/56940]\n",
      "loss: 0.439335  [41632/56940]\n",
      "loss: 0.193568  [44832/56940]\n",
      "loss: 0.231276  [48032/56940]\n",
      "loss: 0.254706  [51232/56940]\n",
      "loss: 0.231805  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.258877 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.251036  [   32/56940]\n",
      "loss: 0.246668  [ 3232/56940]\n",
      "loss: 0.212981  [ 6432/56940]\n",
      "loss: 0.361827  [ 9632/56940]\n",
      "loss: 0.327593  [12832/56940]\n",
      "loss: 0.457049  [16032/56940]\n",
      "loss: 0.248939  [19232/56940]\n",
      "loss: 0.403288  [22432/56940]\n",
      "loss: 0.345101  [25632/56940]\n",
      "loss: 0.342889  [28832/56940]\n",
      "loss: 0.552700  [32032/56940]\n",
      "loss: 0.189638  [35232/56940]\n",
      "loss: 0.340898  [38432/56940]\n",
      "loss: 0.230760  [41632/56940]\n",
      "loss: 0.201114  [44832/56940]\n",
      "loss: 0.298848  [48032/56940]\n",
      "loss: 0.250646  [51232/56940]\n",
      "loss: 0.381865  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.257759 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.235152  [   32/56940]\n",
      "loss: 0.309155  [ 3232/56940]\n",
      "loss: 0.563746  [ 6432/56940]\n",
      "loss: 0.373822  [ 9632/56940]\n",
      "loss: 0.316743  [12832/56940]\n",
      "loss: 0.210948  [16032/56940]\n",
      "loss: 0.242516  [19232/56940]\n",
      "loss: 0.135190  [22432/56940]\n",
      "loss: 0.362500  [25632/56940]\n",
      "loss: 0.350187  [28832/56940]\n",
      "loss: 0.115865  [32032/56940]\n",
      "loss: 0.411865  [35232/56940]\n",
      "loss: 0.267063  [38432/56940]\n",
      "loss: 0.250790  [41632/56940]\n",
      "loss: 0.389425  [44832/56940]\n",
      "loss: 0.333814  [48032/56940]\n",
      "loss: 0.295849  [51232/56940]\n",
      "loss: 0.166219  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.244005 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.205641  [   32/56940]\n",
      "loss: 0.122527  [ 3232/56940]\n",
      "loss: 0.321817  [ 6432/56940]\n",
      "loss: 0.290080  [ 9632/56940]\n",
      "loss: 0.366611  [12832/56940]\n",
      "loss: 0.584534  [16032/56940]\n",
      "loss: 0.288281  [19232/56940]\n",
      "loss: 0.336305  [22432/56940]\n",
      "loss: 0.297357  [25632/56940]\n",
      "loss: 0.213589  [28832/56940]\n",
      "loss: 0.233761  [32032/56940]\n",
      "loss: 0.444918  [35232/56940]\n",
      "loss: 0.281616  [38432/56940]\n",
      "loss: 0.307589  [41632/56940]\n",
      "loss: 0.243523  [44832/56940]\n",
      "loss: 0.177679  [48032/56940]\n",
      "loss: 0.221650  [51232/56940]\n",
      "loss: 0.344650  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.251615 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.295674  [   32/56940]\n",
      "loss: 0.343084  [ 3232/56940]\n",
      "loss: 0.169395  [ 6432/56940]\n",
      "loss: 0.115189  [ 9632/56940]\n",
      "loss: 0.442454  [12832/56940]\n",
      "loss: 0.162744  [16032/56940]\n",
      "loss: 0.461881  [19232/56940]\n",
      "loss: 0.426224  [22432/56940]\n",
      "loss: 0.365735  [25632/56940]\n",
      "loss: 0.263159  [28832/56940]\n",
      "loss: 0.261108  [32032/56940]\n",
      "loss: 0.317527  [35232/56940]\n",
      "loss: 0.158116  [38432/56940]\n",
      "loss: 0.214006  [41632/56940]\n",
      "loss: 0.320726  [44832/56940]\n",
      "loss: 0.261698  [48032/56940]\n",
      "loss: 0.197358  [51232/56940]\n",
      "loss: 0.364553  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.254692 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.344014  [   32/56940]\n",
      "loss: 0.302157  [ 3232/56940]\n",
      "loss: 0.160516  [ 6432/56940]\n",
      "loss: 0.282704  [ 9632/56940]\n",
      "loss: 0.335398  [12832/56940]\n",
      "loss: 0.225606  [16032/56940]\n",
      "loss: 0.475141  [19232/56940]\n",
      "loss: 0.427165  [22432/56940]\n",
      "loss: 0.368846  [25632/56940]\n",
      "loss: 0.299358  [28832/56940]\n",
      "loss: 0.414630  [32032/56940]\n",
      "loss: 0.265296  [35232/56940]\n",
      "loss: 0.205413  [38432/56940]\n",
      "loss: 0.146720  [41632/56940]\n",
      "loss: 0.634004  [44832/56940]\n",
      "loss: 0.275505  [48032/56940]\n",
      "loss: 0.423907  [51232/56940]\n",
      "loss: 0.207037  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.250412 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.219450  [   32/56940]\n",
      "loss: 0.477935  [ 3232/56940]\n",
      "loss: 0.152512  [ 6432/56940]\n",
      "loss: 0.223494  [ 9632/56940]\n",
      "loss: 0.284438  [12832/56940]\n",
      "loss: 0.449560  [16032/56940]\n",
      "loss: 0.131610  [19232/56940]\n",
      "loss: 0.106707  [22432/56940]\n",
      "loss: 0.342161  [25632/56940]\n",
      "loss: 0.294419  [28832/56940]\n",
      "loss: 0.304407  [32032/56940]\n",
      "loss: 0.341375  [35232/56940]\n",
      "loss: 0.264487  [38432/56940]\n",
      "loss: 0.241494  [41632/56940]\n",
      "loss: 0.471478  [44832/56940]\n",
      "loss: 0.238957  [48032/56940]\n",
      "loss: 0.249940  [51232/56940]\n",
      "loss: 0.286610  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.254385 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.311814  [   32/56940]\n",
      "loss: 0.438454  [ 3232/56940]\n",
      "loss: 0.196637  [ 6432/56940]\n",
      "loss: 0.262843  [ 9632/56940]\n",
      "loss: 0.816607  [12832/56940]\n",
      "loss: 0.323712  [16032/56940]\n",
      "loss: 0.207216  [19232/56940]\n",
      "loss: 0.227000  [22432/56940]\n",
      "loss: 0.265495  [25632/56940]\n",
      "loss: 0.473249  [28832/56940]\n",
      "loss: 0.198021  [32032/56940]\n",
      "loss: 0.284924  [35232/56940]\n",
      "loss: 0.381212  [38432/56940]\n",
      "loss: 0.299144  [41632/56940]\n",
      "loss: 0.408470  [44832/56940]\n",
      "loss: 0.273147  [48032/56940]\n",
      "loss: 0.197316  [51232/56940]\n",
      "loss: 0.694644  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.239539 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.206197  [   32/56940]\n",
      "loss: 0.125286  [ 3232/56940]\n",
      "loss: 0.315650  [ 6432/56940]\n",
      "loss: 0.170312  [ 9632/56940]\n",
      "loss: 0.290945  [12832/56940]\n",
      "loss: 0.328180  [16032/56940]\n",
      "loss: 0.156902  [19232/56940]\n",
      "loss: 0.260352  [22432/56940]\n",
      "loss: 0.260275  [25632/56940]\n",
      "loss: 0.464905  [28832/56940]\n",
      "loss: 0.206591  [32032/56940]\n",
      "loss: 0.537560  [35232/56940]\n",
      "loss: 0.242090  [38432/56940]\n",
      "loss: 0.283159  [41632/56940]\n",
      "loss: 0.152096  [44832/56940]\n",
      "loss: 0.247237  [48032/56940]\n",
      "loss: 0.342014  [51232/56940]\n",
      "loss: 0.220959  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.262044 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.193752  [   32/56940]\n",
      "loss: 0.306756  [ 3232/56940]\n",
      "loss: 0.169491  [ 6432/56940]\n",
      "loss: 0.578507  [ 9632/56940]\n",
      "loss: 0.357567  [12832/56940]\n",
      "loss: 0.393476  [16032/56940]\n",
      "loss: 0.354008  [19232/56940]\n",
      "loss: 0.261239  [22432/56940]\n",
      "loss: 0.165139  [25632/56940]\n",
      "loss: 0.181255  [28832/56940]\n",
      "loss: 0.221404  [32032/56940]\n",
      "loss: 0.450609  [35232/56940]\n",
      "loss: 0.536428  [38432/56940]\n",
      "loss: 0.154660  [41632/56940]\n",
      "loss: 0.485178  [44832/56940]\n",
      "loss: 0.179733  [48032/56940]\n",
      "loss: 0.260338  [51232/56940]\n",
      "loss: 0.128205  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.276756 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.560173  [   32/56940]\n",
      "loss: 0.111819  [ 3232/56940]\n",
      "loss: 0.199074  [ 6432/56940]\n",
      "loss: 0.245208  [ 9632/56940]\n",
      "loss: 0.259059  [12832/56940]\n",
      "loss: 0.159150  [16032/56940]\n",
      "loss: 0.364286  [19232/56940]\n",
      "loss: 0.270915  [22432/56940]\n",
      "loss: 0.171494  [25632/56940]\n",
      "loss: 0.377248  [28832/56940]\n",
      "loss: 0.567219  [32032/56940]\n",
      "loss: 0.237610  [35232/56940]\n",
      "loss: 0.304669  [38432/56940]\n",
      "loss: 0.215546  [41632/56940]\n",
      "loss: 0.302893  [44832/56940]\n",
      "loss: 0.117873  [48032/56940]\n",
      "loss: 0.234917  [51232/56940]\n",
      "loss: 0.316298  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.279338 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.250332  [   32/56940]\n",
      "loss: 0.206242  [ 3232/56940]\n",
      "loss: 0.325484  [ 6432/56940]\n",
      "loss: 0.295776  [ 9632/56940]\n",
      "loss: 0.236959  [12832/56940]\n",
      "loss: 0.409786  [16032/56940]\n",
      "loss: 0.268917  [19232/56940]\n",
      "loss: 0.309123  [22432/56940]\n",
      "loss: 0.250745  [25632/56940]\n",
      "loss: 0.266271  [28832/56940]\n",
      "loss: 0.202162  [32032/56940]\n",
      "loss: 0.307449  [35232/56940]\n",
      "loss: 0.160604  [38432/56940]\n",
      "loss: 0.292411  [41632/56940]\n",
      "loss: 0.199670  [44832/56940]\n",
      "loss: 0.216438  [48032/56940]\n",
      "loss: 0.253194  [51232/56940]\n",
      "loss: 0.259506  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.248338 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.231037  [   32/56940]\n",
      "loss: 0.252510  [ 3232/56940]\n",
      "loss: 0.343828  [ 6432/56940]\n",
      "loss: 0.184432  [ 9632/56940]\n",
      "loss: 0.495494  [12832/56940]\n",
      "loss: 0.418442  [16032/56940]\n",
      "loss: 0.301640  [19232/56940]\n",
      "loss: 0.260795  [22432/56940]\n",
      "loss: 0.232899  [25632/56940]\n",
      "loss: 0.144071  [28832/56940]\n",
      "loss: 0.231826  [32032/56940]\n",
      "loss: 0.181353  [35232/56940]\n",
      "loss: 0.191127  [38432/56940]\n",
      "loss: 0.249426  [41632/56940]\n",
      "loss: 0.429272  [44832/56940]\n",
      "loss: 0.330585  [48032/56940]\n",
      "loss: 0.158771  [51232/56940]\n",
      "loss: 0.325241  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.242765 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.230121  [   32/56940]\n",
      "loss: 0.238434  [ 3232/56940]\n",
      "loss: 0.387498  [ 6432/56940]\n",
      "loss: 0.323085  [ 9632/56940]\n",
      "loss: 0.127593  [12832/56940]\n",
      "loss: 0.221299  [16032/56940]\n",
      "loss: 0.412202  [19232/56940]\n",
      "loss: 0.127945  [22432/56940]\n",
      "loss: 0.217342  [25632/56940]\n",
      "loss: 0.261831  [28832/56940]\n",
      "loss: 0.187027  [32032/56940]\n",
      "loss: 0.274552  [35232/56940]\n",
      "loss: 0.453637  [38432/56940]\n",
      "loss: 0.173145  [41632/56940]\n",
      "loss: 0.173837  [44832/56940]\n",
      "loss: 0.439803  [48032/56940]\n",
      "loss: 0.303189  [51232/56940]\n",
      "loss: 0.157807  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.241346 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.374195  [   32/56940]\n",
      "loss: 0.288288  [ 3232/56940]\n",
      "loss: 0.184426  [ 6432/56940]\n",
      "loss: 0.442793  [ 9632/56940]\n",
      "loss: 0.428158  [12832/56940]\n",
      "loss: 0.223303  [16032/56940]\n",
      "loss: 0.138113  [19232/56940]\n",
      "loss: 0.229353  [22432/56940]\n",
      "loss: 0.249857  [25632/56940]\n",
      "loss: 0.322976  [28832/56940]\n",
      "loss: 0.207989  [32032/56940]\n",
      "loss: 0.324341  [35232/56940]\n",
      "loss: 0.288505  [38432/56940]\n",
      "loss: 0.187887  [41632/56940]\n",
      "loss: 0.232011  [44832/56940]\n",
      "loss: 0.326813  [48032/56940]\n",
      "loss: 0.402109  [51232/56940]\n",
      "loss: 0.355128  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.241391 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.139353  [   32/56940]\n",
      "loss: 0.427912  [ 3232/56940]\n",
      "loss: 0.102338  [ 6432/56940]\n",
      "loss: 0.442309  [ 9632/56940]\n",
      "loss: 0.201066  [12832/56940]\n",
      "loss: 0.176502  [16032/56940]\n",
      "loss: 0.289342  [19232/56940]\n",
      "loss: 0.258987  [22432/56940]\n",
      "loss: 0.152665  [25632/56940]\n",
      "loss: 0.325360  [28832/56940]\n",
      "loss: 0.193367  [32032/56940]\n",
      "loss: 0.312647  [35232/56940]\n",
      "loss: 0.215995  [38432/56940]\n",
      "loss: 0.255014  [41632/56940]\n",
      "loss: 0.211390  [44832/56940]\n",
      "loss: 0.321272  [48032/56940]\n",
      "loss: 0.187180  [51232/56940]\n",
      "loss: 0.183716  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.243026 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.256126  [   32/56940]\n",
      "loss: 0.348456  [ 3232/56940]\n",
      "loss: 0.253815  [ 6432/56940]\n",
      "loss: 0.201582  [ 9632/56940]\n",
      "loss: 0.199229  [12832/56940]\n",
      "loss: 0.210267  [16032/56940]\n",
      "loss: 0.265414  [19232/56940]\n",
      "loss: 0.450868  [22432/56940]\n",
      "loss: 0.735277  [25632/56940]\n",
      "loss: 0.172877  [28832/56940]\n",
      "loss: 0.251692  [32032/56940]\n",
      "loss: 0.229963  [35232/56940]\n",
      "loss: 0.340082  [38432/56940]\n",
      "loss: 0.169832  [41632/56940]\n",
      "loss: 0.185305  [44832/56940]\n",
      "loss: 0.403062  [48032/56940]\n",
      "loss: 0.340947  [51232/56940]\n",
      "loss: 0.417690  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.244709 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.420042  [   32/56940]\n",
      "loss: 0.303619  [ 3232/56940]\n",
      "loss: 0.569289  [ 6432/56940]\n",
      "loss: 0.177880  [ 9632/56940]\n",
      "loss: 0.293795  [12832/56940]\n",
      "loss: 0.285179  [16032/56940]\n",
      "loss: 0.466003  [19232/56940]\n",
      "loss: 0.165633  [22432/56940]\n",
      "loss: 0.219013  [25632/56940]\n",
      "loss: 0.662076  [28832/56940]\n",
      "loss: 0.223287  [32032/56940]\n",
      "loss: 0.155598  [35232/56940]\n",
      "loss: 0.414091  [38432/56940]\n",
      "loss: 0.491399  [41632/56940]\n",
      "loss: 0.331539  [44832/56940]\n",
      "loss: 0.409621  [48032/56940]\n",
      "loss: 0.209172  [51232/56940]\n",
      "loss: 0.243430  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.264186 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.238857  [   32/56940]\n",
      "loss: 0.188884  [ 3232/56940]\n",
      "loss: 0.173918  [ 6432/56940]\n",
      "loss: 0.394975  [ 9632/56940]\n",
      "loss: 0.498642  [12832/56940]\n",
      "loss: 0.190689  [16032/56940]\n",
      "loss: 0.440150  [19232/56940]\n",
      "loss: 0.463252  [22432/56940]\n",
      "loss: 0.290919  [25632/56940]\n",
      "loss: 0.267070  [28832/56940]\n",
      "loss: 0.273999  [32032/56940]\n",
      "loss: 0.282326  [35232/56940]\n",
      "loss: 0.243264  [38432/56940]\n",
      "loss: 0.281373  [41632/56940]\n",
      "loss: 0.188625  [44832/56940]\n",
      "loss: 0.289960  [48032/56940]\n",
      "loss: 0.187050  [51232/56940]\n",
      "loss: 0.123479  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.239957 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.322142  [   32/56940]\n",
      "loss: 0.239103  [ 3232/56940]\n",
      "loss: 0.275766  [ 6432/56940]\n",
      "loss: 0.144677  [ 9632/56940]\n",
      "loss: 0.379197  [12832/56940]\n",
      "loss: 0.147534  [16032/56940]\n",
      "loss: 0.215779  [19232/56940]\n",
      "loss: 0.341647  [22432/56940]\n",
      "loss: 0.205110  [25632/56940]\n",
      "loss: 0.265216  [28832/56940]\n",
      "loss: 0.130693  [32032/56940]\n",
      "loss: 0.187184  [35232/56940]\n",
      "loss: 0.318054  [38432/56940]\n",
      "loss: 0.458057  [41632/56940]\n",
      "loss: 0.142249  [44832/56940]\n",
      "loss: 0.439935  [48032/56940]\n",
      "loss: 0.276483  [51232/56940]\n",
      "loss: 0.334907  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.242355 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.319251  [   32/56940]\n",
      "loss: 0.197078  [ 3232/56940]\n",
      "loss: 0.272594  [ 6432/56940]\n",
      "loss: 0.111445  [ 9632/56940]\n",
      "loss: 0.277377  [12832/56940]\n",
      "loss: 0.221708  [16032/56940]\n",
      "loss: 0.320963  [19232/56940]\n",
      "loss: 0.353902  [22432/56940]\n",
      "loss: 0.381344  [25632/56940]\n",
      "loss: 0.265071  [28832/56940]\n",
      "loss: 0.395776  [32032/56940]\n",
      "loss: 0.330570  [35232/56940]\n",
      "loss: 0.259870  [38432/56940]\n",
      "loss: 0.163656  [41632/56940]\n",
      "loss: 0.285648  [44832/56940]\n",
      "loss: 0.197094  [48032/56940]\n",
      "loss: 0.283478  [51232/56940]\n",
      "loss: 0.348228  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.241825 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.420281  [   32/56940]\n",
      "loss: 0.429144  [ 3232/56940]\n",
      "loss: 0.253487  [ 6432/56940]\n",
      "loss: 0.214259  [ 9632/56940]\n",
      "loss: 0.288790  [12832/56940]\n",
      "loss: 0.125086  [16032/56940]\n",
      "loss: 0.367859  [19232/56940]\n",
      "loss: 0.246208  [22432/56940]\n",
      "loss: 0.305352  [25632/56940]\n",
      "loss: 0.117204  [28832/56940]\n",
      "loss: 0.501362  [32032/56940]\n",
      "loss: 0.310686  [35232/56940]\n",
      "loss: 0.470396  [38432/56940]\n",
      "loss: 0.199465  [41632/56940]\n",
      "loss: 0.219205  [44832/56940]\n",
      "loss: 0.383433  [48032/56940]\n",
      "loss: 0.545788  [51232/56940]\n",
      "loss: 0.382483  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.239988 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.264902  [   32/56940]\n",
      "loss: 0.140466  [ 3232/56940]\n",
      "loss: 0.401426  [ 6432/56940]\n",
      "loss: 0.300976  [ 9632/56940]\n",
      "loss: 0.464203  [12832/56940]\n",
      "loss: 0.470050  [16032/56940]\n",
      "loss: 0.225198  [19232/56940]\n",
      "loss: 0.307346  [22432/56940]\n",
      "loss: 0.187707  [25632/56940]\n",
      "loss: 0.507244  [28832/56940]\n",
      "loss: 0.228919  [32032/56940]\n",
      "loss: 0.342532  [35232/56940]\n",
      "loss: 0.098079  [38432/56940]\n",
      "loss: 0.267147  [41632/56940]\n",
      "loss: 0.268983  [44832/56940]\n",
      "loss: 0.582606  [48032/56940]\n",
      "loss: 0.081818  [51232/56940]\n",
      "loss: 0.275956  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.253235 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.434961  [   32/56940]\n",
      "loss: 0.237610  [ 3232/56940]\n",
      "loss: 0.241180  [ 6432/56940]\n",
      "loss: 0.347326  [ 9632/56940]\n",
      "loss: 0.282626  [12832/56940]\n",
      "loss: 0.327132  [16032/56940]\n",
      "loss: 0.296694  [19232/56940]\n",
      "loss: 0.376567  [22432/56940]\n",
      "loss: 0.194286  [25632/56940]\n",
      "loss: 0.326165  [28832/56940]\n",
      "loss: 0.405419  [32032/56940]\n",
      "loss: 0.179800  [35232/56940]\n",
      "loss: 0.193537  [38432/56940]\n",
      "loss: 0.181339  [41632/56940]\n",
      "loss: 0.200455  [44832/56940]\n",
      "loss: 0.231921  [48032/56940]\n",
      "loss: 0.372667  [51232/56940]\n",
      "loss: 0.440671  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.236071 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.395466  [   32/56940]\n",
      "loss: 0.257948  [ 3232/56940]\n",
      "loss: 0.565755  [ 6432/56940]\n",
      "loss: 0.118527  [ 9632/56940]\n",
      "loss: 0.482125  [12832/56940]\n",
      "loss: 0.247776  [16032/56940]\n",
      "loss: 0.138169  [19232/56940]\n",
      "loss: 0.191747  [22432/56940]\n",
      "loss: 0.266227  [25632/56940]\n",
      "loss: 0.282456  [28832/56940]\n",
      "loss: 0.213486  [32032/56940]\n",
      "loss: 0.325734  [35232/56940]\n",
      "loss: 0.201467  [38432/56940]\n",
      "loss: 0.286420  [41632/56940]\n",
      "loss: 0.201632  [44832/56940]\n",
      "loss: 0.262998  [48032/56940]\n",
      "loss: 0.268638  [51232/56940]\n",
      "loss: 0.196851  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.236960 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.364608  [   32/56940]\n",
      "loss: 0.336294  [ 3232/56940]\n",
      "loss: 0.380516  [ 6432/56940]\n",
      "loss: 0.242669  [ 9632/56940]\n",
      "loss: 0.556401  [12832/56940]\n",
      "loss: 0.225711  [16032/56940]\n",
      "loss: 0.277548  [19232/56940]\n",
      "loss: 0.124197  [22432/56940]\n",
      "loss: 0.157420  [25632/56940]\n",
      "loss: 0.282106  [28832/56940]\n",
      "loss: 0.300419  [32032/56940]\n",
      "loss: 0.284984  [35232/56940]\n",
      "loss: 0.185390  [38432/56940]\n",
      "loss: 0.243184  [41632/56940]\n",
      "loss: 0.531004  [44832/56940]\n",
      "loss: 0.213293  [48032/56940]\n",
      "loss: 0.387645  [51232/56940]\n",
      "loss: 0.298620  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.275793 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.323460  [   32/56940]\n",
      "loss: 0.302998  [ 3232/56940]\n",
      "loss: 0.313634  [ 6432/56940]\n",
      "loss: 0.209402  [ 9632/56940]\n",
      "loss: 0.442322  [12832/56940]\n",
      "loss: 0.228429  [16032/56940]\n",
      "loss: 0.203279  [19232/56940]\n",
      "loss: 0.180150  [22432/56940]\n",
      "loss: 0.190077  [25632/56940]\n",
      "loss: 0.210594  [28832/56940]\n",
      "loss: 0.195791  [32032/56940]\n",
      "loss: 0.267731  [35232/56940]\n",
      "loss: 0.205845  [38432/56940]\n",
      "loss: 0.280747  [41632/56940]\n",
      "loss: 0.241762  [44832/56940]\n",
      "loss: 0.331302  [48032/56940]\n",
      "loss: 0.179497  [51232/56940]\n",
      "loss: 0.280315  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.246147 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.285452  [   32/56940]\n",
      "loss: 0.302770  [ 3232/56940]\n",
      "loss: 0.264355  [ 6432/56940]\n",
      "loss: 0.411166  [ 9632/56940]\n",
      "loss: 0.292254  [12832/56940]\n",
      "loss: 0.216922  [16032/56940]\n",
      "loss: 0.295509  [19232/56940]\n",
      "loss: 0.310705  [22432/56940]\n",
      "loss: 0.417424  [25632/56940]\n",
      "loss: 0.149956  [28832/56940]\n",
      "loss: 0.349826  [32032/56940]\n",
      "loss: 0.232683  [35232/56940]\n",
      "loss: 0.248972  [38432/56940]\n",
      "loss: 0.276383  [41632/56940]\n",
      "loss: 0.393549  [44832/56940]\n",
      "loss: 0.158066  [48032/56940]\n",
      "loss: 0.209373  [51232/56940]\n",
      "loss: 0.227528  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.238780 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.235488  [   32/56940]\n",
      "loss: 0.193641  [ 3232/56940]\n",
      "loss: 0.251958  [ 6432/56940]\n",
      "loss: 0.389286  [ 9632/56940]\n",
      "loss: 0.339350  [12832/56940]\n",
      "loss: 0.156131  [16032/56940]\n",
      "loss: 0.258859  [19232/56940]\n",
      "loss: 0.353168  [22432/56940]\n",
      "loss: 0.245253  [25632/56940]\n",
      "loss: 0.223543  [28832/56940]\n",
      "loss: 0.331294  [32032/56940]\n",
      "loss: 0.206907  [35232/56940]\n",
      "loss: 0.264217  [38432/56940]\n",
      "loss: 0.348563  [41632/56940]\n",
      "loss: 0.330615  [44832/56940]\n",
      "loss: 0.182149  [48032/56940]\n",
      "loss: 0.271559  [51232/56940]\n",
      "loss: 0.155527  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.290915 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.351221  [   32/56940]\n",
      "loss: 0.163439  [ 3232/56940]\n",
      "loss: 0.333178  [ 6432/56940]\n",
      "loss: 0.140456  [ 9632/56940]\n",
      "loss: 0.201241  [12832/56940]\n",
      "loss: 0.396681  [16032/56940]\n",
      "loss: 0.221088  [19232/56940]\n",
      "loss: 0.292984  [22432/56940]\n",
      "loss: 0.376637  [25632/56940]\n",
      "loss: 0.303841  [28832/56940]\n",
      "loss: 0.318973  [32032/56940]\n",
      "loss: 0.243844  [35232/56940]\n",
      "loss: 0.272328  [38432/56940]\n",
      "loss: 0.205341  [41632/56940]\n",
      "loss: 0.171570  [44832/56940]\n",
      "loss: 0.179311  [48032/56940]\n",
      "loss: 0.213335  [51232/56940]\n",
      "loss: 0.233861  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.242586 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.412771  [   32/56940]\n",
      "loss: 0.235146  [ 3232/56940]\n",
      "loss: 0.222778  [ 6432/56940]\n",
      "loss: 0.192858  [ 9632/56940]\n",
      "loss: 0.309707  [12832/56940]\n",
      "loss: 0.125024  [16032/56940]\n",
      "loss: 0.328717  [19232/56940]\n",
      "loss: 0.245839  [22432/56940]\n",
      "loss: 0.310135  [25632/56940]\n",
      "loss: 0.215214  [28832/56940]\n",
      "loss: 0.227699  [32032/56940]\n",
      "loss: 0.334284  [35232/56940]\n",
      "loss: 0.385939  [38432/56940]\n",
      "loss: 0.503212  [41632/56940]\n",
      "loss: 0.306057  [44832/56940]\n",
      "loss: 0.145787  [48032/56940]\n",
      "loss: 0.235369  [51232/56940]\n",
      "loss: 0.281430  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.257137 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.323999  [   32/56940]\n",
      "loss: 0.262281  [ 3232/56940]\n",
      "loss: 0.237934  [ 6432/56940]\n",
      "loss: 0.425960  [ 9632/56940]\n",
      "loss: 0.200430  [12832/56940]\n",
      "loss: 0.292951  [16032/56940]\n",
      "loss: 0.267949  [19232/56940]\n",
      "loss: 0.200280  [22432/56940]\n",
      "loss: 0.377798  [25632/56940]\n",
      "loss: 0.266595  [28832/56940]\n",
      "loss: 0.263517  [32032/56940]\n",
      "loss: 0.145341  [35232/56940]\n",
      "loss: 0.390230  [38432/56940]\n",
      "loss: 0.320885  [41632/56940]\n",
      "loss: 0.252256  [44832/56940]\n",
      "loss: 0.318789  [48032/56940]\n",
      "loss: 0.326801  [51232/56940]\n",
      "loss: 0.354943  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.265076 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.289470  [   32/56940]\n",
      "loss: 0.219625  [ 3232/56940]\n",
      "loss: 0.520533  [ 6432/56940]\n",
      "loss: 0.214299  [ 9632/56940]\n",
      "loss: 0.323678  [12832/56940]\n",
      "loss: 0.325299  [16032/56940]\n",
      "loss: 0.356400  [19232/56940]\n",
      "loss: 0.217815  [22432/56940]\n",
      "loss: 0.306546  [25632/56940]\n",
      "loss: 0.473860  [28832/56940]\n",
      "loss: 0.445286  [32032/56940]\n",
      "loss: 0.269558  [35232/56940]\n",
      "loss: 0.318020  [38432/56940]\n",
      "loss: 0.348956  [41632/56940]\n",
      "loss: 0.404046  [44832/56940]\n",
      "loss: 0.274976  [48032/56940]\n",
      "loss: 0.349823  [51232/56940]\n",
      "loss: 0.131821  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.236030 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.186183  [   32/56940]\n",
      "loss: 0.196830  [ 3232/56940]\n",
      "loss: 0.405306  [ 6432/56940]\n",
      "loss: 0.322279  [ 9632/56940]\n",
      "loss: 0.259538  [12832/56940]\n",
      "loss: 0.250400  [16032/56940]\n",
      "loss: 0.134260  [19232/56940]\n",
      "loss: 0.294372  [22432/56940]\n",
      "loss: 0.206284  [25632/56940]\n",
      "loss: 0.307566  [28832/56940]\n",
      "loss: 0.232200  [32032/56940]\n",
      "loss: 0.160276  [35232/56940]\n",
      "loss: 0.228597  [38432/56940]\n",
      "loss: 0.165439  [41632/56940]\n",
      "loss: 0.169766  [44832/56940]\n",
      "loss: 0.328860  [48032/56940]\n",
      "loss: 0.367878  [51232/56940]\n",
      "loss: 0.389861  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.234976 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.164346  [   32/56940]\n",
      "loss: 0.210202  [ 3232/56940]\n",
      "loss: 0.090335  [ 6432/56940]\n",
      "loss: 0.130007  [ 9632/56940]\n",
      "loss: 0.324636  [12832/56940]\n",
      "loss: 0.293109  [16032/56940]\n",
      "loss: 0.309074  [19232/56940]\n",
      "loss: 0.235531  [22432/56940]\n",
      "loss: 0.208011  [25632/56940]\n",
      "loss: 0.289300  [28832/56940]\n",
      "loss: 0.149764  [32032/56940]\n",
      "loss: 0.284136  [35232/56940]\n",
      "loss: 0.154655  [38432/56940]\n",
      "loss: 0.227180  [41632/56940]\n",
      "loss: 0.207685  [44832/56940]\n",
      "loss: 0.227928  [48032/56940]\n",
      "loss: 0.324276  [51232/56940]\n",
      "loss: 0.376959  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.241305 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.268120  [   32/56940]\n",
      "loss: 0.146575  [ 3232/56940]\n",
      "loss: 0.129360  [ 6432/56940]\n",
      "loss: 0.297942  [ 9632/56940]\n",
      "loss: 0.387817  [12832/56940]\n",
      "loss: 0.512494  [16032/56940]\n",
      "loss: 0.187618  [19232/56940]\n",
      "loss: 0.289235  [22432/56940]\n",
      "loss: 0.427438  [25632/56940]\n",
      "loss: 0.247189  [28832/56940]\n",
      "loss: 0.296354  [32032/56940]\n",
      "loss: 0.220785  [35232/56940]\n",
      "loss: 0.190960  [38432/56940]\n",
      "loss: 0.365002  [41632/56940]\n",
      "loss: 0.296959  [44832/56940]\n",
      "loss: 0.204916  [48032/56940]\n",
      "loss: 0.302413  [51232/56940]\n",
      "loss: 0.376833  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.234470 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.205461  [   32/56940]\n",
      "loss: 0.344569  [ 3232/56940]\n",
      "loss: 0.160344  [ 6432/56940]\n",
      "loss: 0.204448  [ 9632/56940]\n",
      "loss: 0.178549  [12832/56940]\n",
      "loss: 0.160924  [16032/56940]\n",
      "loss: 0.341931  [19232/56940]\n",
      "loss: 0.426205  [22432/56940]\n",
      "loss: 0.362540  [25632/56940]\n",
      "loss: 0.291277  [28832/56940]\n",
      "loss: 0.290381  [32032/56940]\n",
      "loss: 0.389011  [35232/56940]\n",
      "loss: 0.361331  [38432/56940]\n",
      "loss: 0.264415  [41632/56940]\n",
      "loss: 0.210307  [44832/56940]\n",
      "loss: 0.251442  [48032/56940]\n",
      "loss: 0.540260  [51232/56940]\n",
      "loss: 0.395313  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.244068 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.285531  [   32/56940]\n",
      "loss: 0.136108  [ 3232/56940]\n",
      "loss: 0.205679  [ 6432/56940]\n",
      "loss: 0.323433  [ 9632/56940]\n",
      "loss: 0.560665  [12832/56940]\n",
      "loss: 0.654150  [16032/56940]\n",
      "loss: 0.210068  [19232/56940]\n",
      "loss: 0.315033  [22432/56940]\n",
      "loss: 0.199419  [25632/56940]\n",
      "loss: 0.238422  [28832/56940]\n",
      "loss: 0.331347  [32032/56940]\n",
      "loss: 0.245070  [35232/56940]\n",
      "loss: 0.162401  [38432/56940]\n",
      "loss: 0.295892  [41632/56940]\n",
      "loss: 0.162651  [44832/56940]\n",
      "loss: 0.209081  [48032/56940]\n",
      "loss: 0.285811  [51232/56940]\n",
      "loss: 0.287622  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.236364 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.333982  [   32/56940]\n",
      "loss: 0.241171  [ 3232/56940]\n",
      "loss: 0.278223  [ 6432/56940]\n",
      "loss: 0.171636  [ 9632/56940]\n",
      "loss: 0.348100  [12832/56940]\n",
      "loss: 0.177853  [16032/56940]\n",
      "loss: 0.551560  [19232/56940]\n",
      "loss: 0.251811  [22432/56940]\n",
      "loss: 0.411587  [25632/56940]\n",
      "loss: 0.446096  [28832/56940]\n",
      "loss: 0.562529  [32032/56940]\n",
      "loss: 0.175175  [35232/56940]\n",
      "loss: 0.266620  [38432/56940]\n",
      "loss: 0.263641  [41632/56940]\n",
      "loss: 0.221928  [44832/56940]\n",
      "loss: 0.207575  [48032/56940]\n",
      "loss: 0.204771  [51232/56940]\n",
      "loss: 0.356768  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.245083 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.235369  [   32/56940]\n",
      "loss: 0.358366  [ 3232/56940]\n",
      "loss: 0.249940  [ 6432/56940]\n",
      "loss: 0.171090  [ 9632/56940]\n",
      "loss: 0.298760  [12832/56940]\n",
      "loss: 0.359979  [16032/56940]\n",
      "loss: 0.281175  [19232/56940]\n",
      "loss: 0.246189  [22432/56940]\n",
      "loss: 0.313449  [25632/56940]\n",
      "loss: 0.250573  [28832/56940]\n",
      "loss: 0.178929  [32032/56940]\n",
      "loss: 0.117228  [35232/56940]\n",
      "loss: 0.249062  [38432/56940]\n",
      "loss: 0.244265  [41632/56940]\n",
      "loss: 0.289028  [44832/56940]\n",
      "loss: 0.255612  [48032/56940]\n",
      "loss: 0.235417  [51232/56940]\n",
      "loss: 0.299715  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.233508 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.234353  [   32/56940]\n",
      "loss: 0.442437  [ 3232/56940]\n",
      "loss: 0.193216  [ 6432/56940]\n",
      "loss: 0.249786  [ 9632/56940]\n",
      "loss: 0.264530  [12832/56940]\n",
      "loss: 0.256920  [16032/56940]\n",
      "loss: 0.345653  [19232/56940]\n",
      "loss: 0.161475  [22432/56940]\n",
      "loss: 0.218841  [25632/56940]\n",
      "loss: 0.438917  [28832/56940]\n",
      "loss: 0.285642  [32032/56940]\n",
      "loss: 0.355498  [35232/56940]\n",
      "loss: 0.389608  [38432/56940]\n",
      "loss: 0.648701  [41632/56940]\n",
      "loss: 0.196487  [44832/56940]\n",
      "loss: 0.297422  [48032/56940]\n",
      "loss: 0.192223  [51232/56940]\n",
      "loss: 0.208908  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.235415 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.122955  [   32/56940]\n",
      "loss: 0.215514  [ 3232/56940]\n",
      "loss: 0.241583  [ 6432/56940]\n",
      "loss: 0.172557  [ 9632/56940]\n",
      "loss: 0.270535  [12832/56940]\n",
      "loss: 0.338922  [16032/56940]\n",
      "loss: 0.283948  [19232/56940]\n",
      "loss: 0.223580  [22432/56940]\n",
      "loss: 0.179681  [25632/56940]\n",
      "loss: 0.178081  [28832/56940]\n",
      "loss: 0.219982  [32032/56940]\n",
      "loss: 0.198652  [35232/56940]\n",
      "loss: 0.212823  [38432/56940]\n",
      "loss: 0.119964  [41632/56940]\n",
      "loss: 0.286898  [44832/56940]\n",
      "loss: 0.206941  [48032/56940]\n",
      "loss: 0.301944  [51232/56940]\n",
      "loss: 0.296879  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.243149 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.176144  [   32/56940]\n",
      "loss: 0.224634  [ 3232/56940]\n",
      "loss: 0.337485  [ 6432/56940]\n",
      "loss: 0.295050  [ 9632/56940]\n",
      "loss: 0.414326  [12832/56940]\n",
      "loss: 0.281675  [16032/56940]\n",
      "loss: 0.257679  [19232/56940]\n",
      "loss: 0.360080  [22432/56940]\n",
      "loss: 0.242682  [25632/56940]\n",
      "loss: 0.225018  [28832/56940]\n",
      "loss: 0.456864  [32032/56940]\n",
      "loss: 0.181016  [35232/56940]\n",
      "loss: 0.110894  [38432/56940]\n",
      "loss: 0.294564  [41632/56940]\n",
      "loss: 0.225015  [44832/56940]\n",
      "loss: 0.321561  [48032/56940]\n",
      "loss: 0.336023  [51232/56940]\n",
      "loss: 0.152971  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.245244 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.148875  [   32/56940]\n",
      "loss: 0.373736  [ 3232/56940]\n",
      "loss: 0.138862  [ 6432/56940]\n",
      "loss: 0.211735  [ 9632/56940]\n",
      "loss: 0.424777  [12832/56940]\n",
      "loss: 0.653180  [16032/56940]\n",
      "loss: 0.191631  [19232/56940]\n",
      "loss: 0.230575  [22432/56940]\n",
      "loss: 0.489925  [25632/56940]\n",
      "loss: 0.205407  [28832/56940]\n",
      "loss: 0.214031  [32032/56940]\n",
      "loss: 0.330477  [35232/56940]\n",
      "loss: 0.280354  [38432/56940]\n",
      "loss: 0.243942  [41632/56940]\n",
      "loss: 0.370293  [44832/56940]\n",
      "loss: 0.231829  [48032/56940]\n",
      "loss: 0.177810  [51232/56940]\n",
      "loss: 0.615766  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.239850 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.384002  [   32/56940]\n",
      "loss: 0.338461  [ 3232/56940]\n",
      "loss: 0.237062  [ 6432/56940]\n",
      "loss: 0.200739  [ 9632/56940]\n",
      "loss: 0.221171  [12832/56940]\n",
      "loss: 0.096813  [16032/56940]\n",
      "loss: 0.213057  [19232/56940]\n",
      "loss: 0.242041  [22432/56940]\n",
      "loss: 0.309247  [25632/56940]\n",
      "loss: 0.240451  [28832/56940]\n",
      "loss: 0.276610  [32032/56940]\n",
      "loss: 0.210168  [35232/56940]\n",
      "loss: 0.157916  [38432/56940]\n",
      "loss: 0.363944  [41632/56940]\n",
      "loss: 0.295849  [44832/56940]\n",
      "loss: 0.126643  [48032/56940]\n",
      "loss: 0.432311  [51232/56940]\n",
      "loss: 0.187262  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.231445 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.236394  [   32/56940]\n",
      "loss: 0.232804  [ 3232/56940]\n",
      "loss: 0.327275  [ 6432/56940]\n",
      "loss: 0.408464  [ 9632/56940]\n",
      "loss: 0.229874  [12832/56940]\n",
      "loss: 0.273893  [16032/56940]\n",
      "loss: 0.228279  [19232/56940]\n",
      "loss: 0.222416  [22432/56940]\n",
      "loss: 0.282030  [25632/56940]\n",
      "loss: 0.283870  [28832/56940]\n",
      "loss: 0.291797  [32032/56940]\n",
      "loss: 0.321399  [35232/56940]\n",
      "loss: 0.227369  [38432/56940]\n",
      "loss: 0.180816  [41632/56940]\n",
      "loss: 0.389994  [44832/56940]\n",
      "loss: 0.276012  [48032/56940]\n",
      "loss: 0.261945  [51232/56940]\n",
      "loss: 0.292857  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.242463 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.181395  [   32/56940]\n",
      "loss: 0.224202  [ 3232/56940]\n",
      "loss: 0.121833  [ 6432/56940]\n",
      "loss: 0.228458  [ 9632/56940]\n",
      "loss: 0.147757  [12832/56940]\n",
      "loss: 0.330469  [16032/56940]\n",
      "loss: 0.406398  [19232/56940]\n",
      "loss: 0.228536  [22432/56940]\n",
      "loss: 0.481889  [25632/56940]\n",
      "loss: 0.342596  [28832/56940]\n",
      "loss: 0.368597  [32032/56940]\n",
      "loss: 0.221289  [35232/56940]\n",
      "loss: 0.344956  [38432/56940]\n",
      "loss: 0.128498  [41632/56940]\n",
      "loss: 0.282490  [44832/56940]\n",
      "loss: 0.305804  [48032/56940]\n",
      "loss: 0.314925  [51232/56940]\n",
      "loss: 0.164952  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.237138 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.195833  [   32/56940]\n",
      "loss: 0.222081  [ 3232/56940]\n",
      "loss: 0.260267  [ 6432/56940]\n",
      "loss: 0.370192  [ 9632/56940]\n",
      "loss: 0.514147  [12832/56940]\n",
      "loss: 0.203414  [16032/56940]\n",
      "loss: 0.253718  [19232/56940]\n",
      "loss: 0.324689  [22432/56940]\n",
      "loss: 0.337578  [25632/56940]\n",
      "loss: 0.270567  [28832/56940]\n",
      "loss: 0.281196  [32032/56940]\n",
      "loss: 0.288433  [35232/56940]\n",
      "loss: 0.180818  [38432/56940]\n",
      "loss: 0.277512  [41632/56940]\n",
      "loss: 0.275305  [44832/56940]\n",
      "loss: 0.156097  [48032/56940]\n",
      "loss: 0.261987  [51232/56940]\n",
      "loss: 0.377673  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.242130 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.205504  [   32/56940]\n",
      "loss: 0.288890  [ 3232/56940]\n",
      "loss: 0.210982  [ 6432/56940]\n",
      "loss: 0.212523  [ 9632/56940]\n",
      "loss: 0.222757  [12832/56940]\n",
      "loss: 0.159202  [16032/56940]\n",
      "loss: 0.318327  [19232/56940]\n",
      "loss: 0.168856  [22432/56940]\n",
      "loss: 0.152891  [25632/56940]\n",
      "loss: 0.342515  [28832/56940]\n",
      "loss: 0.626450  [32032/56940]\n",
      "loss: 0.436876  [35232/56940]\n",
      "loss: 0.641041  [38432/56940]\n",
      "loss: 0.335273  [41632/56940]\n",
      "loss: 0.250150  [44832/56940]\n",
      "loss: 0.165732  [48032/56940]\n",
      "loss: 0.314974  [51232/56940]\n",
      "loss: 0.299744  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.231270 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.132196  [   32/56940]\n",
      "loss: 0.196530  [ 3232/56940]\n",
      "loss: 0.230575  [ 6432/56940]\n",
      "loss: 0.439621  [ 9632/56940]\n",
      "loss: 0.374781  [12832/56940]\n",
      "loss: 0.296885  [16032/56940]\n",
      "loss: 0.174082  [19232/56940]\n",
      "loss: 0.134388  [22432/56940]\n",
      "loss: 0.300695  [25632/56940]\n",
      "loss: 0.111416  [28832/56940]\n",
      "loss: 0.503174  [32032/56940]\n",
      "loss: 0.274563  [35232/56940]\n",
      "loss: 0.357831  [38432/56940]\n",
      "loss: 0.187784  [41632/56940]\n",
      "loss: 0.118366  [44832/56940]\n",
      "loss: 0.377501  [48032/56940]\n",
      "loss: 0.381644  [51232/56940]\n",
      "loss: 0.279334  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.241675 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.301741  [   32/56940]\n",
      "loss: 0.279610  [ 3232/56940]\n",
      "loss: 0.358438  [ 6432/56940]\n",
      "loss: 0.195748  [ 9632/56940]\n",
      "loss: 0.384782  [12832/56940]\n",
      "loss: 0.224367  [16032/56940]\n",
      "loss: 0.186942  [19232/56940]\n",
      "loss: 0.147795  [22432/56940]\n",
      "loss: 0.422890  [25632/56940]\n",
      "loss: 0.458425  [28832/56940]\n",
      "loss: 0.202386  [32032/56940]\n",
      "loss: 0.316911  [35232/56940]\n",
      "loss: 0.204324  [38432/56940]\n",
      "loss: 0.396397  [41632/56940]\n",
      "loss: 0.297480  [44832/56940]\n",
      "loss: 0.305880  [48032/56940]\n",
      "loss: 0.315192  [51232/56940]\n",
      "loss: 0.293879  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.237026 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.220895  [   32/56940]\n",
      "loss: 0.232959  [ 3232/56940]\n",
      "loss: 0.134122  [ 6432/56940]\n",
      "loss: 0.326481  [ 9632/56940]\n",
      "loss: 0.297058  [12832/56940]\n",
      "loss: 0.214581  [16032/56940]\n",
      "loss: 0.212383  [19232/56940]\n",
      "loss: 0.415069  [22432/56940]\n",
      "loss: 0.247179  [25632/56940]\n",
      "loss: 0.252409  [28832/56940]\n",
      "loss: 0.145842  [32032/56940]\n",
      "loss: 0.164730  [35232/56940]\n",
      "loss: 0.304580  [38432/56940]\n",
      "loss: 0.446012  [41632/56940]\n",
      "loss: 0.323073  [44832/56940]\n",
      "loss: 0.275869  [48032/56940]\n",
      "loss: 0.096213  [51232/56940]\n",
      "loss: 0.469264  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.237943 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.275989  [   32/56940]\n",
      "loss: 0.315950  [ 3232/56940]\n",
      "loss: 0.303021  [ 6432/56940]\n",
      "loss: 0.238315  [ 9632/56940]\n",
      "loss: 0.328254  [12832/56940]\n",
      "loss: 0.196428  [16032/56940]\n",
      "loss: 0.250400  [19232/56940]\n",
      "loss: 0.193097  [22432/56940]\n",
      "loss: 0.143124  [25632/56940]\n",
      "loss: 0.174765  [28832/56940]\n",
      "loss: 0.259725  [32032/56940]\n",
      "loss: 0.260962  [35232/56940]\n",
      "loss: 0.199098  [38432/56940]\n",
      "loss: 0.143439  [41632/56940]\n",
      "loss: 0.320342  [44832/56940]\n",
      "loss: 0.170770  [48032/56940]\n",
      "loss: 0.310453  [51232/56940]\n",
      "loss: 0.446321  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.268040 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.356620  [   32/56940]\n",
      "loss: 0.298957  [ 3232/56940]\n",
      "loss: 0.237749  [ 6432/56940]\n",
      "loss: 0.285974  [ 9632/56940]\n",
      "loss: 0.358551  [12832/56940]\n",
      "loss: 0.240838  [16032/56940]\n",
      "loss: 0.178083  [19232/56940]\n",
      "loss: 0.208731  [22432/56940]\n",
      "loss: 0.348578  [25632/56940]\n",
      "loss: 0.255849  [28832/56940]\n",
      "loss: 0.251151  [32032/56940]\n",
      "loss: 0.254695  [35232/56940]\n",
      "loss: 0.194718  [38432/56940]\n",
      "loss: 0.298948  [41632/56940]\n",
      "loss: 0.249233  [44832/56940]\n",
      "loss: 0.167811  [48032/56940]\n",
      "loss: 0.366552  [51232/56940]\n",
      "loss: 0.355170  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.233368 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.298653  [   32/56940]\n",
      "loss: 0.259163  [ 3232/56940]\n",
      "loss: 0.161847  [ 6432/56940]\n",
      "loss: 0.304505  [ 9632/56940]\n",
      "loss: 0.161645  [12832/56940]\n",
      "loss: 0.450753  [16032/56940]\n",
      "loss: 0.263318  [19232/56940]\n",
      "loss: 0.351444  [22432/56940]\n",
      "loss: 0.411535  [25632/56940]\n",
      "loss: 0.313126  [28832/56940]\n",
      "loss: 0.228372  [32032/56940]\n",
      "loss: 0.411449  [35232/56940]\n",
      "loss: 0.408846  [38432/56940]\n",
      "loss: 0.149302  [41632/56940]\n",
      "loss: 0.409794  [44832/56940]\n",
      "loss: 0.383257  [48032/56940]\n",
      "loss: 0.294219  [51232/56940]\n",
      "loss: 0.491220  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.234941 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.417177  [   32/56940]\n",
      "loss: 0.226792  [ 3232/56940]\n",
      "loss: 0.356995  [ 6432/56940]\n",
      "loss: 0.223690  [ 9632/56940]\n",
      "loss: 0.263587  [12832/56940]\n",
      "loss: 0.420490  [16032/56940]\n",
      "loss: 0.240881  [19232/56940]\n",
      "loss: 0.188630  [22432/56940]\n",
      "loss: 0.294983  [25632/56940]\n",
      "loss: 0.284218  [28832/56940]\n",
      "loss: 0.186349  [32032/56940]\n",
      "loss: 0.261940  [35232/56940]\n",
      "loss: 0.225284  [38432/56940]\n",
      "loss: 0.314303  [41632/56940]\n",
      "loss: 0.350002  [44832/56940]\n",
      "loss: 0.166251  [48032/56940]\n",
      "loss: 0.289192  [51232/56940]\n",
      "loss: 0.218224  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.237074 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.383909  [   32/56940]\n",
      "loss: 0.316867  [ 3232/56940]\n",
      "loss: 0.459830  [ 6432/56940]\n",
      "loss: 0.391858  [ 9632/56940]\n",
      "loss: 0.237132  [12832/56940]\n",
      "loss: 0.231357  [16032/56940]\n",
      "loss: 0.167331  [19232/56940]\n",
      "loss: 0.187738  [22432/56940]\n",
      "loss: 0.137084  [25632/56940]\n",
      "loss: 0.213004  [28832/56940]\n",
      "loss: 0.375217  [32032/56940]\n",
      "loss: 0.259953  [35232/56940]\n",
      "loss: 0.289492  [38432/56940]\n",
      "loss: 0.206219  [41632/56940]\n",
      "loss: 0.497765  [44832/56940]\n",
      "loss: 0.323296  [48032/56940]\n",
      "loss: 0.239753  [51232/56940]\n",
      "loss: 0.257938  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.279540 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.438644  [   32/56940]\n",
      "loss: 0.308894  [ 3232/56940]\n",
      "loss: 0.340119  [ 6432/56940]\n",
      "loss: 0.180614  [ 9632/56940]\n",
      "loss: 0.357228  [12832/56940]\n",
      "loss: 0.265063  [16032/56940]\n",
      "loss: 0.833866  [19232/56940]\n",
      "loss: 0.273827  [22432/56940]\n",
      "loss: 0.225294  [25632/56940]\n",
      "loss: 0.244326  [28832/56940]\n",
      "loss: 0.297282  [32032/56940]\n",
      "loss: 0.279759  [35232/56940]\n",
      "loss: 0.199872  [38432/56940]\n",
      "loss: 0.268065  [41632/56940]\n",
      "loss: 0.516417  [44832/56940]\n",
      "loss: 0.179230  [48032/56940]\n",
      "loss: 0.306657  [51232/56940]\n",
      "loss: 0.225963  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.232917 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.304252  [   32/56940]\n",
      "loss: 0.351846  [ 3232/56940]\n",
      "loss: 0.399501  [ 6432/56940]\n",
      "loss: 0.300068  [ 9632/56940]\n",
      "loss: 0.183758  [12832/56940]\n",
      "loss: 0.351156  [16032/56940]\n",
      "loss: 0.191127  [19232/56940]\n",
      "loss: 0.332021  [22432/56940]\n",
      "loss: 0.162612  [25632/56940]\n",
      "loss: 0.313233  [28832/56940]\n",
      "loss: 0.573273  [32032/56940]\n",
      "loss: 0.337325  [35232/56940]\n",
      "loss: 0.257919  [38432/56940]\n",
      "loss: 0.310306  [41632/56940]\n",
      "loss: 0.404524  [44832/56940]\n",
      "loss: 0.328642  [48032/56940]\n",
      "loss: 0.310576  [51232/56940]\n",
      "loss: 0.398524  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.244706 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.290270  [   32/56940]\n",
      "loss: 0.349605  [ 3232/56940]\n",
      "loss: 0.147215  [ 6432/56940]\n",
      "loss: 0.242221  [ 9632/56940]\n",
      "loss: 0.236339  [12832/56940]\n",
      "loss: 0.334743  [16032/56940]\n",
      "loss: 0.261942  [19232/56940]\n",
      "loss: 0.467854  [22432/56940]\n",
      "loss: 0.248087  [25632/56940]\n",
      "loss: 0.300669  [28832/56940]\n",
      "loss: 0.398677  [32032/56940]\n",
      "loss: 0.181515  [35232/56940]\n",
      "loss: 0.552266  [38432/56940]\n",
      "loss: 0.149101  [41632/56940]\n",
      "loss: 0.330241  [44832/56940]\n",
      "loss: 0.172813  [48032/56940]\n",
      "loss: 0.291576  [51232/56940]\n",
      "loss: 0.353444  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.234026 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.139947  [   32/56940]\n",
      "loss: 0.315877  [ 3232/56940]\n",
      "loss: 0.360237  [ 6432/56940]\n",
      "loss: 0.261341  [ 9632/56940]\n",
      "loss: 0.181322  [12832/56940]\n",
      "loss: 0.234064  [16032/56940]\n",
      "loss: 0.240611  [19232/56940]\n",
      "loss: 0.353358  [22432/56940]\n",
      "loss: 0.161219  [25632/56940]\n",
      "loss: 0.366680  [28832/56940]\n",
      "loss: 0.317753  [32032/56940]\n",
      "loss: 0.575672  [35232/56940]\n",
      "loss: 0.477972  [38432/56940]\n",
      "loss: 0.346586  [41632/56940]\n",
      "loss: 0.240722  [44832/56940]\n",
      "loss: 0.194625  [48032/56940]\n",
      "loss: 0.245636  [51232/56940]\n",
      "loss: 0.327448  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.232317 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.224165  [   32/56940]\n",
      "loss: 0.492340  [ 3232/56940]\n",
      "loss: 0.307963  [ 6432/56940]\n",
      "loss: 0.245679  [ 9632/56940]\n",
      "loss: 0.205282  [12832/56940]\n",
      "loss: 0.248928  [16032/56940]\n",
      "loss: 0.392975  [19232/56940]\n",
      "loss: 0.199805  [22432/56940]\n",
      "loss: 0.161668  [25632/56940]\n",
      "loss: 0.343406  [28832/56940]\n",
      "loss: 0.252401  [32032/56940]\n",
      "loss: 0.372449  [35232/56940]\n",
      "loss: 0.146597  [38432/56940]\n",
      "loss: 0.174556  [41632/56940]\n",
      "loss: 0.358336  [44832/56940]\n",
      "loss: 0.248863  [48032/56940]\n",
      "loss: 0.376567  [51232/56940]\n",
      "loss: 0.434306  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.241709 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.346057  [   32/56940]\n",
      "loss: 0.240321  [ 3232/56940]\n",
      "loss: 0.338575  [ 6432/56940]\n",
      "loss: 0.317582  [ 9632/56940]\n",
      "loss: 0.260107  [12832/56940]\n",
      "loss: 0.156376  [16032/56940]\n",
      "loss: 0.180546  [19232/56940]\n",
      "loss: 0.355590  [22432/56940]\n",
      "loss: 0.224755  [25632/56940]\n",
      "loss: 0.331110  [28832/56940]\n",
      "loss: 0.222299  [32032/56940]\n",
      "loss: 0.459838  [35232/56940]\n",
      "loss: 0.480945  [38432/56940]\n",
      "loss: 0.158324  [41632/56940]\n",
      "loss: 0.489743  [44832/56940]\n",
      "loss: 0.266807  [48032/56940]\n",
      "loss: 0.183146  [51232/56940]\n",
      "loss: 0.156020  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.229060 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.398258  [   32/56940]\n",
      "loss: 0.212426  [ 3232/56940]\n",
      "loss: 0.129827  [ 6432/56940]\n",
      "loss: 0.259017  [ 9632/56940]\n",
      "loss: 0.232102  [12832/56940]\n",
      "loss: 0.246240  [16032/56940]\n",
      "loss: 0.337057  [19232/56940]\n",
      "loss: 0.288946  [22432/56940]\n",
      "loss: 0.201606  [25632/56940]\n",
      "loss: 0.232350  [28832/56940]\n",
      "loss: 0.275651  [32032/56940]\n",
      "loss: 0.177737  [35232/56940]\n",
      "loss: 0.233099  [38432/56940]\n",
      "loss: 0.207116  [41632/56940]\n",
      "loss: 0.210176  [44832/56940]\n",
      "loss: 0.373255  [48032/56940]\n",
      "loss: 0.337822  [51232/56940]\n",
      "loss: 0.342918  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.230529 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.200434  [   32/56940]\n",
      "loss: 0.199172  [ 3232/56940]\n",
      "loss: 0.220047  [ 6432/56940]\n",
      "loss: 0.173560  [ 9632/56940]\n",
      "loss: 0.294654  [12832/56940]\n",
      "loss: 0.250627  [16032/56940]\n",
      "loss: 0.478185  [19232/56940]\n",
      "loss: 0.303814  [22432/56940]\n",
      "loss: 0.391550  [25632/56940]\n",
      "loss: 0.218401  [28832/56940]\n",
      "loss: 0.390847  [32032/56940]\n",
      "loss: 0.294527  [35232/56940]\n",
      "loss: 0.353633  [38432/56940]\n",
      "loss: 0.112106  [41632/56940]\n",
      "loss: 0.309844  [44832/56940]\n",
      "loss: 0.365778  [48032/56940]\n",
      "loss: 0.263915  [51232/56940]\n",
      "loss: 0.204174  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.232728 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.160493  [   32/56940]\n",
      "loss: 0.279345  [ 3232/56940]\n",
      "loss: 0.359560  [ 6432/56940]\n",
      "loss: 0.380818  [ 9632/56940]\n",
      "loss: 0.626490  [12832/56940]\n",
      "loss: 0.379284  [16032/56940]\n",
      "loss: 0.258953  [19232/56940]\n",
      "loss: 0.280086  [22432/56940]\n",
      "loss: 0.182359  [25632/56940]\n",
      "loss: 0.193637  [28832/56940]\n",
      "loss: 0.450076  [32032/56940]\n",
      "loss: 0.229489  [35232/56940]\n",
      "loss: 0.259072  [38432/56940]\n",
      "loss: 0.244012  [41632/56940]\n",
      "loss: 0.267868  [44832/56940]\n",
      "loss: 0.276199  [48032/56940]\n",
      "loss: 0.261623  [51232/56940]\n",
      "loss: 0.504882  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.240628 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.262597  [   32/56940]\n",
      "loss: 0.248574  [ 3232/56940]\n",
      "loss: 0.283699  [ 6432/56940]\n",
      "loss: 0.313840  [ 9632/56940]\n",
      "loss: 0.217375  [12832/56940]\n",
      "loss: 0.373476  [16032/56940]\n",
      "loss: 0.295711  [19232/56940]\n",
      "loss: 0.240575  [22432/56940]\n",
      "loss: 0.200599  [25632/56940]\n",
      "loss: 0.245575  [28832/56940]\n",
      "loss: 0.161981  [32032/56940]\n",
      "loss: 0.168728  [35232/56940]\n",
      "loss: 0.216731  [38432/56940]\n",
      "loss: 0.208115  [41632/56940]\n",
      "loss: 0.194615  [44832/56940]\n",
      "loss: 0.189996  [48032/56940]\n",
      "loss: 0.364805  [51232/56940]\n",
      "loss: 0.388777  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.243350 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.281651  [   32/56940]\n",
      "loss: 0.144720  [ 3232/56940]\n",
      "loss: 0.255254  [ 6432/56940]\n",
      "loss: 0.279425  [ 9632/56940]\n",
      "loss: 0.277308  [12832/56940]\n",
      "loss: 0.419450  [16032/56940]\n",
      "loss: 0.369789  [19232/56940]\n",
      "loss: 0.295441  [22432/56940]\n",
      "loss: 0.261123  [25632/56940]\n",
      "loss: 0.314648  [28832/56940]\n",
      "loss: 0.290146  [32032/56940]\n",
      "loss: 0.260602  [35232/56940]\n",
      "loss: 0.227465  [38432/56940]\n",
      "loss: 0.473353  [41632/56940]\n",
      "loss: 0.258531  [44832/56940]\n",
      "loss: 0.229147  [48032/56940]\n",
      "loss: 0.200158  [51232/56940]\n",
      "loss: 0.211497  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.232001 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.263869  [   32/56940]\n",
      "loss: 0.237749  [ 3232/56940]\n",
      "loss: 0.358222  [ 6432/56940]\n",
      "loss: 0.271219  [ 9632/56940]\n",
      "loss: 0.189876  [12832/56940]\n",
      "loss: 0.281293  [16032/56940]\n",
      "loss: 0.150198  [19232/56940]\n",
      "loss: 0.227241  [22432/56940]\n",
      "loss: 0.187935  [25632/56940]\n",
      "loss: 0.247223  [28832/56940]\n",
      "loss: 0.207772  [32032/56940]\n",
      "loss: 0.157472  [35232/56940]\n",
      "loss: 0.205861  [38432/56940]\n",
      "loss: 0.273834  [41632/56940]\n",
      "loss: 0.286725  [44832/56940]\n",
      "loss: 0.504583  [48032/56940]\n",
      "loss: 0.175161  [51232/56940]\n",
      "loss: 0.277881  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.238635 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.179346  [   32/56940]\n",
      "loss: 0.416131  [ 3232/56940]\n",
      "loss: 0.136682  [ 6432/56940]\n",
      "loss: 0.288553  [ 9632/56940]\n",
      "loss: 0.163405  [12832/56940]\n",
      "loss: 0.188421  [16032/56940]\n",
      "loss: 0.245253  [19232/56940]\n",
      "loss: 0.158835  [22432/56940]\n",
      "loss: 0.194164  [25632/56940]\n",
      "loss: 0.234907  [28832/56940]\n",
      "loss: 0.244216  [32032/56940]\n",
      "loss: 0.252583  [35232/56940]\n",
      "loss: 0.201002  [38432/56940]\n",
      "loss: 0.229647  [41632/56940]\n",
      "loss: 0.272455  [44832/56940]\n",
      "loss: 0.466742  [48032/56940]\n",
      "loss: 0.467676  [51232/56940]\n",
      "loss: 0.480241  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.250482 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.330209  [   32/56940]\n",
      "loss: 0.428743  [ 3232/56940]\n",
      "loss: 0.379142  [ 6432/56940]\n",
      "loss: 0.355021  [ 9632/56940]\n",
      "loss: 0.308075  [12832/56940]\n",
      "loss: 0.238059  [16032/56940]\n",
      "loss: 0.255504  [19232/56940]\n",
      "loss: 0.212200  [22432/56940]\n",
      "loss: 0.268224  [25632/56940]\n",
      "loss: 0.339744  [28832/56940]\n",
      "loss: 0.395046  [32032/56940]\n",
      "loss: 0.256668  [35232/56940]\n",
      "loss: 0.334336  [38432/56940]\n",
      "loss: 0.159552  [41632/56940]\n",
      "loss: 0.263177  [44832/56940]\n",
      "loss: 0.397918  [48032/56940]\n",
      "loss: 0.146320  [51232/56940]\n",
      "loss: 0.657558  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.231574 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.238543  [   32/56940]\n",
      "loss: 0.253703  [ 3232/56940]\n",
      "loss: 0.376326  [ 6432/56940]\n",
      "loss: 0.215836  [ 9632/56940]\n",
      "loss: 0.432937  [12832/56940]\n",
      "loss: 0.169711  [16032/56940]\n",
      "loss: 0.420265  [19232/56940]\n",
      "loss: 0.351828  [22432/56940]\n",
      "loss: 0.206171  [25632/56940]\n",
      "loss: 0.235942  [28832/56940]\n",
      "loss: 0.134539  [32032/56940]\n",
      "loss: 0.284837  [35232/56940]\n",
      "loss: 0.219386  [38432/56940]\n",
      "loss: 0.197396  [41632/56940]\n",
      "loss: 0.231805  [44832/56940]\n",
      "loss: 0.716989  [48032/56940]\n",
      "loss: 0.183681  [51232/56940]\n",
      "loss: 0.137850  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.232172 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.325005  [   32/56940]\n",
      "loss: 0.172652  [ 3232/56940]\n",
      "loss: 0.316347  [ 6432/56940]\n",
      "loss: 0.091769  [ 9632/56940]\n",
      "loss: 0.426209  [12832/56940]\n",
      "loss: 0.612818  [16032/56940]\n",
      "loss: 0.179028  [19232/56940]\n",
      "loss: 0.607218  [22432/56940]\n",
      "loss: 0.381236  [25632/56940]\n",
      "loss: 0.234758  [28832/56940]\n",
      "loss: 0.440771  [32032/56940]\n",
      "loss: 0.252719  [35232/56940]\n",
      "loss: 0.346260  [38432/56940]\n",
      "loss: 0.488197  [41632/56940]\n",
      "loss: 0.505724  [44832/56940]\n",
      "loss: 0.245965  [48032/56940]\n",
      "loss: 0.179481  [51232/56940]\n",
      "loss: 0.354633  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.230661 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.380305  [   32/56940]\n",
      "loss: 0.154884  [ 3232/56940]\n",
      "loss: 0.207069  [ 6432/56940]\n",
      "loss: 0.368600  [ 9632/56940]\n",
      "loss: 0.194524  [12832/56940]\n",
      "loss: 0.300779  [16032/56940]\n",
      "loss: 0.265285  [19232/56940]\n",
      "loss: 0.396343  [22432/56940]\n",
      "loss: 0.205539  [25632/56940]\n",
      "loss: 0.276255  [28832/56940]\n",
      "loss: 0.321629  [32032/56940]\n",
      "loss: 0.272001  [35232/56940]\n",
      "loss: 0.166689  [38432/56940]\n",
      "loss: 0.330183  [41632/56940]\n",
      "loss: 0.244739  [44832/56940]\n",
      "loss: 0.098993  [48032/56940]\n",
      "loss: 0.224034  [51232/56940]\n",
      "loss: 0.385248  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.240062 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.219264  [   32/56940]\n",
      "loss: 0.153202  [ 3232/56940]\n",
      "loss: 0.433130  [ 6432/56940]\n",
      "loss: 0.079880  [ 9632/56940]\n",
      "loss: 0.247090  [12832/56940]\n",
      "loss: 0.268339  [16032/56940]\n",
      "loss: 0.421549  [19232/56940]\n",
      "loss: 0.359469  [22432/56940]\n",
      "loss: 0.202129  [25632/56940]\n",
      "loss: 0.257510  [28832/56940]\n",
      "loss: 0.264091  [32032/56940]\n",
      "loss: 0.264009  [35232/56940]\n",
      "loss: 0.154072  [38432/56940]\n",
      "loss: 0.173310  [41632/56940]\n",
      "loss: 0.284024  [44832/56940]\n",
      "loss: 0.290017  [48032/56940]\n",
      "loss: 0.180316  [51232/56940]\n",
      "loss: 0.418429  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.260195 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.227330  [   32/56940]\n",
      "loss: 0.185248  [ 3232/56940]\n",
      "loss: 0.195241  [ 6432/56940]\n",
      "loss: 0.252062  [ 9632/56940]\n",
      "loss: 0.300179  [12832/56940]\n",
      "loss: 0.183341  [16032/56940]\n",
      "loss: 0.166751  [19232/56940]\n",
      "loss: 0.332613  [22432/56940]\n",
      "loss: 0.142217  [25632/56940]\n",
      "loss: 0.265680  [28832/56940]\n",
      "loss: 0.229710  [32032/56940]\n",
      "loss: 0.170617  [35232/56940]\n",
      "loss: 0.343173  [38432/56940]\n",
      "loss: 0.236987  [41632/56940]\n",
      "loss: 0.257816  [44832/56940]\n",
      "loss: 0.286141  [48032/56940]\n",
      "loss: 0.139034  [51232/56940]\n",
      "loss: 0.170433  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.226195 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.373796  [   32/56940]\n",
      "loss: 0.371930  [ 3232/56940]\n",
      "loss: 0.304041  [ 6432/56940]\n",
      "loss: 0.193789  [ 9632/56940]\n",
      "loss: 0.547802  [12832/56940]\n",
      "loss: 0.289910  [16032/56940]\n",
      "loss: 0.214977  [19232/56940]\n",
      "loss: 0.276911  [22432/56940]\n",
      "loss: 0.262447  [25632/56940]\n",
      "loss: 0.309874  [28832/56940]\n",
      "loss: 0.293446  [32032/56940]\n",
      "loss: 0.314376  [35232/56940]\n",
      "loss: 0.141226  [38432/56940]\n",
      "loss: 0.510020  [41632/56940]\n",
      "loss: 0.316938  [44832/56940]\n",
      "loss: 0.358492  [48032/56940]\n",
      "loss: 0.170878  [51232/56940]\n",
      "loss: 0.253178  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.242504 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.173235  [   32/56940]\n",
      "loss: 0.307515  [ 3232/56940]\n",
      "loss: 0.268825  [ 6432/56940]\n",
      "loss: 0.280418  [ 9632/56940]\n",
      "loss: 0.356177  [12832/56940]\n",
      "loss: 0.232764  [16032/56940]\n",
      "loss: 0.231970  [19232/56940]\n",
      "loss: 0.274051  [22432/56940]\n",
      "loss: 0.360301  [25632/56940]\n",
      "loss: 0.360088  [28832/56940]\n",
      "loss: 0.205800  [32032/56940]\n",
      "loss: 0.389578  [35232/56940]\n",
      "loss: 0.176450  [38432/56940]\n",
      "loss: 0.209074  [41632/56940]\n",
      "loss: 0.214161  [44832/56940]\n",
      "loss: 0.146171  [48032/56940]\n",
      "loss: 0.232078  [51232/56940]\n",
      "loss: 0.433860  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.269413 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.129001  [   32/56940]\n",
      "loss: 0.458744  [ 3232/56940]\n",
      "loss: 0.231252  [ 6432/56940]\n",
      "loss: 0.152995  [ 9632/56940]\n",
      "loss: 0.283613  [12832/56940]\n",
      "loss: 0.364907  [16032/56940]\n",
      "loss: 0.147966  [19232/56940]\n",
      "loss: 0.244288  [22432/56940]\n",
      "loss: 0.172401  [25632/56940]\n",
      "loss: 0.279688  [28832/56940]\n",
      "loss: 0.192348  [32032/56940]\n",
      "loss: 0.201434  [35232/56940]\n",
      "loss: 0.320118  [38432/56940]\n",
      "loss: 0.506671  [41632/56940]\n",
      "loss: 0.352602  [44832/56940]\n",
      "loss: 0.418260  [48032/56940]\n",
      "loss: 0.388281  [51232/56940]\n",
      "loss: 0.257031  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.230611 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.178630  [   32/56940]\n",
      "loss: 0.317174  [ 3232/56940]\n",
      "loss: 0.332651  [ 6432/56940]\n",
      "loss: 0.268707  [ 9632/56940]\n",
      "loss: 0.666878  [12832/56940]\n",
      "loss: 0.175391  [16032/56940]\n",
      "loss: 0.302189  [19232/56940]\n",
      "loss: 0.101616  [22432/56940]\n",
      "loss: 0.208991  [25632/56940]\n",
      "loss: 0.292777  [28832/56940]\n",
      "loss: 0.347444  [32032/56940]\n",
      "loss: 0.198078  [35232/56940]\n",
      "loss: 0.234792  [38432/56940]\n",
      "loss: 0.323591  [41632/56940]\n",
      "loss: 0.209249  [44832/56940]\n",
      "loss: 0.223122  [48032/56940]\n",
      "loss: 0.356761  [51232/56940]\n",
      "loss: 0.157260  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.235660 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.197552  [   32/56940]\n",
      "loss: 0.303355  [ 3232/56940]\n",
      "loss: 0.181289  [ 6432/56940]\n",
      "loss: 0.183568  [ 9632/56940]\n",
      "loss: 0.494565  [12832/56940]\n",
      "loss: 0.292924  [16032/56940]\n",
      "loss: 0.229276  [19232/56940]\n",
      "loss: 0.113977  [22432/56940]\n",
      "loss: 0.113484  [25632/56940]\n",
      "loss: 0.349764  [28832/56940]\n",
      "loss: 0.546120  [32032/56940]\n",
      "loss: 0.315522  [35232/56940]\n",
      "loss: 0.224568  [38432/56940]\n",
      "loss: 0.177679  [41632/56940]\n",
      "loss: 0.482001  [44832/56940]\n",
      "loss: 0.224659  [48032/56940]\n",
      "loss: 0.418298  [51232/56940]\n",
      "loss: 0.260679  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.228306 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.281970  [   32/56940]\n",
      "loss: 0.321383  [ 3232/56940]\n",
      "loss: 0.168441  [ 6432/56940]\n",
      "loss: 0.336868  [ 9632/56940]\n",
      "loss: 0.183378  [12832/56940]\n",
      "loss: 0.229518  [16032/56940]\n",
      "loss: 0.569064  [19232/56940]\n",
      "loss: 0.556282  [22432/56940]\n",
      "loss: 0.327566  [25632/56940]\n",
      "loss: 0.176883  [28832/56940]\n",
      "loss: 0.411063  [32032/56940]\n",
      "loss: 0.197129  [35232/56940]\n",
      "loss: 0.357241  [38432/56940]\n",
      "loss: 0.471031  [41632/56940]\n",
      "loss: 0.167144  [44832/56940]\n",
      "loss: 0.431318  [48032/56940]\n",
      "loss: 0.196304  [51232/56940]\n",
      "loss: 0.582422  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.232214 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.144096  [   32/56940]\n",
      "loss: 0.220873  [ 3232/56940]\n",
      "loss: 0.346413  [ 6432/56940]\n",
      "loss: 0.198303  [ 9632/56940]\n",
      "loss: 0.137823  [12832/56940]\n",
      "loss: 0.199171  [16032/56940]\n",
      "loss: 0.287773  [19232/56940]\n",
      "loss: 0.169558  [22432/56940]\n",
      "loss: 0.215529  [25632/56940]\n",
      "loss: 0.147022  [28832/56940]\n",
      "loss: 0.326992  [32032/56940]\n",
      "loss: 0.231638  [35232/56940]\n",
      "loss: 0.152107  [38432/56940]\n",
      "loss: 0.178637  [41632/56940]\n",
      "loss: 0.106563  [44832/56940]\n",
      "loss: 0.359451  [48032/56940]\n",
      "loss: 0.428712  [51232/56940]\n",
      "loss: 0.156812  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.227429 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.136811  [   32/56940]\n",
      "loss: 0.316583  [ 3232/56940]\n",
      "loss: 0.297779  [ 6432/56940]\n",
      "loss: 0.224858  [ 9632/56940]\n",
      "loss: 0.195319  [12832/56940]\n",
      "loss: 0.154266  [16032/56940]\n",
      "loss: 0.135300  [19232/56940]\n",
      "loss: 0.185551  [22432/56940]\n",
      "loss: 0.171867  [25632/56940]\n",
      "loss: 0.476801  [28832/56940]\n",
      "loss: 0.331783  [32032/56940]\n",
      "loss: 0.381318  [35232/56940]\n",
      "loss: 0.289797  [38432/56940]\n",
      "loss: 0.270923  [41632/56940]\n",
      "loss: 0.292115  [44832/56940]\n",
      "loss: 0.257283  [48032/56940]\n",
      "loss: 0.449290  [51232/56940]\n",
      "loss: 0.310360  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.226779 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.174608  [   32/56940]\n",
      "loss: 0.276398  [ 3232/56940]\n",
      "loss: 0.149495  [ 6432/56940]\n",
      "loss: 0.247972  [ 9632/56940]\n",
      "loss: 0.195272  [12832/56940]\n",
      "loss: 0.267436  [16032/56940]\n",
      "loss: 0.173884  [19232/56940]\n",
      "loss: 0.420484  [22432/56940]\n",
      "loss: 0.161381  [25632/56940]\n",
      "loss: 0.247551  [28832/56940]\n",
      "loss: 0.206781  [32032/56940]\n",
      "loss: 0.193799  [35232/56940]\n",
      "loss: 0.448204  [38432/56940]\n",
      "loss: 0.208039  [41632/56940]\n",
      "loss: 0.392629  [44832/56940]\n",
      "loss: 0.180782  [48032/56940]\n",
      "loss: 0.455221  [51232/56940]\n",
      "loss: 0.302341  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.230609 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.300071  [   32/56940]\n",
      "loss: 0.263272  [ 3232/56940]\n",
      "loss: 0.267164  [ 6432/56940]\n",
      "loss: 0.233837  [ 9632/56940]\n",
      "loss: 0.196382  [12832/56940]\n",
      "loss: 0.310641  [16032/56940]\n",
      "loss: 0.319810  [19232/56940]\n",
      "loss: 0.505340  [22432/56940]\n",
      "loss: 0.500989  [25632/56940]\n",
      "loss: 0.258841  [28832/56940]\n",
      "loss: 0.361728  [32032/56940]\n",
      "loss: 0.217247  [35232/56940]\n",
      "loss: 0.168920  [38432/56940]\n",
      "loss: 0.241333  [41632/56940]\n",
      "loss: 0.339197  [44832/56940]\n",
      "loss: 0.381774  [48032/56940]\n",
      "loss: 0.144179  [51232/56940]\n",
      "loss: 0.140961  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.259504 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.164511  [   32/56940]\n",
      "loss: 0.253424  [ 3232/56940]\n",
      "loss: 0.255104  [ 6432/56940]\n",
      "loss: 0.226816  [ 9632/56940]\n",
      "loss: 0.137677  [12832/56940]\n",
      "loss: 0.219762  [16032/56940]\n",
      "loss: 0.173576  [19232/56940]\n",
      "loss: 0.213768  [22432/56940]\n",
      "loss: 0.114605  [25632/56940]\n",
      "loss: 0.420106  [28832/56940]\n",
      "loss: 0.181551  [32032/56940]\n",
      "loss: 0.275021  [35232/56940]\n",
      "loss: 0.335275  [38432/56940]\n",
      "loss: 0.395343  [41632/56940]\n",
      "loss: 0.185681  [44832/56940]\n",
      "loss: 0.382916  [48032/56940]\n",
      "loss: 0.630192  [51232/56940]\n",
      "loss: 0.508758  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.231155 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.242570  [   32/56940]\n",
      "loss: 0.169431  [ 3232/56940]\n",
      "loss: 0.200382  [ 6432/56940]\n",
      "loss: 0.322643  [ 9632/56940]\n",
      "loss: 0.109687  [12832/56940]\n",
      "loss: 0.430760  [16032/56940]\n",
      "loss: 0.197716  [19232/56940]\n",
      "loss: 0.371992  [22432/56940]\n",
      "loss: 0.185254  [25632/56940]\n",
      "loss: 0.373272  [28832/56940]\n",
      "loss: 0.189857  [32032/56940]\n",
      "loss: 0.337301  [35232/56940]\n",
      "loss: 0.332171  [38432/56940]\n",
      "loss: 0.359730  [41632/56940]\n",
      "loss: 0.264636  [44832/56940]\n",
      "loss: 0.279777  [48032/56940]\n",
      "loss: 0.173742  [51232/56940]\n",
      "loss: 0.180955  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.225474 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.263830  [   32/56940]\n",
      "loss: 0.438447  [ 3232/56940]\n",
      "loss: 0.709383  [ 6432/56940]\n",
      "loss: 0.241464  [ 9632/56940]\n",
      "loss: 0.221931  [12832/56940]\n",
      "loss: 0.270011  [16032/56940]\n",
      "loss: 0.207357  [19232/56940]\n",
      "loss: 0.251988  [22432/56940]\n",
      "loss: 0.189832  [25632/56940]\n",
      "loss: 0.190392  [28832/56940]\n",
      "loss: 0.342757  [32032/56940]\n",
      "loss: 0.149912  [35232/56940]\n",
      "loss: 0.177035  [38432/56940]\n",
      "loss: 0.188837  [41632/56940]\n",
      "loss: 0.439231  [44832/56940]\n",
      "loss: 0.248556  [48032/56940]\n",
      "loss: 0.206385  [51232/56940]\n",
      "loss: 0.225193  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.233608 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.269978  [   32/56940]\n",
      "loss: 0.369253  [ 3232/56940]\n",
      "loss: 0.273494  [ 6432/56940]\n",
      "loss: 0.212888  [ 9632/56940]\n",
      "loss: 0.257100  [12832/56940]\n",
      "loss: 0.252513  [16032/56940]\n",
      "loss: 0.092580  [19232/56940]\n",
      "loss: 0.164041  [22432/56940]\n",
      "loss: 0.315389  [25632/56940]\n",
      "loss: 0.216195  [28832/56940]\n",
      "loss: 0.143599  [32032/56940]\n",
      "loss: 0.165458  [35232/56940]\n",
      "loss: 0.286089  [38432/56940]\n",
      "loss: 0.117859  [41632/56940]\n",
      "loss: 0.193579  [44832/56940]\n",
      "loss: 0.338079  [48032/56940]\n",
      "loss: 0.199778  [51232/56940]\n",
      "loss: 0.458690  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.237191 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.404698  [   32/56940]\n",
      "loss: 0.422720  [ 3232/56940]\n",
      "loss: 0.146872  [ 6432/56940]\n",
      "loss: 0.430454  [ 9632/56940]\n",
      "loss: 0.276200  [12832/56940]\n",
      "loss: 0.267782  [16032/56940]\n",
      "loss: 0.151256  [19232/56940]\n",
      "loss: 0.163617  [22432/56940]\n",
      "loss: 0.344107  [25632/56940]\n",
      "loss: 0.110705  [28832/56940]\n",
      "loss: 0.265455  [32032/56940]\n",
      "loss: 0.361971  [35232/56940]\n",
      "loss: 0.266480  [38432/56940]\n",
      "loss: 0.194373  [41632/56940]\n",
      "loss: 0.129554  [44832/56940]\n",
      "loss: 0.253736  [48032/56940]\n",
      "loss: 0.573152  [51232/56940]\n",
      "loss: 0.197573  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.226563 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.240651  [   32/56940]\n",
      "loss: 0.366509  [ 3232/56940]\n",
      "loss: 0.260675  [ 6432/56940]\n",
      "loss: 0.321390  [ 9632/56940]\n",
      "loss: 0.129599  [12832/56940]\n",
      "loss: 0.378688  [16032/56940]\n",
      "loss: 0.325305  [19232/56940]\n",
      "loss: 0.239163  [22432/56940]\n",
      "loss: 0.229495  [25632/56940]\n",
      "loss: 0.240402  [28832/56940]\n",
      "loss: 0.203891  [32032/56940]\n",
      "loss: 0.290477  [35232/56940]\n",
      "loss: 0.286122  [38432/56940]\n",
      "loss: 0.344849  [41632/56940]\n",
      "loss: 0.278003  [44832/56940]\n",
      "loss: 0.289850  [48032/56940]\n",
      "loss: 0.232134  [51232/56940]\n",
      "loss: 0.192533  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.226062 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.254345  [   32/56940]\n",
      "loss: 0.211502  [ 3232/56940]\n",
      "loss: 0.297634  [ 6432/56940]\n",
      "loss: 0.185148  [ 9632/56940]\n",
      "loss: 0.232393  [12832/56940]\n",
      "loss: 0.120154  [16032/56940]\n",
      "loss: 0.138676  [19232/56940]\n",
      "loss: 0.466037  [22432/56940]\n",
      "loss: 0.231496  [25632/56940]\n",
      "loss: 0.129868  [28832/56940]\n",
      "loss: 0.154335  [32032/56940]\n",
      "loss: 0.314866  [35232/56940]\n",
      "loss: 0.314145  [38432/56940]\n",
      "loss: 0.242039  [41632/56940]\n",
      "loss: 0.247779  [44832/56940]\n",
      "loss: 0.262483  [48032/56940]\n",
      "loss: 0.184102  [51232/56940]\n",
      "loss: 0.252017  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.224894 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.136445  [   32/56940]\n",
      "loss: 0.361909  [ 3232/56940]\n",
      "loss: 0.192318  [ 6432/56940]\n",
      "loss: 0.338361  [ 9632/56940]\n",
      "loss: 0.281617  [12832/56940]\n",
      "loss: 0.112559  [16032/56940]\n",
      "loss: 0.161322  [19232/56940]\n",
      "loss: 0.494977  [22432/56940]\n",
      "loss: 0.203195  [25632/56940]\n",
      "loss: 0.184870  [28832/56940]\n",
      "loss: 0.237002  [32032/56940]\n",
      "loss: 0.319425  [35232/56940]\n",
      "loss: 0.266553  [38432/56940]\n",
      "loss: 0.184289  [41632/56940]\n",
      "loss: 0.239935  [44832/56940]\n",
      "loss: 0.106508  [48032/56940]\n",
      "loss: 0.284589  [51232/56940]\n",
      "loss: 0.140603  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.229285 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.294289  [   32/56940]\n",
      "loss: 0.241345  [ 3232/56940]\n",
      "loss: 0.288573  [ 6432/56940]\n",
      "loss: 0.211216  [ 9632/56940]\n",
      "loss: 0.329520  [12832/56940]\n",
      "loss: 0.315781  [16032/56940]\n",
      "loss: 0.179394  [19232/56940]\n",
      "loss: 0.286100  [22432/56940]\n",
      "loss: 0.146097  [25632/56940]\n",
      "loss: 0.158883  [28832/56940]\n",
      "loss: 0.243144  [32032/56940]\n",
      "loss: 0.213920  [35232/56940]\n",
      "loss: 0.196267  [38432/56940]\n",
      "loss: 0.286725  [41632/56940]\n",
      "loss: 0.171758  [44832/56940]\n",
      "loss: 0.263427  [48032/56940]\n",
      "loss: 0.260514  [51232/56940]\n",
      "loss: 0.177486  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.242305 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.221442  [   32/56940]\n",
      "loss: 0.291153  [ 3232/56940]\n",
      "loss: 0.300351  [ 6432/56940]\n",
      "loss: 0.284142  [ 9632/56940]\n",
      "loss: 0.323540  [12832/56940]\n",
      "loss: 0.269657  [16032/56940]\n",
      "loss: 0.347749  [19232/56940]\n",
      "loss: 0.188785  [22432/56940]\n",
      "loss: 0.145363  [25632/56940]\n",
      "loss: 0.414762  [28832/56940]\n",
      "loss: 0.364523  [32032/56940]\n",
      "loss: 0.187802  [35232/56940]\n",
      "loss: 0.282609  [38432/56940]\n",
      "loss: 0.318374  [41632/56940]\n",
      "loss: 0.176131  [44832/56940]\n",
      "loss: 0.085835  [48032/56940]\n",
      "loss: 0.195816  [51232/56940]\n",
      "loss: 0.406667  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.227766 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.297865  [   32/56940]\n",
      "loss: 0.352597  [ 3232/56940]\n",
      "loss: 0.112664  [ 6432/56940]\n",
      "loss: 0.212067  [ 9632/56940]\n",
      "loss: 0.223680  [12832/56940]\n",
      "loss: 0.287715  [16032/56940]\n",
      "loss: 0.247879  [19232/56940]\n",
      "loss: 0.302555  [22432/56940]\n",
      "loss: 0.321158  [25632/56940]\n",
      "loss: 0.392584  [28832/56940]\n",
      "loss: 0.177349  [32032/56940]\n",
      "loss: 0.185054  [35232/56940]\n",
      "loss: 0.160965  [38432/56940]\n",
      "loss: 0.451546  [41632/56940]\n",
      "loss: 0.181043  [44832/56940]\n",
      "loss: 0.242783  [48032/56940]\n",
      "loss: 0.431659  [51232/56940]\n",
      "loss: 0.260170  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.226547 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.333193  [   32/56940]\n",
      "loss: 0.207185  [ 3232/56940]\n",
      "loss: 0.192385  [ 6432/56940]\n",
      "loss: 0.176412  [ 9632/56940]\n",
      "loss: 0.235855  [12832/56940]\n",
      "loss: 0.201668  [16032/56940]\n",
      "loss: 0.210410  [19232/56940]\n",
      "loss: 0.191582  [22432/56940]\n",
      "loss: 0.201629  [25632/56940]\n",
      "loss: 0.284233  [28832/56940]\n",
      "loss: 0.125144  [32032/56940]\n",
      "loss: 0.310325  [35232/56940]\n",
      "loss: 0.127763  [38432/56940]\n",
      "loss: 0.097127  [41632/56940]\n",
      "loss: 0.176745  [44832/56940]\n",
      "loss: 0.409620  [48032/56940]\n",
      "loss: 0.444600  [51232/56940]\n",
      "loss: 0.265072  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.227781 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.126248  [   32/56940]\n",
      "loss: 0.444350  [ 3232/56940]\n",
      "loss: 0.337270  [ 6432/56940]\n",
      "loss: 0.244512  [ 9632/56940]\n",
      "loss: 0.380070  [12832/56940]\n",
      "loss: 0.271407  [16032/56940]\n",
      "loss: 0.178217  [19232/56940]\n",
      "loss: 0.232602  [22432/56940]\n",
      "loss: 0.290060  [25632/56940]\n",
      "loss: 0.319627  [28832/56940]\n",
      "loss: 0.222314  [32032/56940]\n",
      "loss: 0.333739  [35232/56940]\n",
      "loss: 0.400873  [38432/56940]\n",
      "loss: 0.309702  [41632/56940]\n",
      "loss: 0.280457  [44832/56940]\n",
      "loss: 0.260870  [48032/56940]\n",
      "loss: 0.365415  [51232/56940]\n",
      "loss: 0.143388  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.241606 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.255387  [   32/56940]\n",
      "loss: 0.152250  [ 3232/56940]\n",
      "loss: 0.223722  [ 6432/56940]\n",
      "loss: 0.202964  [ 9632/56940]\n",
      "loss: 0.454522  [12832/56940]\n",
      "loss: 0.189755  [16032/56940]\n",
      "loss: 0.214195  [19232/56940]\n",
      "loss: 0.238598  [22432/56940]\n",
      "loss: 0.621661  [25632/56940]\n",
      "loss: 0.140901  [28832/56940]\n",
      "loss: 0.212566  [32032/56940]\n",
      "loss: 0.304598  [35232/56940]\n",
      "loss: 0.272029  [38432/56940]\n",
      "loss: 0.222478  [41632/56940]\n",
      "loss: 0.476165  [44832/56940]\n",
      "loss: 0.155909  [48032/56940]\n",
      "loss: 0.210558  [51232/56940]\n",
      "loss: 0.205511  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.221876 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.447463  [   32/56940]\n",
      "loss: 0.162287  [ 3232/56940]\n",
      "loss: 0.330336  [ 6432/56940]\n",
      "loss: 0.435276  [ 9632/56940]\n",
      "loss: 0.322678  [12832/56940]\n",
      "loss: 0.447305  [16032/56940]\n",
      "loss: 0.157311  [19232/56940]\n",
      "loss: 0.210323  [22432/56940]\n",
      "loss: 0.207712  [25632/56940]\n",
      "loss: 0.236298  [28832/56940]\n",
      "loss: 0.343876  [32032/56940]\n",
      "loss: 0.247668  [35232/56940]\n",
      "loss: 0.139145  [38432/56940]\n",
      "loss: 0.126725  [41632/56940]\n",
      "loss: 0.279166  [44832/56940]\n",
      "loss: 0.203015  [48032/56940]\n",
      "loss: 0.319938  [51232/56940]\n",
      "loss: 0.388323  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.216632 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.332357  [   32/56940]\n",
      "loss: 0.514920  [ 3232/56940]\n",
      "loss: 0.129944  [ 6432/56940]\n",
      "loss: 0.162136  [ 9632/56940]\n",
      "loss: 0.342359  [12832/56940]\n",
      "loss: 0.260993  [16032/56940]\n",
      "loss: 0.139834  [19232/56940]\n",
      "loss: 0.240278  [22432/56940]\n",
      "loss: 0.253207  [25632/56940]\n",
      "loss: 0.531280  [28832/56940]\n",
      "loss: 0.318259  [32032/56940]\n",
      "loss: 0.355758  [35232/56940]\n",
      "loss: 0.271223  [38432/56940]\n",
      "loss: 0.470751  [41632/56940]\n",
      "loss: 0.408559  [44832/56940]\n",
      "loss: 0.221718  [48032/56940]\n",
      "loss: 0.246925  [51232/56940]\n",
      "loss: 0.173944  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.223261 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.290479  [   32/56940]\n",
      "loss: 0.222296  [ 3232/56940]\n",
      "loss: 0.349776  [ 6432/56940]\n",
      "loss: 0.449706  [ 9632/56940]\n",
      "loss: 0.504821  [12832/56940]\n",
      "loss: 0.318654  [16032/56940]\n",
      "loss: 0.297872  [19232/56940]\n",
      "loss: 0.229732  [22432/56940]\n",
      "loss: 0.414033  [25632/56940]\n",
      "loss: 0.424392  [28832/56940]\n",
      "loss: 0.419195  [32032/56940]\n",
      "loss: 0.215305  [35232/56940]\n",
      "loss: 0.205924  [38432/56940]\n",
      "loss: 0.198910  [41632/56940]\n",
      "loss: 0.275013  [44832/56940]\n",
      "loss: 0.214082  [48032/56940]\n",
      "loss: 0.165200  [51232/56940]\n",
      "loss: 0.160427  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.238568 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.171411  [   32/56940]\n",
      "loss: 0.347723  [ 3232/56940]\n",
      "loss: 0.533996  [ 6432/56940]\n",
      "loss: 0.172813  [ 9632/56940]\n",
      "loss: 0.155382  [12832/56940]\n",
      "loss: 0.210626  [16032/56940]\n",
      "loss: 0.231965  [19232/56940]\n",
      "loss: 0.171620  [22432/56940]\n",
      "loss: 0.202204  [25632/56940]\n",
      "loss: 0.195832  [28832/56940]\n",
      "loss: 0.180793  [32032/56940]\n",
      "loss: 0.106310  [35232/56940]\n",
      "loss: 0.413051  [38432/56940]\n",
      "loss: 0.177697  [41632/56940]\n",
      "loss: 0.193581  [44832/56940]\n",
      "loss: 0.288818  [48032/56940]\n",
      "loss: 0.166032  [51232/56940]\n",
      "loss: 0.202566  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.235201 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.236429  [   32/56940]\n",
      "loss: 0.215762  [ 3232/56940]\n",
      "loss: 0.322128  [ 6432/56940]\n",
      "loss: 0.243152  [ 9632/56940]\n",
      "loss: 0.225406  [12832/56940]\n",
      "loss: 0.204677  [16032/56940]\n",
      "loss: 0.152983  [19232/56940]\n",
      "loss: 0.364489  [22432/56940]\n",
      "loss: 0.212262  [25632/56940]\n",
      "loss: 0.268012  [28832/56940]\n",
      "loss: 0.309212  [32032/56940]\n",
      "loss: 0.226337  [35232/56940]\n",
      "loss: 0.251479  [38432/56940]\n",
      "loss: 0.290758  [41632/56940]\n",
      "loss: 0.208306  [44832/56940]\n",
      "loss: 0.375070  [48032/56940]\n",
      "loss: 0.126767  [51232/56940]\n",
      "loss: 0.204202  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.264968 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.279592  [   32/56940]\n",
      "loss: 0.179056  [ 3232/56940]\n",
      "loss: 0.165451  [ 6432/56940]\n",
      "loss: 0.186324  [ 9632/56940]\n",
      "loss: 0.283692  [12832/56940]\n",
      "loss: 0.326088  [16032/56940]\n",
      "loss: 0.491749  [19232/56940]\n",
      "loss: 0.278750  [22432/56940]\n",
      "loss: 0.120250  [25632/56940]\n",
      "loss: 0.169835  [28832/56940]\n",
      "loss: 0.243968  [32032/56940]\n",
      "loss: 0.138024  [35232/56940]\n",
      "loss: 0.266114  [38432/56940]\n",
      "loss: 0.243261  [41632/56940]\n",
      "loss: 0.342054  [44832/56940]\n",
      "loss: 0.282344  [48032/56940]\n",
      "loss: 0.319990  [51232/56940]\n",
      "loss: 0.273774  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.225188 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.181181  [   32/56940]\n",
      "loss: 0.227798  [ 3232/56940]\n",
      "loss: 0.323419  [ 6432/56940]\n",
      "loss: 0.253561  [ 9632/56940]\n",
      "loss: 0.256186  [12832/56940]\n",
      "loss: 0.230560  [16032/56940]\n",
      "loss: 0.157754  [19232/56940]\n",
      "loss: 0.336802  [22432/56940]\n",
      "loss: 0.095970  [25632/56940]\n",
      "loss: 0.233679  [28832/56940]\n",
      "loss: 0.220769  [32032/56940]\n",
      "loss: 0.205338  [35232/56940]\n",
      "loss: 0.172991  [38432/56940]\n",
      "loss: 0.304063  [41632/56940]\n",
      "loss: 0.345741  [44832/56940]\n",
      "loss: 0.268775  [48032/56940]\n",
      "loss: 0.281561  [51232/56940]\n",
      "loss: 0.259070  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.221839 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.363001  [   32/56940]\n",
      "loss: 0.218466  [ 3232/56940]\n",
      "loss: 0.217527  [ 6432/56940]\n",
      "loss: 0.293517  [ 9632/56940]\n",
      "loss: 0.207067  [12832/56940]\n",
      "loss: 0.274342  [16032/56940]\n",
      "loss: 0.181896  [19232/56940]\n",
      "loss: 0.245895  [22432/56940]\n",
      "loss: 0.209383  [25632/56940]\n",
      "loss: 0.177538  [28832/56940]\n",
      "loss: 0.198460  [32032/56940]\n",
      "loss: 0.246985  [35232/56940]\n",
      "loss: 0.257063  [38432/56940]\n",
      "loss: 0.361119  [41632/56940]\n",
      "loss: 0.202983  [44832/56940]\n",
      "loss: 0.141344  [48032/56940]\n",
      "loss: 0.145539  [51232/56940]\n",
      "loss: 0.411482  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.234249 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.196591  [   32/56940]\n",
      "loss: 0.257718  [ 3232/56940]\n",
      "loss: 0.196291  [ 6432/56940]\n",
      "loss: 0.231979  [ 9632/56940]\n",
      "loss: 0.158390  [12832/56940]\n",
      "loss: 0.186976  [16032/56940]\n",
      "loss: 0.351500  [19232/56940]\n",
      "loss: 0.238964  [22432/56940]\n",
      "loss: 0.314970  [25632/56940]\n",
      "loss: 0.123857  [28832/56940]\n",
      "loss: 0.414802  [32032/56940]\n",
      "loss: 0.163283  [35232/56940]\n",
      "loss: 0.384661  [38432/56940]\n",
      "loss: 0.238319  [41632/56940]\n",
      "loss: 0.368607  [44832/56940]\n",
      "loss: 0.154933  [48032/56940]\n",
      "loss: 0.325179  [51232/56940]\n",
      "loss: 0.212528  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.232234 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.205538  [   32/56940]\n",
      "loss: 0.214409  [ 3232/56940]\n",
      "loss: 0.301541  [ 6432/56940]\n",
      "loss: 0.351374  [ 9632/56940]\n",
      "loss: 0.175450  [12832/56940]\n",
      "loss: 0.259616  [16032/56940]\n",
      "loss: 0.314693  [19232/56940]\n",
      "loss: 0.135306  [22432/56940]\n",
      "loss: 0.097399  [25632/56940]\n",
      "loss: 0.276571  [28832/56940]\n",
      "loss: 0.455912  [32032/56940]\n",
      "loss: 0.367894  [35232/56940]\n",
      "loss: 0.289292  [38432/56940]\n",
      "loss: 0.092642  [41632/56940]\n",
      "loss: 0.160535  [44832/56940]\n",
      "loss: 0.252047  [48032/56940]\n",
      "loss: 0.316303  [51232/56940]\n",
      "loss: 0.226584  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.226756 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.634734  [   32/56940]\n",
      "loss: 0.179790  [ 3232/56940]\n",
      "loss: 0.514351  [ 6432/56940]\n",
      "loss: 0.205897  [ 9632/56940]\n",
      "loss: 0.261327  [12832/56940]\n",
      "loss: 0.395945  [16032/56940]\n",
      "loss: 0.238101  [19232/56940]\n",
      "loss: 0.267504  [22432/56940]\n",
      "loss: 0.436600  [25632/56940]\n",
      "loss: 0.278726  [28832/56940]\n",
      "loss: 0.263243  [32032/56940]\n",
      "loss: 0.595795  [35232/56940]\n",
      "loss: 0.176443  [38432/56940]\n",
      "loss: 0.324323  [41632/56940]\n",
      "loss: 0.344440  [44832/56940]\n",
      "loss: 0.271174  [48032/56940]\n",
      "loss: 0.309190  [51232/56940]\n",
      "loss: 0.292143  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.224304 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.270296  [   32/56940]\n",
      "loss: 0.545431  [ 3232/56940]\n",
      "loss: 0.266518  [ 6432/56940]\n",
      "loss: 0.141204  [ 9632/56940]\n",
      "loss: 0.213310  [12832/56940]\n",
      "loss: 0.225152  [16032/56940]\n",
      "loss: 0.235743  [19232/56940]\n",
      "loss: 0.180809  [22432/56940]\n",
      "loss: 0.242308  [25632/56940]\n",
      "loss: 0.258023  [28832/56940]\n",
      "loss: 0.394387  [32032/56940]\n",
      "loss: 0.242908  [35232/56940]\n",
      "loss: 0.160653  [38432/56940]\n",
      "loss: 0.222510  [41632/56940]\n",
      "loss: 0.219384  [44832/56940]\n",
      "loss: 0.323496  [48032/56940]\n",
      "loss: 0.270684  [51232/56940]\n",
      "loss: 0.324133  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.228489 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.400810  [   32/56940]\n",
      "loss: 0.224673  [ 3232/56940]\n",
      "loss: 0.308234  [ 6432/56940]\n",
      "loss: 0.408521  [ 9632/56940]\n",
      "loss: 0.328475  [12832/56940]\n",
      "loss: 0.241766  [16032/56940]\n",
      "loss: 0.400457  [19232/56940]\n",
      "loss: 0.281589  [22432/56940]\n",
      "loss: 0.278509  [25632/56940]\n",
      "loss: 0.133972  [28832/56940]\n",
      "loss: 0.380794  [32032/56940]\n",
      "loss: 0.196087  [35232/56940]\n",
      "loss: 0.187349  [38432/56940]\n",
      "loss: 0.353831  [41632/56940]\n",
      "loss: 0.175198  [44832/56940]\n",
      "loss: 0.224196  [48032/56940]\n",
      "loss: 0.140769  [51232/56940]\n",
      "loss: 0.400792  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.221880 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.140823  [   32/56940]\n",
      "loss: 0.267623  [ 3232/56940]\n",
      "loss: 0.195985  [ 6432/56940]\n",
      "loss: 0.407862  [ 9632/56940]\n",
      "loss: 0.195195  [12832/56940]\n",
      "loss: 0.409774  [16032/56940]\n",
      "loss: 0.314611  [19232/56940]\n",
      "loss: 0.247642  [22432/56940]\n",
      "loss: 0.318190  [25632/56940]\n",
      "loss: 0.255222  [28832/56940]\n",
      "loss: 0.240179  [32032/56940]\n",
      "loss: 0.212728  [35232/56940]\n",
      "loss: 0.273650  [38432/56940]\n",
      "loss: 0.287354  [41632/56940]\n",
      "loss: 0.428593  [44832/56940]\n",
      "loss: 0.278548  [48032/56940]\n",
      "loss: 0.163437  [51232/56940]\n",
      "loss: 0.167851  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.240295 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.532250  [   32/56940]\n",
      "loss: 0.426129  [ 3232/56940]\n",
      "loss: 0.260932  [ 6432/56940]\n",
      "loss: 0.213600  [ 9632/56940]\n",
      "loss: 0.355802  [12832/56940]\n",
      "loss: 0.202543  [16032/56940]\n",
      "loss: 0.494808  [19232/56940]\n",
      "loss: 0.291036  [22432/56940]\n",
      "loss: 0.175769  [25632/56940]\n",
      "loss: 0.373746  [28832/56940]\n",
      "loss: 0.234301  [32032/56940]\n",
      "loss: 0.166617  [35232/56940]\n",
      "loss: 0.291818  [38432/56940]\n",
      "loss: 0.418322  [41632/56940]\n",
      "loss: 0.169247  [44832/56940]\n",
      "loss: 0.255209  [48032/56940]\n",
      "loss: 0.400064  [51232/56940]\n",
      "loss: 0.205060  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.236985 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.190717  [   32/56940]\n",
      "loss: 0.125924  [ 3232/56940]\n",
      "loss: 0.147002  [ 6432/56940]\n",
      "loss: 0.365974  [ 9632/56940]\n",
      "loss: 0.563680  [12832/56940]\n",
      "loss: 0.373538  [16032/56940]\n",
      "loss: 0.282544  [19232/56940]\n",
      "loss: 0.235110  [22432/56940]\n",
      "loss: 0.411627  [25632/56940]\n",
      "loss: 0.200643  [28832/56940]\n",
      "loss: 0.328315  [32032/56940]\n",
      "loss: 0.340899  [35232/56940]\n",
      "loss: 0.275831  [38432/56940]\n",
      "loss: 0.227837  [41632/56940]\n",
      "loss: 0.281280  [44832/56940]\n",
      "loss: 0.323538  [48032/56940]\n",
      "loss: 0.219021  [51232/56940]\n",
      "loss: 0.243671  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.224980 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.331660  [   32/56940]\n",
      "loss: 0.481468  [ 3232/56940]\n",
      "loss: 0.189582  [ 6432/56940]\n",
      "loss: 0.175568  [ 9632/56940]\n",
      "loss: 0.278635  [12832/56940]\n",
      "loss: 0.201028  [16032/56940]\n",
      "loss: 0.357969  [19232/56940]\n",
      "loss: 0.429601  [22432/56940]\n",
      "loss: 0.245653  [25632/56940]\n",
      "loss: 0.259016  [28832/56940]\n",
      "loss: 0.305583  [32032/56940]\n",
      "loss: 0.221138  [35232/56940]\n",
      "loss: 0.183241  [38432/56940]\n",
      "loss: 0.359160  [41632/56940]\n",
      "loss: 0.275601  [44832/56940]\n",
      "loss: 0.154550  [48032/56940]\n",
      "loss: 0.352130  [51232/56940]\n",
      "loss: 0.219680  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.221761 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.495776  [   32/56940]\n",
      "loss: 0.177527  [ 3232/56940]\n",
      "loss: 0.455172  [ 6432/56940]\n",
      "loss: 0.305920  [ 9632/56940]\n",
      "loss: 0.301597  [12832/56940]\n",
      "loss: 0.303573  [16032/56940]\n",
      "loss: 0.256515  [19232/56940]\n",
      "loss: 0.243262  [22432/56940]\n",
      "loss: 0.417273  [25632/56940]\n",
      "loss: 0.182687  [28832/56940]\n",
      "loss: 0.354211  [32032/56940]\n",
      "loss: 0.197045  [35232/56940]\n",
      "loss: 0.318980  [38432/56940]\n",
      "loss: 0.155176  [41632/56940]\n",
      "loss: 0.208400  [44832/56940]\n",
      "loss: 0.255308  [48032/56940]\n",
      "loss: 0.263193  [51232/56940]\n",
      "loss: 0.329511  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.218953 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.374675  [   32/56940]\n",
      "loss: 0.333688  [ 3232/56940]\n",
      "loss: 0.227928  [ 6432/56940]\n",
      "loss: 0.255771  [ 9632/56940]\n",
      "loss: 0.235417  [12832/56940]\n",
      "loss: 0.269216  [16032/56940]\n",
      "loss: 0.258476  [19232/56940]\n",
      "loss: 0.435904  [22432/56940]\n",
      "loss: 0.221433  [25632/56940]\n",
      "loss: 0.225168  [28832/56940]\n",
      "loss: 0.213743  [32032/56940]\n",
      "loss: 0.176709  [35232/56940]\n",
      "loss: 0.204542  [38432/56940]\n",
      "loss: 0.149278  [41632/56940]\n",
      "loss: 0.326570  [44832/56940]\n",
      "loss: 0.389412  [48032/56940]\n",
      "loss: 0.201234  [51232/56940]\n",
      "loss: 0.223458  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.227712 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.392458  [   32/56940]\n",
      "loss: 0.196428  [ 3232/56940]\n",
      "loss: 0.322754  [ 6432/56940]\n",
      "loss: 0.485379  [ 9632/56940]\n",
      "loss: 0.604740  [12832/56940]\n",
      "loss: 0.200917  [16032/56940]\n",
      "loss: 0.230024  [19232/56940]\n",
      "loss: 0.329106  [22432/56940]\n",
      "loss: 0.147399  [25632/56940]\n",
      "loss: 0.199354  [28832/56940]\n",
      "loss: 0.473623  [32032/56940]\n",
      "loss: 0.299730  [35232/56940]\n",
      "loss: 0.200294  [38432/56940]\n",
      "loss: 0.332310  [41632/56940]\n",
      "loss: 0.180293  [44832/56940]\n",
      "loss: 0.096666  [48032/56940]\n",
      "loss: 0.383154  [51232/56940]\n",
      "loss: 0.176379  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.232589 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.228151  [   32/56940]\n",
      "loss: 0.181610  [ 3232/56940]\n",
      "loss: 0.366982  [ 6432/56940]\n",
      "loss: 0.459903  [ 9632/56940]\n",
      "loss: 0.316314  [12832/56940]\n",
      "loss: 0.422099  [16032/56940]\n",
      "loss: 0.263235  [19232/56940]\n",
      "loss: 0.197091  [22432/56940]\n",
      "loss: 0.232075  [25632/56940]\n",
      "loss: 0.287463  [28832/56940]\n",
      "loss: 0.559566  [32032/56940]\n",
      "loss: 0.201814  [35232/56940]\n",
      "loss: 0.295306  [38432/56940]\n",
      "loss: 0.225618  [41632/56940]\n",
      "loss: 0.204116  [44832/56940]\n",
      "loss: 0.171643  [48032/56940]\n",
      "loss: 0.205389  [51232/56940]\n",
      "loss: 0.171076  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.219526 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.102661  [   32/56940]\n",
      "loss: 0.141957  [ 3232/56940]\n",
      "loss: 0.467659  [ 6432/56940]\n",
      "loss: 0.503054  [ 9632/56940]\n",
      "loss: 0.249729  [12832/56940]\n",
      "loss: 0.126260  [16032/56940]\n",
      "loss: 0.239443  [19232/56940]\n",
      "loss: 0.227518  [22432/56940]\n",
      "loss: 0.256625  [25632/56940]\n",
      "loss: 0.320455  [28832/56940]\n",
      "loss: 0.368176  [32032/56940]\n",
      "loss: 0.146113  [35232/56940]\n",
      "loss: 0.220705  [38432/56940]\n",
      "loss: 0.161433  [41632/56940]\n",
      "loss: 0.196466  [44832/56940]\n",
      "loss: 0.267141  [48032/56940]\n",
      "loss: 0.159120  [51232/56940]\n",
      "loss: 0.291379  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.248914 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.266630  [   32/56940]\n",
      "loss: 0.142698  [ 3232/56940]\n",
      "loss: 0.186020  [ 6432/56940]\n",
      "loss: 0.664971  [ 9632/56940]\n",
      "loss: 0.331551  [12832/56940]\n",
      "loss: 0.370055  [16032/56940]\n",
      "loss: 0.159646  [19232/56940]\n",
      "loss: 0.271768  [22432/56940]\n",
      "loss: 0.150102  [25632/56940]\n",
      "loss: 0.116420  [28832/56940]\n",
      "loss: 0.304375  [32032/56940]\n",
      "loss: 0.346694  [35232/56940]\n",
      "loss: 0.300602  [38432/56940]\n",
      "loss: 0.360889  [41632/56940]\n",
      "loss: 0.278696  [44832/56940]\n",
      "loss: 0.381394  [48032/56940]\n",
      "loss: 0.147345  [51232/56940]\n",
      "loss: 0.179549  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.237457 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.195152  [   32/56940]\n",
      "loss: 0.226306  [ 3232/56940]\n",
      "loss: 0.139213  [ 6432/56940]\n",
      "loss: 0.323830  [ 9632/56940]\n",
      "loss: 0.300113  [12832/56940]\n",
      "loss: 0.251607  [16032/56940]\n",
      "loss: 0.196859  [19232/56940]\n",
      "loss: 0.305371  [22432/56940]\n",
      "loss: 0.209524  [25632/56940]\n",
      "loss: 0.283960  [28832/56940]\n",
      "loss: 0.252849  [32032/56940]\n",
      "loss: 0.274576  [35232/56940]\n",
      "loss: 0.197838  [38432/56940]\n",
      "loss: 0.150665  [41632/56940]\n",
      "loss: 0.340015  [44832/56940]\n",
      "loss: 0.318304  [48032/56940]\n",
      "loss: 0.125247  [51232/56940]\n",
      "loss: 0.252569  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.216528 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.178509  [   32/56940]\n",
      "loss: 0.253109  [ 3232/56940]\n",
      "loss: 0.240568  [ 6432/56940]\n",
      "loss: 0.211803  [ 9632/56940]\n",
      "loss: 0.265535  [12832/56940]\n",
      "loss: 0.174976  [16032/56940]\n",
      "loss: 0.198965  [19232/56940]\n",
      "loss: 0.152255  [22432/56940]\n",
      "loss: 0.383723  [25632/56940]\n",
      "loss: 0.110172  [28832/56940]\n",
      "loss: 0.201143  [32032/56940]\n",
      "loss: 0.347439  [35232/56940]\n",
      "loss: 0.268498  [38432/56940]\n",
      "loss: 0.212677  [41632/56940]\n",
      "loss: 0.227649  [44832/56940]\n",
      "loss: 0.310662  [48032/56940]\n",
      "loss: 0.322727  [51232/56940]\n",
      "loss: 0.258509  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.238608 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.313583  [   32/56940]\n",
      "loss: 0.275134  [ 3232/56940]\n",
      "loss: 0.149961  [ 6432/56940]\n",
      "loss: 0.226298  [ 9632/56940]\n",
      "loss: 0.136513  [12832/56940]\n",
      "loss: 0.225340  [16032/56940]\n",
      "loss: 0.322346  [19232/56940]\n",
      "loss: 0.192453  [22432/56940]\n",
      "loss: 0.164345  [25632/56940]\n",
      "loss: 0.297957  [28832/56940]\n",
      "loss: 0.121640  [32032/56940]\n",
      "loss: 0.282860  [35232/56940]\n",
      "loss: 0.431123  [38432/56940]\n",
      "loss: 0.152596  [41632/56940]\n",
      "loss: 0.265467  [44832/56940]\n",
      "loss: 0.237981  [48032/56940]\n",
      "loss: 0.179232  [51232/56940]\n",
      "loss: 0.400618  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.248710 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.290567  [   32/56940]\n",
      "loss: 0.299299  [ 3232/56940]\n",
      "loss: 0.314689  [ 6432/56940]\n",
      "loss: 0.332202  [ 9632/56940]\n",
      "loss: 0.291063  [12832/56940]\n",
      "loss: 0.233714  [16032/56940]\n",
      "loss: 0.144393  [19232/56940]\n",
      "loss: 0.255061  [22432/56940]\n",
      "loss: 0.197508  [25632/56940]\n",
      "loss: 0.139358  [28832/56940]\n",
      "loss: 0.199424  [32032/56940]\n",
      "loss: 0.178909  [35232/56940]\n",
      "loss: 0.290321  [38432/56940]\n",
      "loss: 0.239770  [41632/56940]\n",
      "loss: 0.376316  [44832/56940]\n",
      "loss: 0.211900  [48032/56940]\n",
      "loss: 0.126300  [51232/56940]\n",
      "loss: 0.289868  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.226320 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.177392  [   32/56940]\n",
      "loss: 0.205283  [ 3232/56940]\n",
      "loss: 0.203341  [ 6432/56940]\n",
      "loss: 0.258094  [ 9632/56940]\n",
      "loss: 0.177281  [12832/56940]\n",
      "loss: 0.163111  [16032/56940]\n",
      "loss: 0.208010  [19232/56940]\n",
      "loss: 0.114311  [22432/56940]\n",
      "loss: 0.228636  [25632/56940]\n",
      "loss: 0.170034  [28832/56940]\n",
      "loss: 0.224624  [32032/56940]\n",
      "loss: 0.258812  [35232/56940]\n",
      "loss: 0.407986  [38432/56940]\n",
      "loss: 0.679110  [41632/56940]\n",
      "loss: 0.150793  [44832/56940]\n",
      "loss: 0.218472  [48032/56940]\n",
      "loss: 0.162449  [51232/56940]\n",
      "loss: 0.285337  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.222194 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.458515  [   32/56940]\n",
      "loss: 0.142175  [ 3232/56940]\n",
      "loss: 0.278944  [ 6432/56940]\n",
      "loss: 0.247133  [ 9632/56940]\n",
      "loss: 0.142925  [12832/56940]\n",
      "loss: 0.207969  [16032/56940]\n",
      "loss: 0.242722  [19232/56940]\n",
      "loss: 0.227328  [22432/56940]\n",
      "loss: 0.286369  [25632/56940]\n",
      "loss: 0.213144  [28832/56940]\n",
      "loss: 0.181718  [32032/56940]\n",
      "loss: 0.233007  [35232/56940]\n",
      "loss: 0.267633  [38432/56940]\n",
      "loss: 0.209734  [41632/56940]\n",
      "loss: 0.190552  [44832/56940]\n",
      "loss: 0.214944  [48032/56940]\n",
      "loss: 0.124225  [51232/56940]\n",
      "loss: 0.126551  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.224468 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.357174  [   32/56940]\n",
      "loss: 0.512881  [ 3232/56940]\n",
      "loss: 0.284312  [ 6432/56940]\n",
      "loss: 0.287229  [ 9632/56940]\n",
      "loss: 0.363623  [12832/56940]\n",
      "loss: 0.241870  [16032/56940]\n",
      "loss: 0.295167  [19232/56940]\n",
      "loss: 0.394877  [22432/56940]\n",
      "loss: 0.153111  [25632/56940]\n",
      "loss: 0.382357  [28832/56940]\n",
      "loss: 0.308242  [32032/56940]\n",
      "loss: 0.199114  [35232/56940]\n",
      "loss: 0.400955  [38432/56940]\n",
      "loss: 0.375034  [41632/56940]\n",
      "loss: 0.189260  [44832/56940]\n",
      "loss: 0.130636  [48032/56940]\n",
      "loss: 0.159191  [51232/56940]\n",
      "loss: 0.441404  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.221227 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.240187  [   32/56940]\n",
      "loss: 0.224632  [ 3232/56940]\n",
      "loss: 0.383087  [ 6432/56940]\n",
      "loss: 0.193366  [ 9632/56940]\n",
      "loss: 0.130374  [12832/56940]\n",
      "loss: 0.245306  [16032/56940]\n",
      "loss: 0.226175  [19232/56940]\n",
      "loss: 0.283289  [22432/56940]\n",
      "loss: 0.272690  [25632/56940]\n",
      "loss: 0.365157  [28832/56940]\n",
      "loss: 0.243155  [32032/56940]\n",
      "loss: 0.231494  [35232/56940]\n",
      "loss: 0.274812  [38432/56940]\n",
      "loss: 0.179152  [41632/56940]\n",
      "loss: 0.284929  [44832/56940]\n",
      "loss: 0.249926  [48032/56940]\n",
      "loss: 0.374411  [51232/56940]\n",
      "loss: 0.207525  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.288915 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.263019  [   32/56940]\n",
      "loss: 0.354010  [ 3232/56940]\n",
      "loss: 0.284590  [ 6432/56940]\n",
      "loss: 0.204185  [ 9632/56940]\n",
      "loss: 0.311586  [12832/56940]\n",
      "loss: 0.311224  [16032/56940]\n",
      "loss: 0.112736  [19232/56940]\n",
      "loss: 0.254095  [22432/56940]\n",
      "loss: 0.207674  [25632/56940]\n",
      "loss: 0.523517  [28832/56940]\n",
      "loss: 0.289636  [32032/56940]\n",
      "loss: 0.149235  [35232/56940]\n",
      "loss: 0.128281  [38432/56940]\n",
      "loss: 0.268652  [41632/56940]\n",
      "loss: 0.425775  [44832/56940]\n",
      "loss: 0.118770  [48032/56940]\n",
      "loss: 0.111556  [51232/56940]\n",
      "loss: 0.170315  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.218190 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.278238  [   32/56940]\n",
      "loss: 0.154372  [ 3232/56940]\n",
      "loss: 0.217827  [ 6432/56940]\n",
      "loss: 0.193365  [ 9632/56940]\n",
      "loss: 0.184621  [12832/56940]\n",
      "loss: 0.403122  [16032/56940]\n",
      "loss: 0.235632  [19232/56940]\n",
      "loss: 0.214857  [22432/56940]\n",
      "loss: 0.162594  [25632/56940]\n",
      "loss: 0.203943  [28832/56940]\n",
      "loss: 0.488885  [32032/56940]\n",
      "loss: 0.282886  [35232/56940]\n",
      "loss: 0.181940  [38432/56940]\n",
      "loss: 0.215421  [41632/56940]\n",
      "loss: 0.205378  [44832/56940]\n",
      "loss: 0.214072  [48032/56940]\n",
      "loss: 0.227352  [51232/56940]\n",
      "loss: 0.358359  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.237029 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.256991  [   32/56940]\n",
      "loss: 0.152823  [ 3232/56940]\n",
      "loss: 0.487064  [ 6432/56940]\n",
      "loss: 0.241526  [ 9632/56940]\n",
      "loss: 0.198723  [12832/56940]\n",
      "loss: 0.191447  [16032/56940]\n",
      "loss: 0.303102  [19232/56940]\n",
      "loss: 0.162263  [22432/56940]\n",
      "loss: 0.279609  [25632/56940]\n",
      "loss: 0.269472  [28832/56940]\n",
      "loss: 0.351659  [32032/56940]\n",
      "loss: 0.359543  [35232/56940]\n",
      "loss: 0.208105  [38432/56940]\n",
      "loss: 0.419398  [41632/56940]\n",
      "loss: 0.305681  [44832/56940]\n",
      "loss: 0.410983  [48032/56940]\n",
      "loss: 0.199559  [51232/56940]\n",
      "loss: 0.172924  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.229462 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.313303  [   32/56940]\n",
      "loss: 0.301036  [ 3232/56940]\n",
      "loss: 0.184741  [ 6432/56940]\n",
      "loss: 0.191339  [ 9632/56940]\n",
      "loss: 0.164286  [12832/56940]\n",
      "loss: 0.215991  [16032/56940]\n",
      "loss: 0.327669  [19232/56940]\n",
      "loss: 0.256914  [22432/56940]\n",
      "loss: 0.318001  [25632/56940]\n",
      "loss: 0.302116  [28832/56940]\n",
      "loss: 0.125122  [32032/56940]\n",
      "loss: 0.398320  [35232/56940]\n",
      "loss: 0.123883  [38432/56940]\n",
      "loss: 0.149160  [41632/56940]\n",
      "loss: 0.360139  [44832/56940]\n",
      "loss: 0.308659  [48032/56940]\n",
      "loss: 0.260494  [51232/56940]\n",
      "loss: 0.409325  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.231181 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.280485  [   32/56940]\n",
      "loss: 0.178935  [ 3232/56940]\n",
      "loss: 0.287604  [ 6432/56940]\n",
      "loss: 0.234519  [ 9632/56940]\n",
      "loss: 0.178688  [12832/56940]\n",
      "loss: 0.169851  [16032/56940]\n",
      "loss: 0.336275  [19232/56940]\n",
      "loss: 0.226248  [22432/56940]\n",
      "loss: 0.118469  [25632/56940]\n",
      "loss: 0.295091  [28832/56940]\n",
      "loss: 0.578394  [32032/56940]\n",
      "loss: 0.335792  [35232/56940]\n",
      "loss: 0.214013  [38432/56940]\n",
      "loss: 0.326122  [41632/56940]\n",
      "loss: 0.202580  [44832/56940]\n",
      "loss: 0.159773  [48032/56940]\n",
      "loss: 0.420614  [51232/56940]\n",
      "loss: 0.377921  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.220594 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.216246  [   32/56940]\n",
      "loss: 0.191805  [ 3232/56940]\n",
      "loss: 0.115979  [ 6432/56940]\n",
      "loss: 0.235768  [ 9632/56940]\n",
      "loss: 0.178025  [12832/56940]\n",
      "loss: 0.236661  [16032/56940]\n",
      "loss: 0.189930  [19232/56940]\n",
      "loss: 0.689581  [22432/56940]\n",
      "loss: 0.209999  [25632/56940]\n",
      "loss: 0.194179  [28832/56940]\n",
      "loss: 0.164744  [32032/56940]\n",
      "loss: 0.274030  [35232/56940]\n",
      "loss: 0.199512  [38432/56940]\n",
      "loss: 0.197353  [41632/56940]\n",
      "loss: 0.197827  [44832/56940]\n",
      "loss: 0.141050  [48032/56940]\n",
      "loss: 0.206531  [51232/56940]\n",
      "loss: 0.309716  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.221787 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.432066  [   32/56940]\n",
      "loss: 0.185822  [ 3232/56940]\n",
      "loss: 0.199365  [ 6432/56940]\n",
      "loss: 0.296120  [ 9632/56940]\n",
      "loss: 0.118713  [12832/56940]\n",
      "loss: 0.252397  [16032/56940]\n",
      "loss: 0.114082  [19232/56940]\n",
      "loss: 0.154765  [22432/56940]\n",
      "loss: 0.214724  [25632/56940]\n",
      "loss: 0.196683  [28832/56940]\n",
      "loss: 0.221870  [32032/56940]\n",
      "loss: 0.209270  [35232/56940]\n",
      "loss: 0.180176  [38432/56940]\n",
      "loss: 0.154505  [41632/56940]\n",
      "loss: 0.240635  [44832/56940]\n",
      "loss: 0.276595  [48032/56940]\n",
      "loss: 0.085358  [51232/56940]\n",
      "loss: 0.236110  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.225711 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.156639  [   32/56940]\n",
      "loss: 0.292988  [ 3232/56940]\n",
      "loss: 0.349701  [ 6432/56940]\n",
      "loss: 0.136389  [ 9632/56940]\n",
      "loss: 0.196330  [12832/56940]\n",
      "loss: 0.479610  [16032/56940]\n",
      "loss: 0.124718  [19232/56940]\n",
      "loss: 0.154881  [22432/56940]\n",
      "loss: 0.147667  [25632/56940]\n",
      "loss: 0.511903  [28832/56940]\n",
      "loss: 0.107175  [32032/56940]\n",
      "loss: 0.301739  [35232/56940]\n",
      "loss: 0.160214  [38432/56940]\n",
      "loss: 0.221105  [41632/56940]\n",
      "loss: 0.199976  [44832/56940]\n",
      "loss: 0.192979  [48032/56940]\n",
      "loss: 0.314304  [51232/56940]\n",
      "loss: 0.205519  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.218245 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.244507  [   32/56940]\n",
      "loss: 0.253621  [ 3232/56940]\n",
      "loss: 0.248432  [ 6432/56940]\n",
      "loss: 0.210715  [ 9632/56940]\n",
      "loss: 0.148539  [12832/56940]\n",
      "loss: 0.274762  [16032/56940]\n",
      "loss: 0.533615  [19232/56940]\n",
      "loss: 0.292743  [22432/56940]\n",
      "loss: 0.202804  [25632/56940]\n",
      "loss: 0.176478  [28832/56940]\n",
      "loss: 0.288818  [32032/56940]\n",
      "loss: 0.149438  [35232/56940]\n",
      "loss: 0.186201  [38432/56940]\n",
      "loss: 0.198972  [41632/56940]\n",
      "loss: 0.163356  [44832/56940]\n",
      "loss: 0.179030  [48032/56940]\n",
      "loss: 0.235754  [51232/56940]\n",
      "loss: 0.221055  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.216219 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.295807  [   32/56940]\n",
      "loss: 0.221735  [ 3232/56940]\n",
      "loss: 0.210515  [ 6432/56940]\n",
      "loss: 0.489123  [ 9632/56940]\n",
      "loss: 0.233399  [12832/56940]\n",
      "loss: 0.128628  [16032/56940]\n",
      "loss: 0.178029  [19232/56940]\n",
      "loss: 0.231018  [22432/56940]\n",
      "loss: 0.195598  [25632/56940]\n",
      "loss: 0.317090  [28832/56940]\n",
      "loss: 0.173064  [32032/56940]\n",
      "loss: 0.186685  [35232/56940]\n",
      "loss: 0.345913  [38432/56940]\n",
      "loss: 0.178059  [41632/56940]\n",
      "loss: 0.460478  [44832/56940]\n",
      "loss: 0.206713  [48032/56940]\n",
      "loss: 0.234625  [51232/56940]\n",
      "loss: 0.239664  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.228793 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.186239  [   32/56940]\n",
      "loss: 0.130852  [ 3232/56940]\n",
      "loss: 0.273168  [ 6432/56940]\n",
      "loss: 0.233301  [ 9632/56940]\n",
      "loss: 0.292899  [12832/56940]\n",
      "loss: 0.091562  [16032/56940]\n",
      "loss: 0.267734  [19232/56940]\n",
      "loss: 0.345698  [22432/56940]\n",
      "loss: 0.279409  [25632/56940]\n",
      "loss: 0.249706  [28832/56940]\n",
      "loss: 0.222096  [32032/56940]\n",
      "loss: 0.197177  [35232/56940]\n",
      "loss: 0.157950  [38432/56940]\n",
      "loss: 0.264670  [41632/56940]\n",
      "loss: 0.178680  [44832/56940]\n",
      "loss: 0.272772  [48032/56940]\n",
      "loss: 0.149624  [51232/56940]\n",
      "loss: 0.258290  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.243545 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.114801  [   32/56940]\n",
      "loss: 0.192499  [ 3232/56940]\n",
      "loss: 0.249711  [ 6432/56940]\n",
      "loss: 0.301795  [ 9632/56940]\n",
      "loss: 0.234418  [12832/56940]\n",
      "loss: 0.164403  [16032/56940]\n",
      "loss: 0.256311  [19232/56940]\n",
      "loss: 0.129582  [22432/56940]\n",
      "loss: 0.223978  [25632/56940]\n",
      "loss: 0.340089  [28832/56940]\n",
      "loss: 0.285502  [32032/56940]\n",
      "loss: 0.428054  [35232/56940]\n",
      "loss: 0.276213  [38432/56940]\n",
      "loss: 0.268784  [41632/56940]\n",
      "loss: 0.264392  [44832/56940]\n",
      "loss: 0.180582  [48032/56940]\n",
      "loss: 0.098374  [51232/56940]\n",
      "loss: 0.188767  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.223671 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.163254  [   32/56940]\n",
      "loss: 0.168236  [ 3232/56940]\n",
      "loss: 0.145469  [ 6432/56940]\n",
      "loss: 0.637434  [ 9632/56940]\n",
      "loss: 0.235848  [12832/56940]\n",
      "loss: 0.078344  [16032/56940]\n",
      "loss: 0.253340  [19232/56940]\n",
      "loss: 0.174458  [22432/56940]\n",
      "loss: 0.287791  [25632/56940]\n",
      "loss: 0.497023  [28832/56940]\n",
      "loss: 0.159642  [32032/56940]\n",
      "loss: 0.328074  [35232/56940]\n",
      "loss: 0.342343  [38432/56940]\n",
      "loss: 0.193009  [41632/56940]\n",
      "loss: 0.393692  [44832/56940]\n",
      "loss: 0.226104  [48032/56940]\n",
      "loss: 0.117323  [51232/56940]\n",
      "loss: 0.445269  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.215972 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.336738  [   32/56940]\n",
      "loss: 0.283837  [ 3232/56940]\n",
      "loss: 0.380688  [ 6432/56940]\n",
      "loss: 0.468687  [ 9632/56940]\n",
      "loss: 0.413493  [12832/56940]\n",
      "loss: 0.247825  [16032/56940]\n",
      "loss: 0.176835  [19232/56940]\n",
      "loss: 0.253936  [22432/56940]\n",
      "loss: 0.139547  [25632/56940]\n",
      "loss: 0.152811  [28832/56940]\n",
      "loss: 0.097406  [32032/56940]\n",
      "loss: 0.628127  [35232/56940]\n",
      "loss: 0.139658  [38432/56940]\n",
      "loss: 0.342355  [41632/56940]\n",
      "loss: 0.208547  [44832/56940]\n",
      "loss: 0.159291  [48032/56940]\n",
      "loss: 0.375137  [51232/56940]\n",
      "loss: 0.224900  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.216832 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.148827  [   32/56940]\n",
      "loss: 0.385946  [ 3232/56940]\n",
      "loss: 0.217764  [ 6432/56940]\n",
      "loss: 0.206946  [ 9632/56940]\n",
      "loss: 0.537517  [12832/56940]\n",
      "loss: 0.406420  [16032/56940]\n",
      "loss: 0.169520  [19232/56940]\n",
      "loss: 0.214858  [22432/56940]\n",
      "loss: 0.186675  [25632/56940]\n",
      "loss: 0.195211  [28832/56940]\n",
      "loss: 0.267270  [32032/56940]\n",
      "loss: 0.218590  [35232/56940]\n",
      "loss: 0.243924  [38432/56940]\n",
      "loss: 0.295146  [41632/56940]\n",
      "loss: 0.097543  [44832/56940]\n",
      "loss: 0.193220  [48032/56940]\n",
      "loss: 0.278855  [51232/56940]\n",
      "loss: 0.294423  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.249282 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.360289  [   32/56940]\n",
      "loss: 0.374064  [ 3232/56940]\n",
      "loss: 0.338168  [ 6432/56940]\n",
      "loss: 0.332342  [ 9632/56940]\n",
      "loss: 0.156606  [12832/56940]\n",
      "loss: 0.240012  [16032/56940]\n",
      "loss: 0.206477  [19232/56940]\n",
      "loss: 0.179897  [22432/56940]\n",
      "loss: 0.250946  [25632/56940]\n",
      "loss: 0.365141  [28832/56940]\n",
      "loss: 0.261446  [32032/56940]\n",
      "loss: 0.161578  [35232/56940]\n",
      "loss: 0.136811  [38432/56940]\n",
      "loss: 0.136330  [41632/56940]\n",
      "loss: 0.290104  [44832/56940]\n",
      "loss: 0.211384  [48032/56940]\n",
      "loss: 0.328836  [51232/56940]\n",
      "loss: 0.273418  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.221639 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.119098  [   32/56940]\n",
      "loss: 0.175999  [ 3232/56940]\n",
      "loss: 0.335268  [ 6432/56940]\n",
      "loss: 0.442644  [ 9632/56940]\n",
      "loss: 0.316865  [12832/56940]\n",
      "loss: 0.367426  [16032/56940]\n",
      "loss: 0.245936  [19232/56940]\n",
      "loss: 0.201582  [22432/56940]\n",
      "loss: 0.207687  [25632/56940]\n",
      "loss: 0.429432  [28832/56940]\n",
      "loss: 0.237572  [32032/56940]\n",
      "loss: 0.216519  [35232/56940]\n",
      "loss: 0.213908  [38432/56940]\n",
      "loss: 0.416811  [41632/56940]\n",
      "loss: 0.169920  [44832/56940]\n",
      "loss: 0.363596  [48032/56940]\n",
      "loss: 0.372657  [51232/56940]\n",
      "loss: 0.315188  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.222629 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.157888  [   32/56940]\n",
      "loss: 0.241962  [ 3232/56940]\n",
      "loss: 0.190983  [ 6432/56940]\n",
      "loss: 0.200843  [ 9632/56940]\n",
      "loss: 0.156678  [12832/56940]\n",
      "loss: 0.183481  [16032/56940]\n",
      "loss: 0.190453  [19232/56940]\n",
      "loss: 0.229849  [22432/56940]\n",
      "loss: 0.262258  [25632/56940]\n",
      "loss: 0.238197  [28832/56940]\n",
      "loss: 0.265881  [32032/56940]\n",
      "loss: 0.282250  [35232/56940]\n",
      "loss: 0.214945  [38432/56940]\n",
      "loss: 0.353626  [41632/56940]\n",
      "loss: 0.418911  [44832/56940]\n",
      "loss: 0.224375  [48032/56940]\n",
      "loss: 0.083469  [51232/56940]\n",
      "loss: 0.108423  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.232046 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.477605  [   32/56940]\n",
      "loss: 0.286362  [ 3232/56940]\n",
      "loss: 0.365937  [ 6432/56940]\n",
      "loss: 0.369814  [ 9632/56940]\n",
      "loss: 0.231606  [12832/56940]\n",
      "loss: 0.268407  [16032/56940]\n",
      "loss: 0.209160  [19232/56940]\n",
      "loss: 0.373242  [22432/56940]\n",
      "loss: 0.226180  [25632/56940]\n",
      "loss: 0.239973  [28832/56940]\n",
      "loss: 0.275454  [32032/56940]\n",
      "loss: 0.226072  [35232/56940]\n",
      "loss: 0.170929  [38432/56940]\n",
      "loss: 0.138381  [41632/56940]\n",
      "loss: 0.318134  [44832/56940]\n",
      "loss: 0.127403  [48032/56940]\n",
      "loss: 0.300274  [51232/56940]\n",
      "loss: 0.174361  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.226974 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.366867  [   32/56940]\n",
      "loss: 0.151914  [ 3232/56940]\n",
      "loss: 0.139392  [ 6432/56940]\n",
      "loss: 0.331934  [ 9632/56940]\n",
      "loss: 0.189893  [12832/56940]\n",
      "loss: 0.220311  [16032/56940]\n",
      "loss: 0.180750  [19232/56940]\n",
      "loss: 0.165595  [22432/56940]\n",
      "loss: 0.222906  [25632/56940]\n",
      "loss: 0.105835  [28832/56940]\n",
      "loss: 0.545416  [32032/56940]\n",
      "loss: 0.147443  [35232/56940]\n",
      "loss: 0.537957  [38432/56940]\n",
      "loss: 0.441368  [41632/56940]\n",
      "loss: 0.222572  [44832/56940]\n",
      "loss: 0.120669  [48032/56940]\n",
      "loss: 0.318478  [51232/56940]\n",
      "loss: 0.318437  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.220314 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.213706  [   32/56940]\n",
      "loss: 0.305633  [ 3232/56940]\n",
      "loss: 0.178150  [ 6432/56940]\n",
      "loss: 0.140977  [ 9632/56940]\n",
      "loss: 0.348966  [12832/56940]\n",
      "loss: 0.255316  [16032/56940]\n",
      "loss: 0.422118  [19232/56940]\n",
      "loss: 0.226895  [22432/56940]\n",
      "loss: 0.127613  [25632/56940]\n",
      "loss: 0.362292  [28832/56940]\n",
      "loss: 0.438071  [32032/56940]\n",
      "loss: 0.138705  [35232/56940]\n",
      "loss: 0.294358  [38432/56940]\n",
      "loss: 0.153428  [41632/56940]\n",
      "loss: 0.183329  [44832/56940]\n",
      "loss: 0.179304  [48032/56940]\n",
      "loss: 0.158710  [51232/56940]\n",
      "loss: 0.398284  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.221798 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.377218  [   32/56940]\n",
      "loss: 0.140695  [ 3232/56940]\n",
      "loss: 0.206723  [ 6432/56940]\n",
      "loss: 0.152111  [ 9632/56940]\n",
      "loss: 0.210091  [12832/56940]\n",
      "loss: 0.148347  [16032/56940]\n",
      "loss: 0.466065  [19232/56940]\n",
      "loss: 0.187315  [22432/56940]\n",
      "loss: 0.413460  [25632/56940]\n",
      "loss: 0.133379  [28832/56940]\n",
      "loss: 0.267877  [32032/56940]\n",
      "loss: 0.693700  [35232/56940]\n",
      "loss: 0.209366  [38432/56940]\n",
      "loss: 0.170561  [41632/56940]\n",
      "loss: 0.162131  [44832/56940]\n",
      "loss: 0.187226  [48032/56940]\n",
      "loss: 0.199801  [51232/56940]\n",
      "loss: 0.273423  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.230096 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.309004  [   32/56940]\n",
      "loss: 0.252853  [ 3232/56940]\n",
      "loss: 0.117922  [ 6432/56940]\n",
      "loss: 0.181799  [ 9632/56940]\n",
      "loss: 0.277788  [12832/56940]\n",
      "loss: 0.502816  [16032/56940]\n",
      "loss: 0.427765  [19232/56940]\n",
      "loss: 0.172722  [22432/56940]\n",
      "loss: 0.088229  [25632/56940]\n",
      "loss: 0.433782  [28832/56940]\n",
      "loss: 0.376773  [32032/56940]\n",
      "loss: 0.141626  [35232/56940]\n",
      "loss: 0.183725  [38432/56940]\n",
      "loss: 0.108146  [41632/56940]\n",
      "loss: 0.283634  [44832/56940]\n",
      "loss: 0.235401  [48032/56940]\n",
      "loss: 1.139861  [51232/56940]\n",
      "loss: 0.360234  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.225880 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.701193  [   32/56940]\n",
      "loss: 0.206583  [ 3232/56940]\n",
      "loss: 0.184999  [ 6432/56940]\n",
      "loss: 0.304461  [ 9632/56940]\n",
      "loss: 0.688639  [12832/56940]\n",
      "loss: 0.121160  [16032/56940]\n",
      "loss: 0.256964  [19232/56940]\n",
      "loss: 0.178627  [22432/56940]\n",
      "loss: 0.219777  [25632/56940]\n",
      "loss: 0.189319  [28832/56940]\n",
      "loss: 0.142736  [32032/56940]\n",
      "loss: 0.417402  [35232/56940]\n",
      "loss: 0.295486  [38432/56940]\n",
      "loss: 0.323603  [41632/56940]\n",
      "loss: 0.260474  [44832/56940]\n",
      "loss: 0.507672  [48032/56940]\n",
      "loss: 0.170788  [51232/56940]\n",
      "loss: 0.819391  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.213583 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.156854  [   32/56940]\n",
      "loss: 0.272091  [ 3232/56940]\n",
      "loss: 0.197152  [ 6432/56940]\n",
      "loss: 0.238847  [ 9632/56940]\n",
      "loss: 0.350195  [12832/56940]\n",
      "loss: 0.206839  [16032/56940]\n",
      "loss: 0.159305  [19232/56940]\n",
      "loss: 0.290869  [22432/56940]\n",
      "loss: 0.285851  [25632/56940]\n",
      "loss: 0.324543  [28832/56940]\n",
      "loss: 0.317969  [32032/56940]\n",
      "loss: 0.467306  [35232/56940]\n",
      "loss: 0.284810  [38432/56940]\n",
      "loss: 0.295829  [41632/56940]\n",
      "loss: 0.181707  [44832/56940]\n",
      "loss: 0.301778  [48032/56940]\n",
      "loss: 0.382576  [51232/56940]\n",
      "loss: 0.493200  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.218363 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.233017  [   32/56940]\n",
      "loss: 0.150364  [ 3232/56940]\n",
      "loss: 0.251547  [ 6432/56940]\n",
      "loss: 0.160689  [ 9632/56940]\n",
      "loss: 0.238008  [12832/56940]\n",
      "loss: 0.094518  [16032/56940]\n",
      "loss: 0.209683  [19232/56940]\n",
      "loss: 0.372856  [22432/56940]\n",
      "loss: 0.280217  [25632/56940]\n",
      "loss: 0.204430  [28832/56940]\n",
      "loss: 0.216129  [32032/56940]\n",
      "loss: 0.439015  [35232/56940]\n",
      "loss: 0.122198  [38432/56940]\n",
      "loss: 0.169704  [41632/56940]\n",
      "loss: 0.230343  [44832/56940]\n",
      "loss: 0.183649  [48032/56940]\n",
      "loss: 0.164579  [51232/56940]\n",
      "loss: 0.399485  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.222975 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.223222  [   32/56940]\n",
      "loss: 0.211096  [ 3232/56940]\n",
      "loss: 0.183238  [ 6432/56940]\n",
      "loss: 0.102732  [ 9632/56940]\n",
      "loss: 0.405000  [12832/56940]\n",
      "loss: 0.150646  [16032/56940]\n",
      "loss: 0.178865  [19232/56940]\n",
      "loss: 0.199729  [22432/56940]\n",
      "loss: 0.232262  [25632/56940]\n",
      "loss: 0.156385  [28832/56940]\n",
      "loss: 0.272048  [32032/56940]\n",
      "loss: 0.274840  [35232/56940]\n",
      "loss: 0.263738  [38432/56940]\n",
      "loss: 0.219411  [41632/56940]\n",
      "loss: 0.206047  [44832/56940]\n",
      "loss: 0.251019  [48032/56940]\n",
      "loss: 0.314737  [51232/56940]\n",
      "loss: 0.320102  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.239484 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.223422  [   32/56940]\n",
      "loss: 0.234673  [ 3232/56940]\n",
      "loss: 0.181469  [ 6432/56940]\n",
      "loss: 0.287052  [ 9632/56940]\n",
      "loss: 0.150122  [12832/56940]\n",
      "loss: 0.352737  [16032/56940]\n",
      "loss: 0.216999  [19232/56940]\n",
      "loss: 0.117034  [22432/56940]\n",
      "loss: 0.244718  [25632/56940]\n",
      "loss: 0.349728  [28832/56940]\n",
      "loss: 0.533531  [32032/56940]\n",
      "loss: 0.233080  [35232/56940]\n",
      "loss: 0.288759  [38432/56940]\n",
      "loss: 0.273389  [41632/56940]\n",
      "loss: 0.165737  [44832/56940]\n",
      "loss: 0.221637  [48032/56940]\n",
      "loss: 0.202603  [51232/56940]\n",
      "loss: 0.368483  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.220035 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.196178  [   32/56940]\n",
      "loss: 0.238280  [ 3232/56940]\n",
      "loss: 0.253400  [ 6432/56940]\n",
      "loss: 0.259414  [ 9632/56940]\n",
      "loss: 0.116207  [12832/56940]\n",
      "loss: 0.585527  [16032/56940]\n",
      "loss: 0.186147  [19232/56940]\n",
      "loss: 0.264073  [22432/56940]\n",
      "loss: 0.168323  [25632/56940]\n",
      "loss: 0.385490  [28832/56940]\n",
      "loss: 0.240371  [32032/56940]\n",
      "loss: 0.176157  [35232/56940]\n",
      "loss: 0.235682  [38432/56940]\n",
      "loss: 0.278561  [41632/56940]\n",
      "loss: 0.158815  [44832/56940]\n",
      "loss: 0.183943  [48032/56940]\n",
      "loss: 0.139360  [51232/56940]\n",
      "loss: 0.215879  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.217036 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.104573  [   32/56940]\n",
      "loss: 0.329022  [ 3232/56940]\n",
      "loss: 0.330064  [ 6432/56940]\n",
      "loss: 0.349087  [ 9632/56940]\n",
      "loss: 0.281786  [12832/56940]\n",
      "loss: 0.309233  [16032/56940]\n",
      "loss: 0.172502  [19232/56940]\n",
      "loss: 0.164420  [22432/56940]\n",
      "loss: 0.152394  [25632/56940]\n",
      "loss: 0.160191  [28832/56940]\n",
      "loss: 0.124332  [32032/56940]\n",
      "loss: 0.164151  [35232/56940]\n",
      "loss: 0.326177  [38432/56940]\n",
      "loss: 0.405680  [41632/56940]\n",
      "loss: 0.352418  [44832/56940]\n",
      "loss: 0.584456  [48032/56940]\n",
      "loss: 0.175902  [51232/56940]\n",
      "loss: 0.298941  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.213675 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.300311  [   32/56940]\n",
      "loss: 0.152695  [ 3232/56940]\n",
      "loss: 0.174146  [ 6432/56940]\n",
      "loss: 0.248157  [ 9632/56940]\n",
      "loss: 0.094696  [12832/56940]\n",
      "loss: 0.188403  [16032/56940]\n",
      "loss: 0.188533  [19232/56940]\n",
      "loss: 0.232430  [22432/56940]\n",
      "loss: 0.275440  [25632/56940]\n",
      "loss: 0.474757  [28832/56940]\n",
      "loss: 0.260657  [32032/56940]\n",
      "loss: 0.354050  [35232/56940]\n",
      "loss: 0.242014  [38432/56940]\n",
      "loss: 0.236297  [41632/56940]\n",
      "loss: 0.233967  [44832/56940]\n",
      "loss: 0.126278  [48032/56940]\n",
      "loss: 0.317734  [51232/56940]\n",
      "loss: 0.274967  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.230610 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.223148  [   32/56940]\n",
      "loss: 0.156742  [ 3232/56940]\n",
      "loss: 0.150047  [ 6432/56940]\n",
      "loss: 0.282500  [ 9632/56940]\n",
      "loss: 0.692628  [12832/56940]\n",
      "loss: 0.184125  [16032/56940]\n",
      "loss: 0.264071  [19232/56940]\n",
      "loss: 0.374405  [22432/56940]\n",
      "loss: 0.255596  [25632/56940]\n",
      "loss: 0.182036  [28832/56940]\n",
      "loss: 0.219934  [32032/56940]\n",
      "loss: 0.123349  [35232/56940]\n",
      "loss: 0.461163  [38432/56940]\n",
      "loss: 0.304235  [41632/56940]\n",
      "loss: 0.440152  [44832/56940]\n",
      "loss: 0.226369  [48032/56940]\n",
      "loss: 0.238163  [51232/56940]\n",
      "loss: 0.198982  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.222898 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.153214  [   32/56940]\n",
      "loss: 0.194910  [ 3232/56940]\n",
      "loss: 0.669492  [ 6432/56940]\n",
      "loss: 0.496649  [ 9632/56940]\n",
      "loss: 0.159617  [12832/56940]\n",
      "loss: 0.191010  [16032/56940]\n",
      "loss: 0.416816  [19232/56940]\n",
      "loss: 0.260218  [22432/56940]\n",
      "loss: 0.140772  [25632/56940]\n",
      "loss: 0.122821  [28832/56940]\n",
      "loss: 0.186523  [32032/56940]\n",
      "loss: 0.095764  [35232/56940]\n",
      "loss: 0.164676  [38432/56940]\n",
      "loss: 0.246689  [41632/56940]\n",
      "loss: 0.163676  [44832/56940]\n",
      "loss: 0.393664  [48032/56940]\n",
      "loss: 0.273508  [51232/56940]\n",
      "loss: 0.295170  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.222135 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.193154  [   32/56940]\n",
      "loss: 0.526465  [ 3232/56940]\n",
      "loss: 0.265973  [ 6432/56940]\n",
      "loss: 0.189514  [ 9632/56940]\n",
      "loss: 0.227000  [12832/56940]\n",
      "loss: 0.259423  [16032/56940]\n",
      "loss: 0.387983  [19232/56940]\n",
      "loss: 0.350404  [22432/56940]\n",
      "loss: 0.263786  [25632/56940]\n",
      "loss: 0.188988  [28832/56940]\n",
      "loss: 0.213168  [32032/56940]\n",
      "loss: 0.182784  [35232/56940]\n",
      "loss: 0.218157  [38432/56940]\n",
      "loss: 0.214499  [41632/56940]\n",
      "loss: 0.335208  [44832/56940]\n",
      "loss: 0.201940  [48032/56940]\n",
      "loss: 0.382105  [51232/56940]\n",
      "loss: 0.191478  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.217172 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.180249  [   32/56940]\n",
      "loss: 0.136340  [ 3232/56940]\n",
      "loss: 0.190040  [ 6432/56940]\n",
      "loss: 0.081925  [ 9632/56940]\n",
      "loss: 0.333863  [12832/56940]\n",
      "loss: 0.366422  [16032/56940]\n",
      "loss: 0.204121  [19232/56940]\n",
      "loss: 0.335641  [22432/56940]\n",
      "loss: 0.163090  [25632/56940]\n",
      "loss: 0.214653  [28832/56940]\n",
      "loss: 0.284119  [32032/56940]\n",
      "loss: 0.267361  [35232/56940]\n",
      "loss: 0.385365  [38432/56940]\n",
      "loss: 0.363587  [41632/56940]\n",
      "loss: 0.225987  [44832/56940]\n",
      "loss: 0.241260  [48032/56940]\n",
      "loss: 0.301456  [51232/56940]\n",
      "loss: 0.219842  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.219068 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.224809  [   32/56940]\n",
      "loss: 0.152727  [ 3232/56940]\n",
      "loss: 0.267395  [ 6432/56940]\n",
      "loss: 0.412181  [ 9632/56940]\n",
      "loss: 0.267200  [12832/56940]\n",
      "loss: 0.216336  [16032/56940]\n",
      "loss: 0.326685  [19232/56940]\n",
      "loss: 0.198216  [22432/56940]\n",
      "loss: 0.253731  [25632/56940]\n",
      "loss: 0.284505  [28832/56940]\n",
      "loss: 0.209554  [32032/56940]\n",
      "loss: 0.386268  [35232/56940]\n",
      "loss: 0.220034  [38432/56940]\n",
      "loss: 0.303096  [41632/56940]\n",
      "loss: 0.265753  [44832/56940]\n",
      "loss: 0.450265  [48032/56940]\n",
      "loss: 0.221991  [51232/56940]\n",
      "loss: 0.262108  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.213105 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.259617  [   32/56940]\n",
      "loss: 0.171130  [ 3232/56940]\n",
      "loss: 0.167537  [ 6432/56940]\n",
      "loss: 0.192849  [ 9632/56940]\n",
      "loss: 0.157355  [12832/56940]\n",
      "loss: 0.360985  [16032/56940]\n",
      "loss: 0.221676  [19232/56940]\n",
      "loss: 0.249000  [22432/56940]\n",
      "loss: 0.216815  [25632/56940]\n",
      "loss: 0.225891  [28832/56940]\n",
      "loss: 0.134872  [32032/56940]\n",
      "loss: 0.201168  [35232/56940]\n",
      "loss: 0.249462  [38432/56940]\n",
      "loss: 0.237981  [41632/56940]\n",
      "loss: 0.255163  [44832/56940]\n",
      "loss: 0.137615  [48032/56940]\n",
      "loss: 0.352550  [51232/56940]\n",
      "loss: 0.311226  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.218211 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.137476  [   32/56940]\n",
      "loss: 0.294446  [ 3232/56940]\n",
      "loss: 0.353491  [ 6432/56940]\n",
      "loss: 0.308871  [ 9632/56940]\n",
      "loss: 0.202864  [12832/56940]\n",
      "loss: 0.173150  [16032/56940]\n",
      "loss: 0.160286  [19232/56940]\n",
      "loss: 0.127614  [22432/56940]\n",
      "loss: 0.280235  [25632/56940]\n",
      "loss: 0.255150  [28832/56940]\n",
      "loss: 0.124357  [32032/56940]\n",
      "loss: 0.284368  [35232/56940]\n",
      "loss: 0.221319  [38432/56940]\n",
      "loss: 0.160396  [41632/56940]\n",
      "loss: 0.237429  [44832/56940]\n",
      "loss: 0.224649  [48032/56940]\n",
      "loss: 0.165431  [51232/56940]\n",
      "loss: 0.191714  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.219561 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.325902  [   32/56940]\n",
      "loss: 0.607365  [ 3232/56940]\n",
      "loss: 0.214980  [ 6432/56940]\n",
      "loss: 0.128711  [ 9632/56940]\n",
      "loss: 0.224551  [12832/56940]\n",
      "loss: 0.202362  [16032/56940]\n",
      "loss: 0.160489  [19232/56940]\n",
      "loss: 0.294774  [22432/56940]\n",
      "loss: 0.114456  [25632/56940]\n",
      "loss: 0.278526  [28832/56940]\n",
      "loss: 0.206645  [32032/56940]\n",
      "loss: 0.454202  [35232/56940]\n",
      "loss: 0.368293  [38432/56940]\n",
      "loss: 0.171057  [41632/56940]\n",
      "loss: 0.308103  [44832/56940]\n",
      "loss: 0.201594  [48032/56940]\n",
      "loss: 0.159962  [51232/56940]\n",
      "loss: 0.378623  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.215169 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.203153  [   32/56940]\n",
      "loss: 0.276842  [ 3232/56940]\n",
      "loss: 0.245312  [ 6432/56940]\n",
      "loss: 0.316601  [ 9632/56940]\n",
      "loss: 0.180055  [12832/56940]\n",
      "loss: 0.193075  [16032/56940]\n",
      "loss: 0.331454  [19232/56940]\n",
      "loss: 0.114765  [22432/56940]\n",
      "loss: 0.418563  [25632/56940]\n",
      "loss: 0.243211  [28832/56940]\n",
      "loss: 0.144293  [32032/56940]\n",
      "loss: 0.131822  [35232/56940]\n",
      "loss: 0.368018  [38432/56940]\n",
      "loss: 0.287586  [41632/56940]\n",
      "loss: 0.162182  [44832/56940]\n",
      "loss: 0.480588  [48032/56940]\n",
      "loss: 0.353509  [51232/56940]\n",
      "loss: 0.228923  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.214319 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.167782  [   32/56940]\n",
      "loss: 0.382268  [ 3232/56940]\n",
      "loss: 0.161375  [ 6432/56940]\n",
      "loss: 0.199046  [ 9632/56940]\n",
      "loss: 0.276079  [12832/56940]\n",
      "loss: 0.195234  [16032/56940]\n",
      "loss: 0.349336  [19232/56940]\n",
      "loss: 0.326804  [22432/56940]\n",
      "loss: 0.102337  [25632/56940]\n",
      "loss: 0.120260  [28832/56940]\n",
      "loss: 0.155974  [32032/56940]\n",
      "loss: 0.171790  [35232/56940]\n",
      "loss: 0.258658  [38432/56940]\n",
      "loss: 0.453487  [41632/56940]\n",
      "loss: 0.149341  [44832/56940]\n",
      "loss: 0.349380  [48032/56940]\n",
      "loss: 0.519525  [51232/56940]\n",
      "loss: 0.147970  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.216484 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.280355  [   32/56940]\n",
      "loss: 0.400538  [ 3232/56940]\n",
      "loss: 0.380578  [ 6432/56940]\n",
      "loss: 0.745172  [ 9632/56940]\n",
      "loss: 0.241294  [12832/56940]\n",
      "loss: 0.311454  [16032/56940]\n",
      "loss: 0.141400  [19232/56940]\n",
      "loss: 0.154522  [22432/56940]\n",
      "loss: 0.332919  [25632/56940]\n",
      "loss: 0.358262  [28832/56940]\n",
      "loss: 0.494270  [32032/56940]\n",
      "loss: 0.106557  [35232/56940]\n",
      "loss: 0.200256  [38432/56940]\n",
      "loss: 0.155926  [41632/56940]\n",
      "loss: 0.608956  [44832/56940]\n",
      "loss: 0.195833  [48032/56940]\n",
      "loss: 0.242472  [51232/56940]\n",
      "loss: 0.256614  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.216875 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.260750  [   32/56940]\n",
      "loss: 0.437881  [ 3232/56940]\n",
      "loss: 0.278521  [ 6432/56940]\n",
      "loss: 0.293958  [ 9632/56940]\n",
      "loss: 0.513285  [12832/56940]\n",
      "loss: 0.201096  [16032/56940]\n",
      "loss: 0.297905  [19232/56940]\n",
      "loss: 0.215602  [22432/56940]\n",
      "loss: 0.307793  [25632/56940]\n",
      "loss: 0.266814  [28832/56940]\n",
      "loss: 0.091129  [32032/56940]\n",
      "loss: 0.107400  [35232/56940]\n",
      "loss: 0.161435  [38432/56940]\n",
      "loss: 0.090983  [41632/56940]\n",
      "loss: 0.114152  [44832/56940]\n",
      "loss: 0.249193  [48032/56940]\n",
      "loss: 0.124427  [51232/56940]\n",
      "loss: 0.230898  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.231818 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.324231  [   32/56940]\n",
      "loss: 0.172937  [ 3232/56940]\n",
      "loss: 0.258037  [ 6432/56940]\n",
      "loss: 0.140446  [ 9632/56940]\n",
      "loss: 0.278528  [12832/56940]\n",
      "loss: 0.204691  [16032/56940]\n",
      "loss: 0.177084  [19232/56940]\n",
      "loss: 0.251974  [22432/56940]\n",
      "loss: 0.301552  [25632/56940]\n",
      "loss: 0.227427  [28832/56940]\n",
      "loss: 0.203395  [32032/56940]\n",
      "loss: 0.433466  [35232/56940]\n",
      "loss: 0.148750  [38432/56940]\n",
      "loss: 0.356076  [41632/56940]\n",
      "loss: 0.236561  [44832/56940]\n",
      "loss: 0.118377  [48032/56940]\n",
      "loss: 0.166056  [51232/56940]\n",
      "loss: 0.320664  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.211664 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.135640  [   32/56940]\n",
      "loss: 0.163791  [ 3232/56940]\n",
      "loss: 0.385207  [ 6432/56940]\n",
      "loss: 0.249968  [ 9632/56940]\n",
      "loss: 0.257765  [12832/56940]\n",
      "loss: 0.134444  [16032/56940]\n",
      "loss: 0.425326  [19232/56940]\n",
      "loss: 0.219594  [22432/56940]\n",
      "loss: 0.144297  [25632/56940]\n",
      "loss: 0.165651  [28832/56940]\n",
      "loss: 0.154273  [32032/56940]\n",
      "loss: 0.329658  [35232/56940]\n",
      "loss: 0.395809  [38432/56940]\n",
      "loss: 0.241696  [41632/56940]\n",
      "loss: 0.177719  [44832/56940]\n",
      "loss: 0.304391  [48032/56940]\n",
      "loss: 0.209937  [51232/56940]\n",
      "loss: 0.248156  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.213647 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.164840  [   32/56940]\n",
      "loss: 0.156693  [ 3232/56940]\n",
      "loss: 0.154274  [ 6432/56940]\n",
      "loss: 0.162804  [ 9632/56940]\n",
      "loss: 0.497645  [12832/56940]\n",
      "loss: 0.254815  [16032/56940]\n",
      "loss: 0.247460  [19232/56940]\n",
      "loss: 0.322445  [22432/56940]\n",
      "loss: 0.353082  [25632/56940]\n",
      "loss: 0.310024  [28832/56940]\n",
      "loss: 0.176129  [32032/56940]\n",
      "loss: 0.217476  [35232/56940]\n",
      "loss: 0.103867  [38432/56940]\n",
      "loss: 0.298205  [41632/56940]\n",
      "loss: 0.685920  [44832/56940]\n",
      "loss: 0.197713  [48032/56940]\n",
      "loss: 0.369702  [51232/56940]\n",
      "loss: 0.344176  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.249840 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.392339  [   32/56940]\n",
      "loss: 0.241764  [ 3232/56940]\n",
      "loss: 0.192705  [ 6432/56940]\n",
      "loss: 0.335182  [ 9632/56940]\n",
      "loss: 0.346485  [12832/56940]\n",
      "loss: 0.351049  [16032/56940]\n",
      "loss: 0.462867  [19232/56940]\n",
      "loss: 0.142093  [22432/56940]\n",
      "loss: 0.389825  [25632/56940]\n",
      "loss: 0.207215  [28832/56940]\n",
      "loss: 0.286244  [32032/56940]\n",
      "loss: 0.861508  [35232/56940]\n",
      "loss: 0.322997  [38432/56940]\n",
      "loss: 0.157436  [41632/56940]\n",
      "loss: 0.167581  [44832/56940]\n",
      "loss: 0.217523  [48032/56940]\n",
      "loss: 0.307565  [51232/56940]\n",
      "loss: 0.180999  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.208480 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.303318  [   32/56940]\n",
      "loss: 0.227861  [ 3232/56940]\n",
      "loss: 0.211055  [ 6432/56940]\n",
      "loss: 0.113866  [ 9632/56940]\n",
      "loss: 0.312206  [12832/56940]\n",
      "loss: 0.320203  [16032/56940]\n",
      "loss: 0.155166  [19232/56940]\n",
      "loss: 0.280201  [22432/56940]\n",
      "loss: 0.310674  [25632/56940]\n",
      "loss: 0.180059  [28832/56940]\n",
      "loss: 0.164994  [32032/56940]\n",
      "loss: 0.444780  [35232/56940]\n",
      "loss: 0.303072  [38432/56940]\n",
      "loss: 0.178118  [41632/56940]\n",
      "loss: 0.363461  [44832/56940]\n",
      "loss: 0.344246  [48032/56940]\n",
      "loss: 0.213550  [51232/56940]\n",
      "loss: 0.310335  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.218307 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.176261  [   32/56940]\n",
      "loss: 0.244061  [ 3232/56940]\n",
      "loss: 0.200264  [ 6432/56940]\n",
      "loss: 0.311554  [ 9632/56940]\n",
      "loss: 0.400679  [12832/56940]\n",
      "loss: 0.370920  [16032/56940]\n",
      "loss: 0.444929  [19232/56940]\n",
      "loss: 0.250422  [22432/56940]\n",
      "loss: 0.419687  [25632/56940]\n",
      "loss: 0.277305  [28832/56940]\n",
      "loss: 0.097576  [32032/56940]\n",
      "loss: 0.524969  [35232/56940]\n",
      "loss: 0.611808  [38432/56940]\n",
      "loss: 0.180403  [41632/56940]\n",
      "loss: 0.141562  [44832/56940]\n",
      "loss: 0.164463  [48032/56940]\n",
      "loss: 0.343059  [51232/56940]\n",
      "loss: 0.320552  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.242421 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.392290  [   32/56940]\n",
      "loss: 0.186452  [ 3232/56940]\n",
      "loss: 0.287398  [ 6432/56940]\n",
      "loss: 0.215282  [ 9632/56940]\n",
      "loss: 0.355709  [12832/56940]\n",
      "loss: 0.297572  [16032/56940]\n",
      "loss: 0.160692  [19232/56940]\n",
      "loss: 0.098452  [22432/56940]\n",
      "loss: 0.152055  [25632/56940]\n",
      "loss: 0.146325  [28832/56940]\n",
      "loss: 0.176209  [32032/56940]\n",
      "loss: 0.222134  [35232/56940]\n",
      "loss: 0.254556  [38432/56940]\n",
      "loss: 0.373486  [41632/56940]\n",
      "loss: 0.162474  [44832/56940]\n",
      "loss: 0.216630  [48032/56940]\n",
      "loss: 0.160939  [51232/56940]\n",
      "loss: 0.254961  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.232374 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.312967  [   32/56940]\n",
      "loss: 0.251596  [ 3232/56940]\n",
      "loss: 0.288543  [ 6432/56940]\n",
      "loss: 0.281905  [ 9632/56940]\n",
      "loss: 0.365895  [12832/56940]\n",
      "loss: 0.263324  [16032/56940]\n",
      "loss: 0.330010  [19232/56940]\n",
      "loss: 0.192623  [22432/56940]\n",
      "loss: 0.118951  [25632/56940]\n",
      "loss: 0.216512  [28832/56940]\n",
      "loss: 0.598842  [32032/56940]\n",
      "loss: 0.212575  [35232/56940]\n",
      "loss: 0.232550  [38432/56940]\n",
      "loss: 0.158434  [41632/56940]\n",
      "loss: 0.404112  [44832/56940]\n",
      "loss: 0.304194  [48032/56940]\n",
      "loss: 0.190800  [51232/56940]\n",
      "loss: 0.317260  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.229137 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.260494  [   32/56940]\n",
      "loss: 0.273341  [ 3232/56940]\n",
      "loss: 0.307250  [ 6432/56940]\n",
      "loss: 0.210798  [ 9632/56940]\n",
      "loss: 0.250927  [12832/56940]\n",
      "loss: 0.205203  [16032/56940]\n",
      "loss: 0.610112  [19232/56940]\n",
      "loss: 0.216699  [22432/56940]\n",
      "loss: 0.142258  [25632/56940]\n",
      "loss: 0.325336  [28832/56940]\n",
      "loss: 0.354524  [32032/56940]\n",
      "loss: 0.199888  [35232/56940]\n",
      "loss: 0.192571  [38432/56940]\n",
      "loss: 0.184033  [41632/56940]\n",
      "loss: 0.120099  [44832/56940]\n",
      "loss: 0.208432  [48032/56940]\n",
      "loss: 0.162287  [51232/56940]\n",
      "loss: 0.132683  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.232554 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.167203  [   32/56940]\n",
      "loss: 0.156142  [ 3232/56940]\n",
      "loss: 0.405329  [ 6432/56940]\n",
      "loss: 0.166560  [ 9632/56940]\n",
      "loss: 0.270301  [12832/56940]\n",
      "loss: 0.290490  [16032/56940]\n",
      "loss: 0.285335  [19232/56940]\n",
      "loss: 0.326556  [22432/56940]\n",
      "loss: 0.128470  [25632/56940]\n",
      "loss: 0.149108  [28832/56940]\n",
      "loss: 0.456296  [32032/56940]\n",
      "loss: 0.443542  [35232/56940]\n",
      "loss: 0.202285  [38432/56940]\n",
      "loss: 0.335071  [41632/56940]\n",
      "loss: 0.249701  [44832/56940]\n",
      "loss: 0.250557  [48032/56940]\n",
      "loss: 0.212389  [51232/56940]\n",
      "loss: 0.363343  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.212215 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.481599  [   32/56940]\n",
      "loss: 0.158939  [ 3232/56940]\n",
      "loss: 0.274721  [ 6432/56940]\n",
      "loss: 0.597524  [ 9632/56940]\n",
      "loss: 0.179411  [12832/56940]\n",
      "loss: 0.165970  [16032/56940]\n",
      "loss: 0.206082  [19232/56940]\n",
      "loss: 0.323245  [22432/56940]\n",
      "loss: 0.188234  [25632/56940]\n",
      "loss: 0.398727  [28832/56940]\n",
      "loss: 0.264052  [32032/56940]\n",
      "loss: 0.285232  [35232/56940]\n",
      "loss: 0.225028  [38432/56940]\n",
      "loss: 0.374074  [41632/56940]\n",
      "loss: 0.219371  [44832/56940]\n",
      "loss: 0.282167  [48032/56940]\n",
      "loss: 0.245902  [51232/56940]\n",
      "loss: 0.222133  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.235510 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.144533  [   32/56940]\n",
      "loss: 0.196834  [ 3232/56940]\n",
      "loss: 0.245145  [ 6432/56940]\n",
      "loss: 0.432532  [ 9632/56940]\n",
      "loss: 0.295503  [12832/56940]\n",
      "loss: 0.337267  [16032/56940]\n",
      "loss: 0.184068  [19232/56940]\n",
      "loss: 0.174471  [22432/56940]\n",
      "loss: 0.093490  [25632/56940]\n",
      "loss: 0.132501  [28832/56940]\n",
      "loss: 0.338169  [32032/56940]\n",
      "loss: 0.146109  [35232/56940]\n",
      "loss: 0.200256  [38432/56940]\n",
      "loss: 0.253280  [41632/56940]\n",
      "loss: 0.183317  [44832/56940]\n",
      "loss: 0.090580  [48032/56940]\n",
      "loss: 0.793595  [51232/56940]\n",
      "loss: 0.222843  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.209334 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.206619  [   32/56940]\n",
      "loss: 0.151858  [ 3232/56940]\n",
      "loss: 0.214134  [ 6432/56940]\n",
      "loss: 0.204072  [ 9632/56940]\n",
      "loss: 0.269757  [12832/56940]\n",
      "loss: 0.159787  [16032/56940]\n",
      "loss: 0.175390  [19232/56940]\n",
      "loss: 0.277499  [22432/56940]\n",
      "loss: 0.419530  [25632/56940]\n",
      "loss: 0.231184  [28832/56940]\n",
      "loss: 0.157879  [32032/56940]\n",
      "loss: 0.462533  [35232/56940]\n",
      "loss: 0.378096  [38432/56940]\n",
      "loss: 0.253369  [41632/56940]\n",
      "loss: 0.104531  [44832/56940]\n",
      "loss: 0.410569  [48032/56940]\n",
      "loss: 0.168718  [51232/56940]\n",
      "loss: 0.304944  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.210921 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.258033  [   32/56940]\n",
      "loss: 0.424540  [ 3232/56940]\n",
      "loss: 0.183464  [ 6432/56940]\n",
      "loss: 0.124579  [ 9632/56940]\n",
      "loss: 0.347785  [12832/56940]\n",
      "loss: 0.217195  [16032/56940]\n",
      "loss: 0.401201  [19232/56940]\n",
      "loss: 0.189669  [22432/56940]\n",
      "loss: 0.261406  [25632/56940]\n",
      "loss: 0.372994  [28832/56940]\n",
      "loss: 0.224407  [32032/56940]\n",
      "loss: 0.217069  [35232/56940]\n",
      "loss: 0.254306  [38432/56940]\n",
      "loss: 0.286766  [41632/56940]\n",
      "loss: 0.391381  [44832/56940]\n",
      "loss: 0.285331  [48032/56940]\n",
      "loss: 0.096479  [51232/56940]\n",
      "loss: 0.157939  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.209940 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.126098  [   32/56940]\n",
      "loss: 0.241988  [ 3232/56940]\n",
      "loss: 0.128932  [ 6432/56940]\n",
      "loss: 0.231446  [ 9632/56940]\n",
      "loss: 0.277769  [12832/56940]\n",
      "loss: 0.332063  [16032/56940]\n",
      "loss: 0.219074  [19232/56940]\n",
      "loss: 0.392158  [22432/56940]\n",
      "loss: 0.412936  [25632/56940]\n",
      "loss: 0.389382  [28832/56940]\n",
      "loss: 0.208836  [32032/56940]\n",
      "loss: 0.390551  [35232/56940]\n",
      "loss: 0.172773  [38432/56940]\n",
      "loss: 0.166918  [41632/56940]\n",
      "loss: 0.093924  [44832/56940]\n",
      "loss: 0.294598  [48032/56940]\n",
      "loss: 0.278395  [51232/56940]\n",
      "loss: 0.176113  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.217001 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.111952  [   32/56940]\n",
      "loss: 0.225903  [ 3232/56940]\n",
      "loss: 0.311346  [ 6432/56940]\n",
      "loss: 0.172719  [ 9632/56940]\n",
      "loss: 0.353245  [12832/56940]\n",
      "loss: 0.292172  [16032/56940]\n",
      "loss: 0.201382  [19232/56940]\n",
      "loss: 0.260345  [22432/56940]\n",
      "loss: 0.236116  [25632/56940]\n",
      "loss: 0.140695  [28832/56940]\n",
      "loss: 0.173686  [32032/56940]\n",
      "loss: 0.227095  [35232/56940]\n",
      "loss: 0.591416  [38432/56940]\n",
      "loss: 0.324810  [41632/56940]\n",
      "loss: 0.153184  [44832/56940]\n",
      "loss: 0.253399  [48032/56940]\n",
      "loss: 0.178478  [51232/56940]\n",
      "loss: 0.152879  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.217098 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.225848  [   32/56940]\n",
      "loss: 0.125659  [ 3232/56940]\n",
      "loss: 0.329864  [ 6432/56940]\n",
      "loss: 0.391637  [ 9632/56940]\n",
      "loss: 0.151068  [12832/56940]\n",
      "loss: 0.586962  [16032/56940]\n",
      "loss: 0.223514  [19232/56940]\n",
      "loss: 0.278741  [22432/56940]\n",
      "loss: 0.351009  [25632/56940]\n",
      "loss: 0.242605  [28832/56940]\n",
      "loss: 0.171171  [32032/56940]\n",
      "loss: 0.294939  [35232/56940]\n",
      "loss: 0.238711  [38432/56940]\n",
      "loss: 0.306328  [41632/56940]\n",
      "loss: 0.269399  [44832/56940]\n",
      "loss: 0.224210  [48032/56940]\n",
      "loss: 0.231702  [51232/56940]\n",
      "loss: 0.135222  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.226691 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.343900  [   32/56940]\n",
      "loss: 0.229035  [ 3232/56940]\n",
      "loss: 0.241963  [ 6432/56940]\n",
      "loss: 0.105522  [ 9632/56940]\n",
      "loss: 0.242850  [12832/56940]\n",
      "loss: 0.189260  [16032/56940]\n",
      "loss: 0.106716  [19232/56940]\n",
      "loss: 0.282523  [22432/56940]\n",
      "loss: 0.111130  [25632/56940]\n",
      "loss: 0.200542  [28832/56940]\n",
      "loss: 0.173627  [32032/56940]\n",
      "loss: 0.642894  [35232/56940]\n",
      "loss: 0.408518  [38432/56940]\n",
      "loss: 0.321424  [41632/56940]\n",
      "loss: 0.260494  [44832/56940]\n",
      "loss: 0.267873  [48032/56940]\n",
      "loss: 0.290450  [51232/56940]\n",
      "loss: 0.221290  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.211220 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.110845  [   32/56940]\n",
      "loss: 0.192969  [ 3232/56940]\n",
      "loss: 0.136124  [ 6432/56940]\n",
      "loss: 0.476777  [ 9632/56940]\n",
      "loss: 0.237836  [12832/56940]\n",
      "loss: 0.119475  [16032/56940]\n",
      "loss: 0.172193  [19232/56940]\n",
      "loss: 0.129629  [22432/56940]\n",
      "loss: 0.264596  [25632/56940]\n",
      "loss: 0.247452  [28832/56940]\n",
      "loss: 0.208724  [32032/56940]\n",
      "loss: 0.179558  [35232/56940]\n",
      "loss: 0.148888  [38432/56940]\n",
      "loss: 0.345108  [41632/56940]\n",
      "loss: 0.315167  [44832/56940]\n",
      "loss: 0.322369  [48032/56940]\n",
      "loss: 0.246249  [51232/56940]\n",
      "loss: 0.231230  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.220143 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.588076  [   32/56940]\n",
      "loss: 0.416923  [ 3232/56940]\n",
      "loss: 0.275696  [ 6432/56940]\n",
      "loss: 0.174381  [ 9632/56940]\n",
      "loss: 0.186633  [12832/56940]\n",
      "loss: 0.302694  [16032/56940]\n",
      "loss: 0.138216  [19232/56940]\n",
      "loss: 0.182202  [22432/56940]\n",
      "loss: 0.440923  [25632/56940]\n",
      "loss: 0.249719  [28832/56940]\n",
      "loss: 0.166166  [32032/56940]\n",
      "loss: 0.224202  [35232/56940]\n",
      "loss: 0.247198  [38432/56940]\n",
      "loss: 0.222718  [41632/56940]\n",
      "loss: 0.386696  [44832/56940]\n",
      "loss: 0.320939  [48032/56940]\n",
      "loss: 0.244107  [51232/56940]\n",
      "loss: 0.326062  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.216844 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.098523  [   32/56940]\n",
      "loss: 0.564936  [ 3232/56940]\n",
      "loss: 0.164871  [ 6432/56940]\n",
      "loss: 0.179440  [ 9632/56940]\n",
      "loss: 0.214690  [12832/56940]\n",
      "loss: 0.267809  [16032/56940]\n",
      "loss: 0.169542  [19232/56940]\n",
      "loss: 0.282665  [22432/56940]\n",
      "loss: 0.219384  [25632/56940]\n",
      "loss: 0.089322  [28832/56940]\n",
      "loss: 0.245625  [32032/56940]\n",
      "loss: 0.074978  [35232/56940]\n",
      "loss: 0.305247  [38432/56940]\n",
      "loss: 0.221349  [41632/56940]\n",
      "loss: 0.278477  [44832/56940]\n",
      "loss: 0.235220  [48032/56940]\n",
      "loss: 0.168367  [51232/56940]\n",
      "loss: 0.267023  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.215016 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.177175  [   32/56940]\n",
      "loss: 0.332969  [ 3232/56940]\n",
      "loss: 0.470109  [ 6432/56940]\n",
      "loss: 0.300909  [ 9632/56940]\n",
      "loss: 0.214334  [12832/56940]\n",
      "loss: 0.265211  [16032/56940]\n",
      "loss: 0.246805  [19232/56940]\n",
      "loss: 0.236840  [22432/56940]\n",
      "loss: 0.212002  [25632/56940]\n",
      "loss: 0.266369  [28832/56940]\n",
      "loss: 0.423350  [32032/56940]\n",
      "loss: 0.271689  [35232/56940]\n",
      "loss: 0.126564  [38432/56940]\n",
      "loss: 0.323353  [41632/56940]\n",
      "loss: 0.284833  [44832/56940]\n",
      "loss: 0.184034  [48032/56940]\n",
      "loss: 0.263645  [51232/56940]\n",
      "loss: 0.230238  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.218070 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.181565  [   32/56940]\n",
      "loss: 0.215070  [ 3232/56940]\n",
      "loss: 0.233234  [ 6432/56940]\n",
      "loss: 0.224878  [ 9632/56940]\n",
      "loss: 0.136614  [12832/56940]\n",
      "loss: 0.167299  [16032/56940]\n",
      "loss: 0.181788  [19232/56940]\n",
      "loss: 0.118826  [22432/56940]\n",
      "loss: 0.140667  [25632/56940]\n",
      "loss: 0.079237  [28832/56940]\n",
      "loss: 0.247960  [32032/56940]\n",
      "loss: 0.203281  [35232/56940]\n",
      "loss: 0.207656  [38432/56940]\n",
      "loss: 0.264140  [41632/56940]\n",
      "loss: 0.346484  [44832/56940]\n",
      "loss: 0.292082  [48032/56940]\n",
      "loss: 0.302414  [51232/56940]\n",
      "loss: 0.188080  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.220005 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.270606  [   32/56940]\n",
      "loss: 0.302293  [ 3232/56940]\n",
      "loss: 0.121259  [ 6432/56940]\n",
      "loss: 0.377467  [ 9632/56940]\n",
      "loss: 0.333660  [12832/56940]\n",
      "loss: 0.156125  [16032/56940]\n",
      "loss: 0.253821  [19232/56940]\n",
      "loss: 0.247754  [22432/56940]\n",
      "loss: 0.166003  [25632/56940]\n",
      "loss: 0.418631  [28832/56940]\n",
      "loss: 0.195134  [32032/56940]\n",
      "loss: 0.375472  [35232/56940]\n",
      "loss: 0.152652  [38432/56940]\n",
      "loss: 0.277377  [41632/56940]\n",
      "loss: 0.343469  [44832/56940]\n",
      "loss: 0.418112  [48032/56940]\n",
      "loss: 0.456732  [51232/56940]\n",
      "loss: 0.263967  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.226766 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.211540  [   32/56940]\n",
      "loss: 0.770067  [ 3232/56940]\n",
      "loss: 0.137738  [ 6432/56940]\n",
      "loss: 0.237227  [ 9632/56940]\n",
      "loss: 0.129293  [12832/56940]\n",
      "loss: 0.206691  [16032/56940]\n",
      "loss: 0.240452  [19232/56940]\n",
      "loss: 0.186944  [22432/56940]\n",
      "loss: 0.227186  [25632/56940]\n",
      "loss: 0.318810  [28832/56940]\n",
      "loss: 0.243735  [32032/56940]\n",
      "loss: 0.661687  [35232/56940]\n",
      "loss: 0.229609  [38432/56940]\n",
      "loss: 0.342490  [41632/56940]\n",
      "loss: 0.162115  [44832/56940]\n",
      "loss: 0.171517  [48032/56940]\n",
      "loss: 0.350003  [51232/56940]\n",
      "loss: 0.253966  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.211544 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.139871  [   32/56940]\n",
      "loss: 0.114284  [ 3232/56940]\n",
      "loss: 0.478952  [ 6432/56940]\n",
      "loss: 0.196903  [ 9632/56940]\n",
      "loss: 0.354283  [12832/56940]\n",
      "loss: 0.269061  [16032/56940]\n",
      "loss: 0.281945  [19232/56940]\n",
      "loss: 0.163345  [22432/56940]\n",
      "loss: 0.296253  [25632/56940]\n",
      "loss: 0.143229  [28832/56940]\n",
      "loss: 0.188090  [32032/56940]\n",
      "loss: 0.200831  [35232/56940]\n",
      "loss: 0.371747  [38432/56940]\n",
      "loss: 0.197484  [41632/56940]\n",
      "loss: 0.202928  [44832/56940]\n",
      "loss: 0.217311  [48032/56940]\n",
      "loss: 0.271534  [51232/56940]\n",
      "loss: 0.185246  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.214276 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.286782  [   32/56940]\n",
      "loss: 0.198418  [ 3232/56940]\n",
      "loss: 0.259321  [ 6432/56940]\n",
      "loss: 0.303974  [ 9632/56940]\n",
      "loss: 0.197625  [12832/56940]\n",
      "loss: 0.315283  [16032/56940]\n",
      "loss: 0.237486  [19232/56940]\n",
      "loss: 0.523777  [22432/56940]\n",
      "loss: 0.298945  [25632/56940]\n",
      "loss: 0.327603  [28832/56940]\n",
      "loss: 0.240134  [32032/56940]\n",
      "loss: 0.098310  [35232/56940]\n",
      "loss: 0.510108  [38432/56940]\n",
      "loss: 0.143315  [41632/56940]\n",
      "loss: 0.103218  [44832/56940]\n",
      "loss: 0.436461  [48032/56940]\n",
      "loss: 0.107837  [51232/56940]\n",
      "loss: 0.184661  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.224107 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.194679  [   32/56940]\n",
      "loss: 0.209138  [ 3232/56940]\n",
      "loss: 0.398289  [ 6432/56940]\n",
      "loss: 0.160924  [ 9632/56940]\n",
      "loss: 0.177028  [12832/56940]\n",
      "loss: 0.126302  [16032/56940]\n",
      "loss: 0.296305  [19232/56940]\n",
      "loss: 0.267639  [22432/56940]\n",
      "loss: 0.312302  [25632/56940]\n",
      "loss: 0.141641  [28832/56940]\n",
      "loss: 0.530450  [32032/56940]\n",
      "loss: 0.430205  [35232/56940]\n",
      "loss: 0.257720  [38432/56940]\n",
      "loss: 0.165713  [41632/56940]\n",
      "loss: 0.170883  [44832/56940]\n",
      "loss: 0.416965  [48032/56940]\n",
      "loss: 0.219918  [51232/56940]\n",
      "loss: 0.161343  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.223374 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.210562  [   32/56940]\n",
      "loss: 0.213601  [ 3232/56940]\n",
      "loss: 0.310356  [ 6432/56940]\n",
      "loss: 0.475387  [ 9632/56940]\n",
      "loss: 0.251274  [12832/56940]\n",
      "loss: 0.381065  [16032/56940]\n",
      "loss: 0.281755  [19232/56940]\n",
      "loss: 0.167524  [22432/56940]\n",
      "loss: 0.226084  [25632/56940]\n",
      "loss: 0.234027  [28832/56940]\n",
      "loss: 0.195862  [32032/56940]\n",
      "loss: 0.171860  [35232/56940]\n",
      "loss: 0.173746  [38432/56940]\n",
      "loss: 0.219850  [41632/56940]\n",
      "loss: 0.279568  [44832/56940]\n",
      "loss: 0.176174  [48032/56940]\n",
      "loss: 0.142135  [51232/56940]\n",
      "loss: 0.436049  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.235584 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.213554  [   32/56940]\n",
      "loss: 0.131995  [ 3232/56940]\n",
      "loss: 0.163378  [ 6432/56940]\n",
      "loss: 0.161227  [ 9632/56940]\n",
      "loss: 0.242767  [12832/56940]\n",
      "loss: 0.183126  [16032/56940]\n",
      "loss: 0.232281  [19232/56940]\n",
      "loss: 0.260191  [22432/56940]\n",
      "loss: 0.391249  [25632/56940]\n",
      "loss: 0.281722  [28832/56940]\n",
      "loss: 0.149078  [32032/56940]\n",
      "loss: 0.185095  [35232/56940]\n",
      "loss: 0.139001  [38432/56940]\n",
      "loss: 0.266804  [41632/56940]\n",
      "loss: 0.130925  [44832/56940]\n",
      "loss: 0.068153  [48032/56940]\n",
      "loss: 0.404160  [51232/56940]\n",
      "loss: 0.185115  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.226357 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.182500  [   32/56940]\n",
      "loss: 0.171100  [ 3232/56940]\n",
      "loss: 0.283344  [ 6432/56940]\n",
      "loss: 0.371383  [ 9632/56940]\n",
      "loss: 0.125860  [12832/56940]\n",
      "loss: 0.218326  [16032/56940]\n",
      "loss: 0.218900  [19232/56940]\n",
      "loss: 0.162855  [22432/56940]\n",
      "loss: 0.243008  [25632/56940]\n",
      "loss: 0.167749  [28832/56940]\n",
      "loss: 0.374308  [32032/56940]\n",
      "loss: 0.237078  [35232/56940]\n",
      "loss: 0.395971  [38432/56940]\n",
      "loss: 0.222070  [41632/56940]\n",
      "loss: 0.243094  [44832/56940]\n",
      "loss: 0.200384  [48032/56940]\n",
      "loss: 0.215962  [51232/56940]\n",
      "loss: 0.326593  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.210426 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.146285  [   32/56940]\n",
      "loss: 0.121316  [ 3232/56940]\n",
      "loss: 0.336641  [ 6432/56940]\n",
      "loss: 0.178154  [ 9632/56940]\n",
      "loss: 0.116646  [12832/56940]\n",
      "loss: 0.103590  [16032/56940]\n",
      "loss: 0.247117  [19232/56940]\n",
      "loss: 0.296935  [22432/56940]\n",
      "loss: 0.291781  [25632/56940]\n",
      "loss: 0.432313  [28832/56940]\n",
      "loss: 0.079211  [32032/56940]\n",
      "loss: 0.207397  [35232/56940]\n",
      "loss: 0.162551  [38432/56940]\n",
      "loss: 0.567549  [41632/56940]\n",
      "loss: 0.205032  [44832/56940]\n",
      "loss: 0.247018  [48032/56940]\n",
      "loss: 0.266020  [51232/56940]\n",
      "loss: 0.089224  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.227960 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.145029  [   32/56940]\n",
      "loss: 0.135483  [ 3232/56940]\n",
      "loss: 0.236508  [ 6432/56940]\n",
      "loss: 0.213557  [ 9632/56940]\n",
      "loss: 0.190212  [12832/56940]\n",
      "loss: 0.482237  [16032/56940]\n",
      "loss: 0.164906  [19232/56940]\n",
      "loss: 0.180455  [22432/56940]\n",
      "loss: 0.132709  [25632/56940]\n",
      "loss: 0.114303  [28832/56940]\n",
      "loss: 0.329368  [32032/56940]\n",
      "loss: 0.216438  [35232/56940]\n",
      "loss: 0.192147  [38432/56940]\n",
      "loss: 0.121023  [41632/56940]\n",
      "loss: 0.208391  [44832/56940]\n",
      "loss: 0.163889  [48032/56940]\n",
      "loss: 0.310902  [51232/56940]\n",
      "loss: 0.141778  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.239192 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.247365  [   32/56940]\n",
      "loss: 0.087718  [ 3232/56940]\n",
      "loss: 0.217219  [ 6432/56940]\n",
      "loss: 0.352475  [ 9632/56940]\n",
      "loss: 0.189849  [12832/56940]\n",
      "loss: 0.202573  [16032/56940]\n",
      "loss: 0.230959  [19232/56940]\n",
      "loss: 0.322923  [22432/56940]\n",
      "loss: 0.245430  [25632/56940]\n",
      "loss: 0.206974  [28832/56940]\n",
      "loss: 0.138026  [32032/56940]\n",
      "loss: 0.175242  [35232/56940]\n",
      "loss: 0.263191  [38432/56940]\n",
      "loss: 0.258068  [41632/56940]\n",
      "loss: 0.120400  [44832/56940]\n",
      "loss: 0.427148  [48032/56940]\n",
      "loss: 0.168361  [51232/56940]\n",
      "loss: 0.252700  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.218633 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.191963  [   32/56940]\n",
      "loss: 0.116388  [ 3232/56940]\n",
      "loss: 0.179911  [ 6432/56940]\n",
      "loss: 0.238655  [ 9632/56940]\n",
      "loss: 0.147282  [12832/56940]\n",
      "loss: 0.235787  [16032/56940]\n",
      "loss: 0.093908  [19232/56940]\n",
      "loss: 0.373589  [22432/56940]\n",
      "loss: 0.312692  [25632/56940]\n",
      "loss: 0.167254  [28832/56940]\n",
      "loss: 0.195225  [32032/56940]\n",
      "loss: 0.147067  [35232/56940]\n",
      "loss: 0.324454  [38432/56940]\n",
      "loss: 0.218977  [41632/56940]\n",
      "loss: 0.262272  [44832/56940]\n",
      "loss: 0.217819  [48032/56940]\n",
      "loss: 0.327775  [51232/56940]\n",
      "loss: 0.177492  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.255340 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.301159  [   32/56940]\n",
      "loss: 0.272765  [ 3232/56940]\n",
      "loss: 0.436854  [ 6432/56940]\n",
      "loss: 0.259773  [ 9632/56940]\n",
      "loss: 0.204334  [12832/56940]\n",
      "loss: 0.155559  [16032/56940]\n",
      "loss: 0.530476  [19232/56940]\n",
      "loss: 0.399745  [22432/56940]\n",
      "loss: 0.405743  [25632/56940]\n",
      "loss: 0.122958  [28832/56940]\n",
      "loss: 0.145255  [32032/56940]\n",
      "loss: 0.428370  [35232/56940]\n",
      "loss: 0.535465  [38432/56940]\n",
      "loss: 0.117780  [41632/56940]\n",
      "loss: 0.385248  [44832/56940]\n",
      "loss: 0.277130  [48032/56940]\n",
      "loss: 0.141054  [51232/56940]\n",
      "loss: 0.226823  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.221695 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.175042  [   32/56940]\n",
      "loss: 0.203093  [ 3232/56940]\n",
      "loss: 0.334060  [ 6432/56940]\n",
      "loss: 0.191230  [ 9632/56940]\n",
      "loss: 0.372809  [12832/56940]\n",
      "loss: 0.180549  [16032/56940]\n",
      "loss: 0.320347  [19232/56940]\n",
      "loss: 0.165125  [22432/56940]\n",
      "loss: 0.230547  [25632/56940]\n",
      "loss: 0.376676  [28832/56940]\n",
      "loss: 0.270269  [32032/56940]\n",
      "loss: 0.308107  [35232/56940]\n",
      "loss: 0.189682  [38432/56940]\n",
      "loss: 0.147439  [41632/56940]\n",
      "loss: 0.215591  [44832/56940]\n",
      "loss: 0.330220  [48032/56940]\n",
      "loss: 0.200400  [51232/56940]\n",
      "loss: 0.266388  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.239715 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.107985  [   32/56940]\n",
      "loss: 0.178326  [ 3232/56940]\n",
      "loss: 0.215361  [ 6432/56940]\n",
      "loss: 0.284128  [ 9632/56940]\n",
      "loss: 0.256826  [12832/56940]\n",
      "loss: 0.301080  [16032/56940]\n",
      "loss: 0.367902  [19232/56940]\n",
      "loss: 0.229626  [22432/56940]\n",
      "loss: 0.214577  [25632/56940]\n",
      "loss: 0.167324  [28832/56940]\n",
      "loss: 0.279763  [32032/56940]\n",
      "loss: 0.081917  [35232/56940]\n",
      "loss: 0.169388  [38432/56940]\n",
      "loss: 0.136476  [41632/56940]\n",
      "loss: 0.310897  [44832/56940]\n",
      "loss: 0.371982  [48032/56940]\n",
      "loss: 0.327856  [51232/56940]\n",
      "loss: 0.170440  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.217279 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.398622  [   32/56940]\n",
      "loss: 0.283885  [ 3232/56940]\n",
      "loss: 0.276527  [ 6432/56940]\n",
      "loss: 0.230465  [ 9632/56940]\n",
      "loss: 0.394945  [12832/56940]\n",
      "loss: 0.105172  [16032/56940]\n",
      "loss: 0.275073  [19232/56940]\n",
      "loss: 0.166735  [22432/56940]\n",
      "loss: 0.475497  [25632/56940]\n",
      "loss: 0.185092  [28832/56940]\n",
      "loss: 0.231241  [32032/56940]\n",
      "loss: 0.344871  [35232/56940]\n",
      "loss: 0.282469  [38432/56940]\n",
      "loss: 0.586839  [41632/56940]\n",
      "loss: 0.117690  [44832/56940]\n",
      "loss: 0.309684  [48032/56940]\n",
      "loss: 0.203504  [51232/56940]\n",
      "loss: 0.175561  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.219250 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.174542  [   32/56940]\n",
      "loss: 0.219490  [ 3232/56940]\n",
      "loss: 0.202832  [ 6432/56940]\n",
      "loss: 0.300161  [ 9632/56940]\n",
      "loss: 0.202968  [12832/56940]\n",
      "loss: 0.227642  [16032/56940]\n",
      "loss: 0.205136  [19232/56940]\n",
      "loss: 0.142084  [22432/56940]\n",
      "loss: 0.174073  [25632/56940]\n",
      "loss: 0.119283  [28832/56940]\n",
      "loss: 0.266151  [32032/56940]\n",
      "loss: 0.568299  [35232/56940]\n",
      "loss: 0.292845  [38432/56940]\n",
      "loss: 0.186172  [41632/56940]\n",
      "loss: 0.262082  [44832/56940]\n",
      "loss: 0.230577  [48032/56940]\n",
      "loss: 0.302860  [51232/56940]\n",
      "loss: 0.141199  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.211586 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.124154  [   32/56940]\n",
      "loss: 0.242220  [ 3232/56940]\n",
      "loss: 0.376581  [ 6432/56940]\n",
      "loss: 0.187600  [ 9632/56940]\n",
      "loss: 0.140523  [12832/56940]\n",
      "loss: 0.117393  [16032/56940]\n",
      "loss: 0.370003  [19232/56940]\n",
      "loss: 0.221745  [22432/56940]\n",
      "loss: 0.405969  [25632/56940]\n",
      "loss: 0.315856  [28832/56940]\n",
      "loss: 0.157098  [32032/56940]\n",
      "loss: 0.230228  [35232/56940]\n",
      "loss: 0.135255  [38432/56940]\n",
      "loss: 0.239425  [41632/56940]\n",
      "loss: 0.195721  [44832/56940]\n",
      "loss: 0.343455  [48032/56940]\n",
      "loss: 0.189991  [51232/56940]\n",
      "loss: 0.292837  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.215852 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.140423  [   32/56940]\n",
      "loss: 0.138587  [ 3232/56940]\n",
      "loss: 0.186528  [ 6432/56940]\n",
      "loss: 0.191815  [ 9632/56940]\n",
      "loss: 0.201580  [12832/56940]\n",
      "loss: 0.295670  [16032/56940]\n",
      "loss: 0.341771  [19232/56940]\n",
      "loss: 0.657723  [22432/56940]\n",
      "loss: 0.132309  [25632/56940]\n",
      "loss: 0.341256  [28832/56940]\n",
      "loss: 0.216063  [32032/56940]\n",
      "loss: 0.236999  [35232/56940]\n",
      "loss: 0.136329  [38432/56940]\n",
      "loss: 0.082992  [41632/56940]\n",
      "loss: 0.167462  [44832/56940]\n",
      "loss: 0.282651  [48032/56940]\n",
      "loss: 0.220893  [51232/56940]\n",
      "loss: 0.226745  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.235976 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.283137  [   32/56940]\n",
      "loss: 0.263371  [ 3232/56940]\n",
      "loss: 0.201541  [ 6432/56940]\n",
      "loss: 0.110718  [ 9632/56940]\n",
      "loss: 0.307783  [12832/56940]\n",
      "loss: 0.294752  [16032/56940]\n",
      "loss: 0.188093  [19232/56940]\n",
      "loss: 0.202926  [22432/56940]\n",
      "loss: 0.188741  [25632/56940]\n",
      "loss: 0.479332  [28832/56940]\n",
      "loss: 0.264374  [32032/56940]\n",
      "loss: 0.270349  [35232/56940]\n",
      "loss: 0.388178  [38432/56940]\n",
      "loss: 0.281787  [41632/56940]\n",
      "loss: 0.278523  [44832/56940]\n",
      "loss: 0.220046  [48032/56940]\n",
      "loss: 0.147959  [51232/56940]\n",
      "loss: 0.159667  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.209631 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.216462  [   32/56940]\n",
      "loss: 0.319511  [ 3232/56940]\n",
      "loss: 0.191057  [ 6432/56940]\n",
      "loss: 0.224948  [ 9632/56940]\n",
      "loss: 0.215980  [12832/56940]\n",
      "loss: 0.143204  [16032/56940]\n",
      "loss: 0.164173  [19232/56940]\n",
      "loss: 0.210584  [22432/56940]\n",
      "loss: 0.248815  [25632/56940]\n",
      "loss: 0.352061  [28832/56940]\n",
      "loss: 0.259232  [32032/56940]\n",
      "loss: 0.205953  [35232/56940]\n",
      "loss: 0.258592  [38432/56940]\n",
      "loss: 0.217634  [41632/56940]\n",
      "loss: 0.349756  [44832/56940]\n",
      "loss: 0.217095  [48032/56940]\n",
      "loss: 0.155503  [51232/56940]\n",
      "loss: 0.317965  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.233771 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.065111  [   32/56940]\n",
      "loss: 0.462080  [ 3232/56940]\n",
      "loss: 0.377090  [ 6432/56940]\n",
      "loss: 0.229384  [ 9632/56940]\n",
      "loss: 0.109276  [12832/56940]\n",
      "loss: 0.234408  [16032/56940]\n",
      "loss: 0.298333  [19232/56940]\n",
      "loss: 0.106106  [22432/56940]\n",
      "loss: 0.393411  [25632/56940]\n",
      "loss: 0.350963  [28832/56940]\n",
      "loss: 0.049643  [32032/56940]\n",
      "loss: 0.309363  [35232/56940]\n",
      "loss: 0.133808  [38432/56940]\n",
      "loss: 0.431052  [41632/56940]\n",
      "loss: 0.288979  [44832/56940]\n",
      "loss: 0.320417  [48032/56940]\n",
      "loss: 0.265885  [51232/56940]\n",
      "loss: 0.163828  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.217919 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.110644  [   32/56940]\n",
      "loss: 0.103030  [ 3232/56940]\n",
      "loss: 0.268727  [ 6432/56940]\n",
      "loss: 0.166234  [ 9632/56940]\n",
      "loss: 0.281347  [12832/56940]\n",
      "loss: 0.346127  [16032/56940]\n",
      "loss: 0.710503  [19232/56940]\n",
      "loss: 0.465881  [22432/56940]\n",
      "loss: 0.305162  [25632/56940]\n",
      "loss: 0.289251  [28832/56940]\n",
      "loss: 0.193056  [32032/56940]\n",
      "loss: 0.236463  [35232/56940]\n",
      "loss: 0.196954  [38432/56940]\n",
      "loss: 0.349261  [41632/56940]\n",
      "loss: 0.311022  [44832/56940]\n",
      "loss: 0.521839  [48032/56940]\n",
      "loss: 0.309782  [51232/56940]\n",
      "loss: 0.281389  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.205337 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.266010  [   32/56940]\n",
      "loss: 0.349972  [ 3232/56940]\n",
      "loss: 0.134593  [ 6432/56940]\n",
      "loss: 0.203592  [ 9632/56940]\n",
      "loss: 0.377914  [12832/56940]\n",
      "loss: 0.176284  [16032/56940]\n",
      "loss: 0.235774  [19232/56940]\n",
      "loss: 0.095188  [22432/56940]\n",
      "loss: 0.368999  [25632/56940]\n",
      "loss: 0.176232  [28832/56940]\n",
      "loss: 0.300703  [32032/56940]\n",
      "loss: 0.112899  [35232/56940]\n",
      "loss: 0.341229  [38432/56940]\n",
      "loss: 0.122778  [41632/56940]\n",
      "loss: 0.289334  [44832/56940]\n",
      "loss: 0.197656  [48032/56940]\n",
      "loss: 0.214466  [51232/56940]\n",
      "loss: 0.179556  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.212357 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.239412  [   32/56940]\n",
      "loss: 0.308195  [ 3232/56940]\n",
      "loss: 0.344195  [ 6432/56940]\n",
      "loss: 0.221976  [ 9632/56940]\n",
      "loss: 0.205272  [12832/56940]\n",
      "loss: 0.121211  [16032/56940]\n",
      "loss: 0.398011  [19232/56940]\n",
      "loss: 0.279779  [22432/56940]\n",
      "loss: 0.326838  [25632/56940]\n",
      "loss: 0.150072  [28832/56940]\n",
      "loss: 0.238040  [32032/56940]\n",
      "loss: 0.318947  [35232/56940]\n",
      "loss: 0.317457  [38432/56940]\n",
      "loss: 0.106836  [41632/56940]\n",
      "loss: 0.296600  [44832/56940]\n",
      "loss: 0.176501  [48032/56940]\n",
      "loss: 0.260057  [51232/56940]\n",
      "loss: 0.335243  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.215904 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.354130  [   32/56940]\n",
      "loss: 0.276173  [ 3232/56940]\n",
      "loss: 0.247324  [ 6432/56940]\n",
      "loss: 0.275850  [ 9632/56940]\n",
      "loss: 0.251656  [12832/56940]\n",
      "loss: 0.275652  [16032/56940]\n",
      "loss: 0.149862  [19232/56940]\n",
      "loss: 0.239501  [22432/56940]\n",
      "loss: 0.198903  [25632/56940]\n",
      "loss: 0.182319  [28832/56940]\n",
      "loss: 0.098454  [32032/56940]\n",
      "loss: 0.338274  [35232/56940]\n",
      "loss: 0.540153  [38432/56940]\n",
      "loss: 0.096831  [41632/56940]\n",
      "loss: 0.088335  [44832/56940]\n",
      "loss: 0.193814  [48032/56940]\n",
      "loss: 0.258421  [51232/56940]\n",
      "loss: 0.175496  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.211626 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.118022  [   32/56940]\n",
      "loss: 0.252795  [ 3232/56940]\n",
      "loss: 0.256504  [ 6432/56940]\n",
      "loss: 0.238684  [ 9632/56940]\n",
      "loss: 0.169763  [12832/56940]\n",
      "loss: 0.223690  [16032/56940]\n",
      "loss: 0.139250  [19232/56940]\n",
      "loss: 0.409421  [22432/56940]\n",
      "loss: 0.279256  [25632/56940]\n",
      "loss: 0.399151  [28832/56940]\n",
      "loss: 0.435666  [32032/56940]\n",
      "loss: 0.199626  [35232/56940]\n",
      "loss: 0.166218  [38432/56940]\n",
      "loss: 0.241199  [41632/56940]\n",
      "loss: 0.263110  [44832/56940]\n",
      "loss: 0.211316  [48032/56940]\n",
      "loss: 0.300461  [51232/56940]\n",
      "loss: 0.389436  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.221283 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.217755  [   32/56940]\n",
      "loss: 0.145232  [ 3232/56940]\n",
      "loss: 0.330219  [ 6432/56940]\n",
      "loss: 0.295451  [ 9632/56940]\n",
      "loss: 0.329300  [12832/56940]\n",
      "loss: 0.179453  [16032/56940]\n",
      "loss: 0.186910  [19232/56940]\n",
      "loss: 0.244448  [22432/56940]\n",
      "loss: 0.271283  [25632/56940]\n",
      "loss: 0.173203  [28832/56940]\n",
      "loss: 0.131290  [32032/56940]\n",
      "loss: 0.206452  [35232/56940]\n",
      "loss: 0.243710  [38432/56940]\n",
      "loss: 0.197078  [41632/56940]\n",
      "loss: 0.209878  [44832/56940]\n",
      "loss: 0.176499  [48032/56940]\n",
      "loss: 0.065205  [51232/56940]\n",
      "loss: 0.241251  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.226208 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.368990  [   32/56940]\n",
      "loss: 0.241927  [ 3232/56940]\n",
      "loss: 0.262094  [ 6432/56940]\n",
      "loss: 0.320227  [ 9632/56940]\n",
      "loss: 0.355176  [12832/56940]\n",
      "loss: 0.537124  [16032/56940]\n",
      "loss: 0.270163  [19232/56940]\n",
      "loss: 0.300908  [22432/56940]\n",
      "loss: 0.257210  [25632/56940]\n",
      "loss: 0.308883  [28832/56940]\n",
      "loss: 0.190963  [32032/56940]\n",
      "loss: 0.256615  [35232/56940]\n",
      "loss: 0.136481  [38432/56940]\n",
      "loss: 0.209105  [41632/56940]\n",
      "loss: 0.197758  [44832/56940]\n",
      "loss: 0.178192  [48032/56940]\n",
      "loss: 0.168500  [51232/56940]\n",
      "loss: 0.238701  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.208118 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.422463  [   32/56940]\n",
      "loss: 0.314249  [ 3232/56940]\n",
      "loss: 0.146150  [ 6432/56940]\n",
      "loss: 0.219101  [ 9632/56940]\n",
      "loss: 0.182053  [12832/56940]\n",
      "loss: 0.161481  [16032/56940]\n",
      "loss: 0.159510  [19232/56940]\n",
      "loss: 0.468891  [22432/56940]\n",
      "loss: 0.253436  [25632/56940]\n",
      "loss: 0.279404  [28832/56940]\n",
      "loss: 0.205692  [32032/56940]\n",
      "loss: 0.223127  [35232/56940]\n",
      "loss: 0.122442  [38432/56940]\n",
      "loss: 0.151598  [41632/56940]\n",
      "loss: 0.300168  [44832/56940]\n",
      "loss: 0.168742  [48032/56940]\n",
      "loss: 0.197900  [51232/56940]\n",
      "loss: 0.353903  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.231446 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.288102  [   32/56940]\n",
      "loss: 0.198293  [ 3232/56940]\n",
      "loss: 0.224503  [ 6432/56940]\n",
      "loss: 0.288039  [ 9632/56940]\n",
      "loss: 0.287554  [12832/56940]\n",
      "loss: 0.189074  [16032/56940]\n",
      "loss: 0.252907  [19232/56940]\n",
      "loss: 0.176384  [22432/56940]\n",
      "loss: 0.525813  [25632/56940]\n",
      "loss: 0.292856  [28832/56940]\n",
      "loss: 0.166160  [32032/56940]\n",
      "loss: 0.214155  [35232/56940]\n",
      "loss: 0.194153  [38432/56940]\n",
      "loss: 0.589756  [41632/56940]\n",
      "loss: 0.090789  [44832/56940]\n",
      "loss: 0.288913  [48032/56940]\n",
      "loss: 0.219951  [51232/56940]\n",
      "loss: 0.196922  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.220311 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.228082  [   32/56940]\n",
      "loss: 0.216901  [ 3232/56940]\n",
      "loss: 0.230731  [ 6432/56940]\n",
      "loss: 0.217585  [ 9632/56940]\n",
      "loss: 0.207337  [12832/56940]\n",
      "loss: 0.242622  [16032/56940]\n",
      "loss: 0.372028  [19232/56940]\n",
      "loss: 0.297849  [22432/56940]\n",
      "loss: 0.150188  [25632/56940]\n",
      "loss: 0.380717  [28832/56940]\n",
      "loss: 0.312265  [32032/56940]\n",
      "loss: 0.339756  [35232/56940]\n",
      "loss: 0.168639  [38432/56940]\n",
      "loss: 0.323796  [41632/56940]\n",
      "loss: 0.225304  [44832/56940]\n",
      "loss: 0.104024  [48032/56940]\n",
      "loss: 0.148303  [51232/56940]\n",
      "loss: 0.251731  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.219723 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.347666  [   32/56940]\n",
      "loss: 0.263202  [ 3232/56940]\n",
      "loss: 0.123063  [ 6432/56940]\n",
      "loss: 0.457237  [ 9632/56940]\n",
      "loss: 0.121853  [12832/56940]\n",
      "loss: 0.234956  [16032/56940]\n",
      "loss: 0.086620  [19232/56940]\n",
      "loss: 0.294474  [22432/56940]\n",
      "loss: 0.312711  [25632/56940]\n",
      "loss: 0.454051  [28832/56940]\n",
      "loss: 0.195151  [32032/56940]\n",
      "loss: 0.147992  [35232/56940]\n",
      "loss: 0.350893  [38432/56940]\n",
      "loss: 0.109676  [41632/56940]\n",
      "loss: 0.399278  [44832/56940]\n",
      "loss: 0.232522  [48032/56940]\n",
      "loss: 0.094077  [51232/56940]\n",
      "loss: 0.243692  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.206038 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.127918  [   32/56940]\n",
      "loss: 0.274641  [ 3232/56940]\n",
      "loss: 0.269341  [ 6432/56940]\n",
      "loss: 0.382827  [ 9632/56940]\n",
      "loss: 0.325340  [12832/56940]\n",
      "loss: 0.295794  [16032/56940]\n",
      "loss: 0.335959  [19232/56940]\n",
      "loss: 0.354847  [22432/56940]\n",
      "loss: 0.277410  [25632/56940]\n",
      "loss: 0.247490  [28832/56940]\n",
      "loss: 0.416366  [32032/56940]\n",
      "loss: 0.141338  [35232/56940]\n",
      "loss: 0.136187  [38432/56940]\n",
      "loss: 0.230275  [41632/56940]\n",
      "loss: 0.244732  [44832/56940]\n",
      "loss: 0.084743  [48032/56940]\n",
      "loss: 0.209985  [51232/56940]\n",
      "loss: 0.282508  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.209960 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.257729  [   32/56940]\n",
      "loss: 0.198585  [ 3232/56940]\n",
      "loss: 0.269544  [ 6432/56940]\n",
      "loss: 0.129548  [ 9632/56940]\n",
      "loss: 0.285175  [12832/56940]\n",
      "loss: 0.316877  [16032/56940]\n",
      "loss: 0.289771  [19232/56940]\n",
      "loss: 0.380908  [22432/56940]\n",
      "loss: 0.214961  [25632/56940]\n",
      "loss: 0.241394  [28832/56940]\n",
      "loss: 0.346288  [32032/56940]\n",
      "loss: 0.149345  [35232/56940]\n",
      "loss: 0.203995  [38432/56940]\n",
      "loss: 0.410562  [41632/56940]\n",
      "loss: 0.288220  [44832/56940]\n",
      "loss: 0.136430  [48032/56940]\n",
      "loss: 0.370326  [51232/56940]\n",
      "loss: 0.187091  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.212572 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.594996  [   32/56940]\n",
      "loss: 0.101241  [ 3232/56940]\n",
      "loss: 0.246375  [ 6432/56940]\n",
      "loss: 0.329520  [ 9632/56940]\n",
      "loss: 0.214161  [12832/56940]\n",
      "loss: 0.162506  [16032/56940]\n",
      "loss: 0.436264  [19232/56940]\n",
      "loss: 0.274541  [22432/56940]\n",
      "loss: 0.089000  [25632/56940]\n",
      "loss: 0.134338  [28832/56940]\n",
      "loss: 0.252614  [32032/56940]\n",
      "loss: 0.165574  [35232/56940]\n",
      "loss: 0.331821  [38432/56940]\n",
      "loss: 0.456495  [41632/56940]\n",
      "loss: 0.328916  [44832/56940]\n",
      "loss: 0.179589  [48032/56940]\n",
      "loss: 0.425437  [51232/56940]\n",
      "loss: 0.115801  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.211251 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.248044  [   32/56940]\n",
      "loss: 0.185383  [ 3232/56940]\n",
      "loss: 0.148746  [ 6432/56940]\n",
      "loss: 0.385875  [ 9632/56940]\n",
      "loss: 0.290010  [12832/56940]\n",
      "loss: 0.161531  [16032/56940]\n",
      "loss: 0.216953  [19232/56940]\n",
      "loss: 0.294844  [22432/56940]\n",
      "loss: 0.088651  [25632/56940]\n",
      "loss: 0.419753  [28832/56940]\n",
      "loss: 0.245351  [32032/56940]\n",
      "loss: 0.314497  [35232/56940]\n",
      "loss: 0.225155  [38432/56940]\n",
      "loss: 0.226485  [41632/56940]\n",
      "loss: 0.104427  [44832/56940]\n",
      "loss: 0.333571  [48032/56940]\n",
      "loss: 0.197535  [51232/56940]\n",
      "loss: 0.152837  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.208786 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.254083  [   32/56940]\n",
      "loss: 0.259752  [ 3232/56940]\n",
      "loss: 0.274428  [ 6432/56940]\n",
      "loss: 0.286171  [ 9632/56940]\n",
      "loss: 0.191067  [12832/56940]\n",
      "loss: 0.163935  [16032/56940]\n",
      "loss: 0.415210  [19232/56940]\n",
      "loss: 0.132622  [22432/56940]\n",
      "loss: 0.382466  [25632/56940]\n",
      "loss: 0.316709  [28832/56940]\n",
      "loss: 0.169001  [32032/56940]\n",
      "loss: 0.283947  [35232/56940]\n",
      "loss: 0.373010  [38432/56940]\n",
      "loss: 0.152710  [41632/56940]\n",
      "loss: 0.294473  [44832/56940]\n",
      "loss: 0.228693  [48032/56940]\n",
      "loss: 0.258081  [51232/56940]\n",
      "loss: 0.158797  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.209474 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.322444  [   32/56940]\n",
      "loss: 0.143220  [ 3232/56940]\n",
      "loss: 0.241479  [ 6432/56940]\n",
      "loss: 0.157127  [ 9632/56940]\n",
      "loss: 0.322524  [12832/56940]\n",
      "loss: 0.252241  [16032/56940]\n",
      "loss: 0.353788  [19232/56940]\n",
      "loss: 0.328579  [22432/56940]\n",
      "loss: 0.262898  [25632/56940]\n",
      "loss: 0.195721  [28832/56940]\n",
      "loss: 0.335920  [32032/56940]\n",
      "loss: 0.298710  [35232/56940]\n",
      "loss: 0.273104  [38432/56940]\n",
      "loss: 0.272802  [41632/56940]\n",
      "loss: 0.389129  [44832/56940]\n",
      "loss: 0.224452  [48032/56940]\n",
      "loss: 0.624666  [51232/56940]\n",
      "loss: 0.160154  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.208950 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.349102  [   32/56940]\n",
      "loss: 0.134773  [ 3232/56940]\n",
      "loss: 0.444833  [ 6432/56940]\n",
      "loss: 0.312975  [ 9632/56940]\n",
      "loss: 0.236907  [12832/56940]\n",
      "loss: 0.297520  [16032/56940]\n",
      "loss: 0.353562  [19232/56940]\n",
      "loss: 0.267291  [22432/56940]\n",
      "loss: 0.214862  [25632/56940]\n",
      "loss: 0.247708  [28832/56940]\n",
      "loss: 0.169389  [32032/56940]\n",
      "loss: 0.291998  [35232/56940]\n",
      "loss: 0.223966  [38432/56940]\n",
      "loss: 0.351425  [41632/56940]\n",
      "loss: 0.377775  [44832/56940]\n",
      "loss: 0.109409  [48032/56940]\n",
      "loss: 0.355159  [51232/56940]\n",
      "loss: 0.165799  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.208926 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.229699  [   32/56940]\n",
      "loss: 0.118812  [ 3232/56940]\n",
      "loss: 0.302627  [ 6432/56940]\n",
      "loss: 0.063594  [ 9632/56940]\n",
      "loss: 0.170028  [12832/56940]\n",
      "loss: 0.116714  [16032/56940]\n",
      "loss: 0.225756  [19232/56940]\n",
      "loss: 0.246048  [22432/56940]\n",
      "loss: 0.190908  [25632/56940]\n",
      "loss: 0.331554  [28832/56940]\n",
      "loss: 0.525568  [32032/56940]\n",
      "loss: 0.289908  [35232/56940]\n",
      "loss: 0.144327  [38432/56940]\n",
      "loss: 0.192773  [41632/56940]\n",
      "loss: 0.431651  [44832/56940]\n",
      "loss: 0.187126  [48032/56940]\n",
      "loss: 0.288308  [51232/56940]\n",
      "loss: 0.237261  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.227837 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.110842  [   32/56940]\n",
      "loss: 0.333192  [ 3232/56940]\n",
      "loss: 0.320739  [ 6432/56940]\n",
      "loss: 0.284119  [ 9632/56940]\n",
      "loss: 0.197324  [12832/56940]\n",
      "loss: 0.181179  [16032/56940]\n",
      "loss: 0.212292  [19232/56940]\n",
      "loss: 0.252458  [22432/56940]\n",
      "loss: 0.369330  [25632/56940]\n",
      "loss: 0.282357  [28832/56940]\n",
      "loss: 0.233513  [32032/56940]\n",
      "loss: 0.375726  [35232/56940]\n",
      "loss: 0.438590  [38432/56940]\n",
      "loss: 0.260740  [41632/56940]\n",
      "loss: 0.253658  [44832/56940]\n",
      "loss: 0.216969  [48032/56940]\n",
      "loss: 0.438095  [51232/56940]\n",
      "loss: 0.092959  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.205007 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.138599  [   32/56940]\n",
      "loss: 0.141649  [ 3232/56940]\n",
      "loss: 0.332459  [ 6432/56940]\n",
      "loss: 0.264885  [ 9632/56940]\n",
      "loss: 0.397766  [12832/56940]\n",
      "loss: 0.380675  [16032/56940]\n",
      "loss: 0.213392  [19232/56940]\n",
      "loss: 0.229237  [22432/56940]\n",
      "loss: 0.552869  [25632/56940]\n",
      "loss: 0.234910  [28832/56940]\n",
      "loss: 0.332245  [32032/56940]\n",
      "loss: 0.144540  [35232/56940]\n",
      "loss: 0.111226  [38432/56940]\n",
      "loss: 0.263445  [41632/56940]\n",
      "loss: 0.172325  [44832/56940]\n",
      "loss: 0.243246  [48032/56940]\n",
      "loss: 0.126638  [51232/56940]\n",
      "loss: 0.320806  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.238591 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.114452  [   32/56940]\n",
      "loss: 0.204973  [ 3232/56940]\n",
      "loss: 0.300056  [ 6432/56940]\n",
      "loss: 0.252660  [ 9632/56940]\n",
      "loss: 0.165858  [12832/56940]\n",
      "loss: 0.179873  [16032/56940]\n",
      "loss: 0.150883  [19232/56940]\n",
      "loss: 0.177234  [22432/56940]\n",
      "loss: 0.122465  [25632/56940]\n",
      "loss: 0.320213  [28832/56940]\n",
      "loss: 0.423555  [32032/56940]\n",
      "loss: 0.198124  [35232/56940]\n",
      "loss: 0.339669  [38432/56940]\n",
      "loss: 0.639487  [41632/56940]\n",
      "loss: 0.087276  [44832/56940]\n",
      "loss: 0.293884  [48032/56940]\n",
      "loss: 0.123550  [51232/56940]\n",
      "loss: 0.234994  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.213057 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.215178  [   32/56940]\n",
      "loss: 0.230925  [ 3232/56940]\n",
      "loss: 0.264163  [ 6432/56940]\n",
      "loss: 0.250090  [ 9632/56940]\n",
      "loss: 0.137165  [12832/56940]\n",
      "loss: 0.310190  [16032/56940]\n",
      "loss: 0.199273  [19232/56940]\n",
      "loss: 0.334472  [22432/56940]\n",
      "loss: 0.537178  [25632/56940]\n",
      "loss: 0.150452  [28832/56940]\n",
      "loss: 0.577852  [32032/56940]\n",
      "loss: 0.348237  [35232/56940]\n",
      "loss: 0.184381  [38432/56940]\n",
      "loss: 0.227321  [41632/56940]\n",
      "loss: 0.270032  [44832/56940]\n",
      "loss: 0.259060  [48032/56940]\n",
      "loss: 0.443702  [51232/56940]\n",
      "loss: 0.162985  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.210288 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.158668  [   32/56940]\n",
      "loss: 0.233620  [ 3232/56940]\n",
      "loss: 0.187736  [ 6432/56940]\n",
      "loss: 0.166228  [ 9632/56940]\n",
      "loss: 0.258115  [12832/56940]\n",
      "loss: 0.209859  [16032/56940]\n",
      "loss: 0.409527  [19232/56940]\n",
      "loss: 0.570096  [22432/56940]\n",
      "loss: 0.214927  [25632/56940]\n",
      "loss: 0.169265  [28832/56940]\n",
      "loss: 0.327435  [32032/56940]\n",
      "loss: 0.118193  [35232/56940]\n",
      "loss: 0.254244  [38432/56940]\n",
      "loss: 0.340046  [41632/56940]\n",
      "loss: 0.266020  [44832/56940]\n",
      "loss: 0.200878  [48032/56940]\n",
      "loss: 0.439586  [51232/56940]\n",
      "loss: 0.242180  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.221672 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.195414  [   32/56940]\n",
      "loss: 0.169930  [ 3232/56940]\n",
      "loss: 0.236877  [ 6432/56940]\n",
      "loss: 0.291719  [ 9632/56940]\n",
      "loss: 0.209671  [12832/56940]\n",
      "loss: 0.284300  [16032/56940]\n",
      "loss: 0.293635  [19232/56940]\n",
      "loss: 0.144897  [22432/56940]\n",
      "loss: 0.331858  [25632/56940]\n",
      "loss: 0.187906  [28832/56940]\n",
      "loss: 0.278661  [32032/56940]\n",
      "loss: 0.291968  [35232/56940]\n",
      "loss: 0.266221  [38432/56940]\n",
      "loss: 0.072202  [41632/56940]\n",
      "loss: 0.094243  [44832/56940]\n",
      "loss: 0.139871  [48032/56940]\n",
      "loss: 0.133109  [51232/56940]\n",
      "loss: 0.141891  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.204269 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.100363  [   32/56940]\n",
      "loss: 0.370632  [ 3232/56940]\n",
      "loss: 0.240766  [ 6432/56940]\n",
      "loss: 0.271021  [ 9632/56940]\n",
      "loss: 0.149333  [12832/56940]\n",
      "loss: 0.435955  [16032/56940]\n",
      "loss: 0.174487  [19232/56940]\n",
      "loss: 0.280331  [22432/56940]\n",
      "loss: 0.596082  [25632/56940]\n",
      "loss: 0.073154  [28832/56940]\n",
      "loss: 0.264357  [32032/56940]\n",
      "loss: 0.165520  [35232/56940]\n",
      "loss: 0.199244  [38432/56940]\n",
      "loss: 0.171266  [41632/56940]\n",
      "loss: 0.433756  [44832/56940]\n",
      "loss: 0.344824  [48032/56940]\n",
      "loss: 0.298240  [51232/56940]\n",
      "loss: 0.402457  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.210103 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.142090  [   32/56940]\n",
      "loss: 0.087341  [ 3232/56940]\n",
      "loss: 0.187115  [ 6432/56940]\n",
      "loss: 0.087916  [ 9632/56940]\n",
      "loss: 0.223645  [12832/56940]\n",
      "loss: 0.428703  [16032/56940]\n",
      "loss: 0.291967  [19232/56940]\n",
      "loss: 0.255297  [22432/56940]\n",
      "loss: 0.172125  [25632/56940]\n",
      "loss: 0.170164  [28832/56940]\n",
      "loss: 0.163755  [32032/56940]\n",
      "loss: 0.393298  [35232/56940]\n",
      "loss: 0.247776  [38432/56940]\n",
      "loss: 0.281382  [41632/56940]\n",
      "loss: 0.443361  [44832/56940]\n",
      "loss: 0.154736  [48032/56940]\n",
      "loss: 0.152250  [51232/56940]\n",
      "loss: 0.331321  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.201954 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.172217  [   32/56940]\n",
      "loss: 0.271696  [ 3232/56940]\n",
      "loss: 0.147827  [ 6432/56940]\n",
      "loss: 0.245311  [ 9632/56940]\n",
      "loss: 0.319618  [12832/56940]\n",
      "loss: 0.225479  [16032/56940]\n",
      "loss: 0.088277  [19232/56940]\n",
      "loss: 0.165754  [22432/56940]\n",
      "loss: 0.387844  [25632/56940]\n",
      "loss: 0.423813  [28832/56940]\n",
      "loss: 0.228262  [32032/56940]\n",
      "loss: 0.195730  [35232/56940]\n",
      "loss: 0.067846  [38432/56940]\n",
      "loss: 0.244354  [41632/56940]\n",
      "loss: 0.276292  [44832/56940]\n",
      "loss: 0.279750  [48032/56940]\n",
      "loss: 0.126137  [51232/56940]\n",
      "loss: 0.243960  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.202934 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.301686  [   32/56940]\n",
      "loss: 0.377141  [ 3232/56940]\n",
      "loss: 0.189349  [ 6432/56940]\n",
      "loss: 0.535705  [ 9632/56940]\n",
      "loss: 0.091082  [12832/56940]\n",
      "loss: 0.194315  [16032/56940]\n",
      "loss: 0.134105  [19232/56940]\n",
      "loss: 0.181139  [22432/56940]\n",
      "loss: 0.116119  [25632/56940]\n",
      "loss: 0.328264  [28832/56940]\n",
      "loss: 0.135027  [32032/56940]\n",
      "loss: 0.300076  [35232/56940]\n",
      "loss: 0.138504  [38432/56940]\n",
      "loss: 0.203779  [41632/56940]\n",
      "loss: 0.130162  [44832/56940]\n",
      "loss: 0.196079  [48032/56940]\n",
      "loss: 0.605010  [51232/56940]\n",
      "loss: 0.353242  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.226483 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.486857  [   32/56940]\n",
      "loss: 0.337996  [ 3232/56940]\n",
      "loss: 0.332576  [ 6432/56940]\n",
      "loss: 0.188906  [ 9632/56940]\n",
      "loss: 0.205879  [12832/56940]\n",
      "loss: 0.339478  [16032/56940]\n",
      "loss: 0.280157  [19232/56940]\n",
      "loss: 0.337379  [22432/56940]\n",
      "loss: 0.157656  [25632/56940]\n",
      "loss: 0.157001  [28832/56940]\n",
      "loss: 0.178709  [32032/56940]\n",
      "loss: 0.067261  [35232/56940]\n",
      "loss: 0.152813  [38432/56940]\n",
      "loss: 0.352829  [41632/56940]\n",
      "loss: 0.591640  [44832/56940]\n",
      "loss: 0.231691  [48032/56940]\n",
      "loss: 0.117066  [51232/56940]\n",
      "loss: 0.270438  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.223369 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.193667  [   32/56940]\n",
      "loss: 0.239054  [ 3232/56940]\n",
      "loss: 0.129161  [ 6432/56940]\n",
      "loss: 0.233542  [ 9632/56940]\n",
      "loss: 0.135018  [12832/56940]\n",
      "loss: 0.124443  [16032/56940]\n",
      "loss: 0.310429  [19232/56940]\n",
      "loss: 0.241883  [22432/56940]\n",
      "loss: 0.050834  [25632/56940]\n",
      "loss: 0.391255  [28832/56940]\n",
      "loss: 0.192618  [32032/56940]\n",
      "loss: 0.256222  [35232/56940]\n",
      "loss: 0.173904  [38432/56940]\n",
      "loss: 0.222521  [41632/56940]\n",
      "loss: 0.309391  [44832/56940]\n",
      "loss: 0.126707  [48032/56940]\n",
      "loss: 0.184800  [51232/56940]\n",
      "loss: 0.202563  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.241095 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.332530  [   32/56940]\n",
      "loss: 0.338420  [ 3232/56940]\n",
      "loss: 0.288089  [ 6432/56940]\n",
      "loss: 0.241624  [ 9632/56940]\n",
      "loss: 0.157166  [12832/56940]\n",
      "loss: 0.124251  [16032/56940]\n",
      "loss: 0.238777  [19232/56940]\n",
      "loss: 0.057570  [22432/56940]\n",
      "loss: 0.310150  [25632/56940]\n",
      "loss: 0.297057  [28832/56940]\n",
      "loss: 0.128778  [32032/56940]\n",
      "loss: 0.210134  [35232/56940]\n",
      "loss: 0.388749  [38432/56940]\n",
      "loss: 0.182302  [41632/56940]\n",
      "loss: 0.266796  [44832/56940]\n",
      "loss: 0.128099  [48032/56940]\n",
      "loss: 0.420462  [51232/56940]\n",
      "loss: 0.210826  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.210088 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.283147  [   32/56940]\n",
      "loss: 0.245387  [ 3232/56940]\n",
      "loss: 0.177609  [ 6432/56940]\n",
      "loss: 0.132825  [ 9632/56940]\n",
      "loss: 0.470578  [12832/56940]\n",
      "loss: 0.204643  [16032/56940]\n",
      "loss: 0.158739  [19232/56940]\n",
      "loss: 0.278567  [22432/56940]\n",
      "loss: 0.153951  [25632/56940]\n",
      "loss: 0.154612  [28832/56940]\n",
      "loss: 0.284498  [32032/56940]\n",
      "loss: 0.168992  [35232/56940]\n",
      "loss: 0.317381  [38432/56940]\n",
      "loss: 0.483490  [41632/56940]\n",
      "loss: 0.227306  [44832/56940]\n",
      "loss: 0.411671  [48032/56940]\n",
      "loss: 0.145313  [51232/56940]\n",
      "loss: 0.302957  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.209173 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.258349  [   32/56940]\n",
      "loss: 0.150749  [ 3232/56940]\n",
      "loss: 0.249149  [ 6432/56940]\n",
      "loss: 0.234118  [ 9632/56940]\n",
      "loss: 0.353803  [12832/56940]\n",
      "loss: 0.284750  [16032/56940]\n",
      "loss: 0.176708  [19232/56940]\n",
      "loss: 0.205226  [22432/56940]\n",
      "loss: 0.197380  [25632/56940]\n",
      "loss: 0.213086  [28832/56940]\n",
      "loss: 0.144371  [32032/56940]\n",
      "loss: 0.249961  [35232/56940]\n",
      "loss: 0.253025  [38432/56940]\n",
      "loss: 0.172412  [41632/56940]\n",
      "loss: 0.226741  [44832/56940]\n",
      "loss: 0.349930  [48032/56940]\n",
      "loss: 0.297281  [51232/56940]\n",
      "loss: 0.126207  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.202140 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.234599  [   32/56940]\n",
      "loss: 0.135252  [ 3232/56940]\n",
      "loss: 0.193615  [ 6432/56940]\n",
      "loss: 0.189844  [ 9632/56940]\n",
      "loss: 0.167278  [12832/56940]\n",
      "loss: 0.130096  [16032/56940]\n",
      "loss: 0.214287  [19232/56940]\n",
      "loss: 0.218010  [22432/56940]\n",
      "loss: 0.561891  [25632/56940]\n",
      "loss: 0.212032  [28832/56940]\n",
      "loss: 0.170012  [32032/56940]\n",
      "loss: 0.170187  [35232/56940]\n",
      "loss: 0.371980  [38432/56940]\n",
      "loss: 0.094329  [41632/56940]\n",
      "loss: 0.222636  [44832/56940]\n",
      "loss: 0.232944  [48032/56940]\n",
      "loss: 0.318270  [51232/56940]\n",
      "loss: 0.196291  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.201292 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.296559  [   32/56940]\n",
      "loss: 0.126559  [ 3232/56940]\n",
      "loss: 0.369659  [ 6432/56940]\n",
      "loss: 0.253288  [ 9632/56940]\n",
      "loss: 0.187417  [12832/56940]\n",
      "loss: 0.314637  [16032/56940]\n",
      "loss: 0.210585  [19232/56940]\n",
      "loss: 0.258128  [22432/56940]\n",
      "loss: 0.255111  [25632/56940]\n",
      "loss: 0.276275  [28832/56940]\n",
      "loss: 0.314019  [32032/56940]\n",
      "loss: 0.141793  [35232/56940]\n",
      "loss: 0.168909  [38432/56940]\n",
      "loss: 0.379758  [41632/56940]\n",
      "loss: 0.230087  [44832/56940]\n",
      "loss: 0.258816  [48032/56940]\n",
      "loss: 0.238723  [51232/56940]\n",
      "loss: 0.270672  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.210379 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.192552  [   32/56940]\n",
      "loss: 0.246089  [ 3232/56940]\n",
      "loss: 0.187125  [ 6432/56940]\n",
      "loss: 0.274672  [ 9632/56940]\n",
      "loss: 0.327696  [12832/56940]\n",
      "loss: 0.208608  [16032/56940]\n",
      "loss: 0.519104  [19232/56940]\n",
      "loss: 0.606174  [22432/56940]\n",
      "loss: 0.169215  [25632/56940]\n",
      "loss: 0.323015  [28832/56940]\n",
      "loss: 0.211540  [32032/56940]\n",
      "loss: 0.171616  [35232/56940]\n",
      "loss: 0.197241  [38432/56940]\n",
      "loss: 0.159012  [41632/56940]\n",
      "loss: 0.294363  [44832/56940]\n",
      "loss: 0.147988  [48032/56940]\n",
      "loss: 0.170129  [51232/56940]\n",
      "loss: 0.139432  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.207413 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.231101  [   32/56940]\n",
      "loss: 0.380306  [ 3232/56940]\n",
      "loss: 0.246967  [ 6432/56940]\n",
      "loss: 0.064705  [ 9632/56940]\n",
      "loss: 0.150983  [12832/56940]\n",
      "loss: 0.164282  [16032/56940]\n",
      "loss: 0.252609  [19232/56940]\n",
      "loss: 0.405737  [22432/56940]\n",
      "loss: 0.316415  [25632/56940]\n",
      "loss: 0.309004  [28832/56940]\n",
      "loss: 0.437013  [32032/56940]\n",
      "loss: 0.169167  [35232/56940]\n",
      "loss: 0.153256  [38432/56940]\n",
      "loss: 0.315147  [41632/56940]\n",
      "loss: 0.260181  [44832/56940]\n",
      "loss: 0.202617  [48032/56940]\n",
      "loss: 0.223308  [51232/56940]\n",
      "loss: 0.098444  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.226681 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.454172  [   32/56940]\n",
      "loss: 0.316344  [ 3232/56940]\n",
      "loss: 0.304715  [ 6432/56940]\n",
      "loss: 0.112970  [ 9632/56940]\n",
      "loss: 0.351174  [12832/56940]\n",
      "loss: 0.329453  [16032/56940]\n",
      "loss: 0.123753  [19232/56940]\n",
      "loss: 0.170222  [22432/56940]\n",
      "loss: 0.180985  [25632/56940]\n",
      "loss: 0.071017  [28832/56940]\n",
      "loss: 0.118774  [32032/56940]\n",
      "loss: 0.197318  [35232/56940]\n",
      "loss: 0.194275  [38432/56940]\n",
      "loss: 0.328553  [41632/56940]\n",
      "loss: 0.343518  [44832/56940]\n",
      "loss: 0.233868  [48032/56940]\n",
      "loss: 0.147163  [51232/56940]\n",
      "loss: 0.199537  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.207424 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.191671  [   32/56940]\n",
      "loss: 0.317729  [ 3232/56940]\n",
      "loss: 0.489813  [ 6432/56940]\n",
      "loss: 0.154455  [ 9632/56940]\n",
      "loss: 0.242507  [12832/56940]\n",
      "loss: 0.151031  [16032/56940]\n",
      "loss: 0.132166  [19232/56940]\n",
      "loss: 0.256085  [22432/56940]\n",
      "loss: 0.246870  [25632/56940]\n",
      "loss: 0.235907  [28832/56940]\n",
      "loss: 0.356745  [32032/56940]\n",
      "loss: 0.090521  [35232/56940]\n",
      "loss: 0.129562  [38432/56940]\n",
      "loss: 0.191705  [41632/56940]\n",
      "loss: 0.239466  [44832/56940]\n",
      "loss: 0.369454  [48032/56940]\n",
      "loss: 0.569042  [51232/56940]\n",
      "loss: 0.474452  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.210026 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.290865  [   32/56940]\n",
      "loss: 0.203893  [ 3232/56940]\n",
      "loss: 0.165901  [ 6432/56940]\n",
      "loss: 0.208320  [ 9632/56940]\n",
      "loss: 0.493823  [12832/56940]\n",
      "loss: 0.128262  [16032/56940]\n",
      "loss: 0.209374  [19232/56940]\n",
      "loss: 0.293076  [22432/56940]\n",
      "loss: 0.247106  [25632/56940]\n",
      "loss: 0.275938  [28832/56940]\n",
      "loss: 0.243300  [32032/56940]\n",
      "loss: 0.268726  [35232/56940]\n",
      "loss: 0.284129  [38432/56940]\n",
      "loss: 0.138863  [41632/56940]\n",
      "loss: 0.318827  [44832/56940]\n",
      "loss: 0.171510  [48032/56940]\n",
      "loss: 0.229788  [51232/56940]\n",
      "loss: 0.149211  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.205156 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.253886  [   32/56940]\n",
      "loss: 0.242998  [ 3232/56940]\n",
      "loss: 0.642351  [ 6432/56940]\n",
      "loss: 0.290365  [ 9632/56940]\n",
      "loss: 0.209776  [12832/56940]\n",
      "loss: 0.284129  [16032/56940]\n",
      "loss: 0.357688  [19232/56940]\n",
      "loss: 0.118942  [22432/56940]\n",
      "loss: 0.150057  [25632/56940]\n",
      "loss: 0.278128  [28832/56940]\n",
      "loss: 0.135039  [32032/56940]\n",
      "loss: 0.166089  [35232/56940]\n",
      "loss: 0.192772  [38432/56940]\n",
      "loss: 0.317126  [41632/56940]\n",
      "loss: 0.175490  [44832/56940]\n",
      "loss: 0.221884  [48032/56940]\n",
      "loss: 0.310615  [51232/56940]\n",
      "loss: 0.275449  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.203955 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.265729  [   32/56940]\n",
      "loss: 0.201015  [ 3232/56940]\n",
      "loss: 0.521474  [ 6432/56940]\n",
      "loss: 0.167632  [ 9632/56940]\n",
      "loss: 0.198443  [12832/56940]\n",
      "loss: 0.104063  [16032/56940]\n",
      "loss: 0.276582  [19232/56940]\n",
      "loss: 0.327095  [22432/56940]\n",
      "loss: 0.398027  [25632/56940]\n",
      "loss: 0.335516  [28832/56940]\n",
      "loss: 0.251985  [32032/56940]\n",
      "loss: 0.433507  [35232/56940]\n",
      "loss: 0.131003  [38432/56940]\n",
      "loss: 0.180865  [41632/56940]\n",
      "loss: 0.175322  [44832/56940]\n",
      "loss: 0.331253  [48032/56940]\n",
      "loss: 0.290329  [51232/56940]\n",
      "loss: 0.151927  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.220321 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.118715  [   32/56940]\n",
      "loss: 0.216469  [ 3232/56940]\n",
      "loss: 0.207675  [ 6432/56940]\n",
      "loss: 0.321966  [ 9632/56940]\n",
      "loss: 0.147254  [12832/56940]\n",
      "loss: 0.361870  [16032/56940]\n",
      "loss: 0.198572  [19232/56940]\n",
      "loss: 0.153533  [22432/56940]\n",
      "loss: 0.145760  [25632/56940]\n",
      "loss: 0.323278  [28832/56940]\n",
      "loss: 0.291886  [32032/56940]\n",
      "loss: 0.356429  [35232/56940]\n",
      "loss: 0.151410  [38432/56940]\n",
      "loss: 0.272621  [41632/56940]\n",
      "loss: 0.255707  [44832/56940]\n",
      "loss: 0.147895  [48032/56940]\n",
      "loss: 0.331478  [51232/56940]\n",
      "loss: 0.206246  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.266516 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.222836  [   32/56940]\n",
      "loss: 0.173405  [ 3232/56940]\n",
      "loss: 0.168988  [ 6432/56940]\n",
      "loss: 0.231915  [ 9632/56940]\n",
      "loss: 0.225044  [12832/56940]\n",
      "loss: 0.109874  [16032/56940]\n",
      "loss: 0.094953  [19232/56940]\n",
      "loss: 0.127433  [22432/56940]\n",
      "loss: 0.389260  [25632/56940]\n",
      "loss: 0.390286  [28832/56940]\n",
      "loss: 0.147695  [32032/56940]\n",
      "loss: 0.214084  [35232/56940]\n",
      "loss: 0.140962  [38432/56940]\n",
      "loss: 0.447989  [41632/56940]\n",
      "loss: 0.393304  [44832/56940]\n",
      "loss: 0.172487  [48032/56940]\n",
      "loss: 0.228631  [51232/56940]\n",
      "loss: 0.182216  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.202989 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.144294  [   32/56940]\n",
      "loss: 0.151771  [ 3232/56940]\n",
      "loss: 0.221395  [ 6432/56940]\n",
      "loss: 0.106505  [ 9632/56940]\n",
      "loss: 0.145502  [12832/56940]\n",
      "loss: 0.141737  [16032/56940]\n",
      "loss: 0.325343  [19232/56940]\n",
      "loss: 0.370238  [22432/56940]\n",
      "loss: 0.485648  [25632/56940]\n",
      "loss: 0.155075  [28832/56940]\n",
      "loss: 0.093340  [32032/56940]\n",
      "loss: 0.348135  [35232/56940]\n",
      "loss: 0.474627  [38432/56940]\n",
      "loss: 0.226650  [41632/56940]\n",
      "loss: 0.298247  [44832/56940]\n",
      "loss: 0.607009  [48032/56940]\n",
      "loss: 0.083761  [51232/56940]\n",
      "loss: 0.310458  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.204785 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.462673  [   32/56940]\n",
      "loss: 0.411791  [ 3232/56940]\n",
      "loss: 0.202000  [ 6432/56940]\n",
      "loss: 0.218131  [ 9632/56940]\n",
      "loss: 0.402365  [12832/56940]\n",
      "loss: 0.545202  [16032/56940]\n",
      "loss: 0.323946  [19232/56940]\n",
      "loss: 0.219166  [22432/56940]\n",
      "loss: 0.313679  [25632/56940]\n",
      "loss: 0.344901  [28832/56940]\n",
      "loss: 0.346733  [32032/56940]\n",
      "loss: 0.350486  [35232/56940]\n",
      "loss: 0.170892  [38432/56940]\n",
      "loss: 0.261396  [41632/56940]\n",
      "loss: 0.206521  [44832/56940]\n",
      "loss: 0.129458  [48032/56940]\n",
      "loss: 0.149663  [51232/56940]\n",
      "loss: 0.332150  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.218648 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.108085  [   32/56940]\n",
      "loss: 0.242051  [ 3232/56940]\n",
      "loss: 0.221136  [ 6432/56940]\n",
      "loss: 0.114353  [ 9632/56940]\n",
      "loss: 0.334721  [12832/56940]\n",
      "loss: 0.194757  [16032/56940]\n",
      "loss: 0.228787  [19232/56940]\n",
      "loss: 0.138936  [22432/56940]\n",
      "loss: 0.277633  [25632/56940]\n",
      "loss: 0.268798  [28832/56940]\n",
      "loss: 0.178637  [32032/56940]\n",
      "loss: 0.122534  [35232/56940]\n",
      "loss: 0.428739  [38432/56940]\n",
      "loss: 0.222905  [41632/56940]\n",
      "loss: 0.387136  [44832/56940]\n",
      "loss: 0.196712  [48032/56940]\n",
      "loss: 0.609975  [51232/56940]\n",
      "loss: 0.165946  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.205339 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.249995  [   32/56940]\n",
      "loss: 0.255779  [ 3232/56940]\n",
      "loss: 0.273047  [ 6432/56940]\n",
      "loss: 0.473209  [ 9632/56940]\n",
      "loss: 0.488545  [12832/56940]\n",
      "loss: 0.117809  [16032/56940]\n",
      "loss: 0.116908  [19232/56940]\n",
      "loss: 0.242066  [22432/56940]\n",
      "loss: 0.310175  [25632/56940]\n",
      "loss: 0.135413  [28832/56940]\n",
      "loss: 0.137367  [32032/56940]\n",
      "loss: 0.507448  [35232/56940]\n",
      "loss: 0.120189  [38432/56940]\n",
      "loss: 0.217696  [41632/56940]\n",
      "loss: 0.572380  [44832/56940]\n",
      "loss: 0.304102  [48032/56940]\n",
      "loss: 0.208519  [51232/56940]\n",
      "loss: 0.320734  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.217985 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.174725  [   32/56940]\n",
      "loss: 0.437360  [ 3232/56940]\n",
      "loss: 0.420538  [ 6432/56940]\n",
      "loss: 0.385297  [ 9632/56940]\n",
      "loss: 0.167841  [12832/56940]\n",
      "loss: 0.202235  [16032/56940]\n",
      "loss: 0.128728  [19232/56940]\n",
      "loss: 0.623905  [22432/56940]\n",
      "loss: 0.236607  [25632/56940]\n",
      "loss: 0.195104  [28832/56940]\n",
      "loss: 0.237960  [32032/56940]\n",
      "loss: 0.214143  [35232/56940]\n",
      "loss: 0.178709  [38432/56940]\n",
      "loss: 0.226840  [41632/56940]\n",
      "loss: 0.106716  [44832/56940]\n",
      "loss: 0.096813  [48032/56940]\n",
      "loss: 0.255715  [51232/56940]\n",
      "loss: 0.171378  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.203235 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.262314  [   32/56940]\n",
      "loss: 0.205021  [ 3232/56940]\n",
      "loss: 0.168529  [ 6432/56940]\n",
      "loss: 0.318998  [ 9632/56940]\n",
      "loss: 0.245266  [12832/56940]\n",
      "loss: 0.171831  [16032/56940]\n",
      "loss: 0.225964  [19232/56940]\n",
      "loss: 0.172696  [22432/56940]\n",
      "loss: 0.160546  [25632/56940]\n",
      "loss: 0.155046  [28832/56940]\n",
      "loss: 0.616087  [32032/56940]\n",
      "loss: 0.225283  [35232/56940]\n",
      "loss: 0.111943  [38432/56940]\n",
      "loss: 0.304663  [41632/56940]\n",
      "loss: 0.386021  [44832/56940]\n",
      "loss: 0.267231  [48032/56940]\n",
      "loss: 0.245327  [51232/56940]\n",
      "loss: 0.189083  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.217967 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.111941  [   32/56940]\n",
      "loss: 0.280530  [ 3232/56940]\n",
      "loss: 0.345678  [ 6432/56940]\n",
      "loss: 0.401749  [ 9632/56940]\n",
      "loss: 0.142524  [12832/56940]\n",
      "loss: 0.339354  [16032/56940]\n",
      "loss: 0.309592  [19232/56940]\n",
      "loss: 0.200038  [22432/56940]\n",
      "loss: 0.208256  [25632/56940]\n",
      "loss: 0.170131  [28832/56940]\n",
      "loss: 0.486899  [32032/56940]\n",
      "loss: 0.297012  [35232/56940]\n",
      "loss: 0.252027  [38432/56940]\n",
      "loss: 0.185553  [41632/56940]\n",
      "loss: 0.305894  [44832/56940]\n",
      "loss: 0.111619  [48032/56940]\n",
      "loss: 0.174128  [51232/56940]\n",
      "loss: 0.207272  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.212932 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.132997  [   32/56940]\n",
      "loss: 0.311198  [ 3232/56940]\n",
      "loss: 0.358444  [ 6432/56940]\n",
      "loss: 0.228536  [ 9632/56940]\n",
      "loss: 0.444342  [12832/56940]\n",
      "loss: 0.135420  [16032/56940]\n",
      "loss: 0.274469  [19232/56940]\n",
      "loss: 0.324225  [22432/56940]\n",
      "loss: 0.294162  [25632/56940]\n",
      "loss: 0.226986  [28832/56940]\n",
      "loss: 0.183103  [32032/56940]\n",
      "loss: 0.231938  [35232/56940]\n",
      "loss: 0.239275  [38432/56940]\n",
      "loss: 0.159984  [41632/56940]\n",
      "loss: 0.235040  [44832/56940]\n",
      "loss: 0.188290  [48032/56940]\n",
      "loss: 0.177415  [51232/56940]\n",
      "loss: 0.172221  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.224388 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.050374  [   32/56940]\n",
      "loss: 0.281132  [ 3232/56940]\n",
      "loss: 0.375759  [ 6432/56940]\n",
      "loss: 0.135053  [ 9632/56940]\n",
      "loss: 0.264353  [12832/56940]\n",
      "loss: 0.167555  [16032/56940]\n",
      "loss: 0.506031  [19232/56940]\n",
      "loss: 0.408774  [22432/56940]\n",
      "loss: 0.252672  [25632/56940]\n",
      "loss: 0.212603  [28832/56940]\n",
      "loss: 0.155252  [32032/56940]\n",
      "loss: 0.312868  [35232/56940]\n",
      "loss: 0.210439  [38432/56940]\n",
      "loss: 0.267184  [41632/56940]\n",
      "loss: 0.195421  [44832/56940]\n",
      "loss: 0.158703  [48032/56940]\n",
      "loss: 0.260064  [51232/56940]\n",
      "loss: 0.391248  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.231590 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.194341  [   32/56940]\n",
      "loss: 0.320347  [ 3232/56940]\n",
      "loss: 0.217320  [ 6432/56940]\n",
      "loss: 0.147040  [ 9632/56940]\n",
      "loss: 0.222550  [12832/56940]\n",
      "loss: 0.172912  [16032/56940]\n",
      "loss: 0.221348  [19232/56940]\n",
      "loss: 0.288830  [22432/56940]\n",
      "loss: 0.160883  [25632/56940]\n",
      "loss: 0.416514  [28832/56940]\n",
      "loss: 0.370507  [32032/56940]\n",
      "loss: 0.213596  [35232/56940]\n",
      "loss: 0.295369  [38432/56940]\n",
      "loss: 0.360290  [41632/56940]\n",
      "loss: 0.230089  [44832/56940]\n",
      "loss: 0.272371  [48032/56940]\n",
      "loss: 0.312020  [51232/56940]\n",
      "loss: 0.223290  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.206276 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.301872  [   32/56940]\n",
      "loss: 0.231104  [ 3232/56940]\n",
      "loss: 0.324525  [ 6432/56940]\n",
      "loss: 0.206908  [ 9632/56940]\n",
      "loss: 0.259741  [12832/56940]\n",
      "loss: 0.223412  [16032/56940]\n",
      "loss: 0.302458  [19232/56940]\n",
      "loss: 0.155241  [22432/56940]\n",
      "loss: 0.224845  [25632/56940]\n",
      "loss: 0.196112  [28832/56940]\n",
      "loss: 0.287107  [32032/56940]\n",
      "loss: 0.202769  [35232/56940]\n",
      "loss: 0.171114  [38432/56940]\n",
      "loss: 0.305366  [41632/56940]\n",
      "loss: 0.191716  [44832/56940]\n",
      "loss: 0.267151  [48032/56940]\n",
      "loss: 0.454063  [51232/56940]\n",
      "loss: 0.142668  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.212128 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.175330  [   32/56940]\n",
      "loss: 0.364966  [ 3232/56940]\n",
      "loss: 0.263890  [ 6432/56940]\n",
      "loss: 0.130709  [ 9632/56940]\n",
      "loss: 0.470536  [12832/56940]\n",
      "loss: 0.310782  [16032/56940]\n",
      "loss: 0.596594  [19232/56940]\n",
      "loss: 0.164123  [22432/56940]\n",
      "loss: 0.135114  [25632/56940]\n",
      "loss: 0.149984  [28832/56940]\n",
      "loss: 0.280519  [32032/56940]\n",
      "loss: 0.426391  [35232/56940]\n",
      "loss: 0.332693  [38432/56940]\n",
      "loss: 0.157594  [41632/56940]\n",
      "loss: 0.179593  [44832/56940]\n",
      "loss: 0.157330  [48032/56940]\n",
      "loss: 0.133112  [51232/56940]\n",
      "loss: 0.243115  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.205973 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.210095  [   32/56940]\n",
      "loss: 0.422225  [ 3232/56940]\n",
      "loss: 0.324554  [ 6432/56940]\n",
      "loss: 0.138809  [ 9632/56940]\n",
      "loss: 0.274547  [12832/56940]\n",
      "loss: 0.270808  [16032/56940]\n",
      "loss: 0.247269  [19232/56940]\n",
      "loss: 0.229987  [22432/56940]\n",
      "loss: 0.253763  [25632/56940]\n",
      "loss: 0.223912  [28832/56940]\n",
      "loss: 0.330107  [32032/56940]\n",
      "loss: 0.346022  [35232/56940]\n",
      "loss: 0.190933  [38432/56940]\n",
      "loss: 0.199082  [41632/56940]\n",
      "loss: 0.251648  [44832/56940]\n",
      "loss: 0.188325  [48032/56940]\n",
      "loss: 0.308632  [51232/56940]\n",
      "loss: 0.153504  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.239439 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.186325  [   32/56940]\n",
      "loss: 0.109170  [ 3232/56940]\n",
      "loss: 0.098486  [ 6432/56940]\n",
      "loss: 0.325358  [ 9632/56940]\n",
      "loss: 0.321830  [12832/56940]\n",
      "loss: 0.200883  [16032/56940]\n",
      "loss: 0.183356  [19232/56940]\n",
      "loss: 0.251996  [22432/56940]\n",
      "loss: 0.301119  [25632/56940]\n",
      "loss: 0.206201  [28832/56940]\n",
      "loss: 0.227623  [32032/56940]\n",
      "loss: 0.371594  [35232/56940]\n",
      "loss: 0.400335  [38432/56940]\n",
      "loss: 0.133271  [41632/56940]\n",
      "loss: 0.212054  [44832/56940]\n",
      "loss: 0.169060  [48032/56940]\n",
      "loss: 0.313576  [51232/56940]\n",
      "loss: 0.666660  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.217909 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.249546  [   32/56940]\n",
      "loss: 0.357408  [ 3232/56940]\n",
      "loss: 0.299461  [ 6432/56940]\n",
      "loss: 0.168885  [ 9632/56940]\n",
      "loss: 0.195474  [12832/56940]\n",
      "loss: 0.263292  [16032/56940]\n",
      "loss: 0.297946  [19232/56940]\n",
      "loss: 0.083054  [22432/56940]\n",
      "loss: 0.187758  [25632/56940]\n",
      "loss: 0.121651  [28832/56940]\n",
      "loss: 0.346703  [32032/56940]\n",
      "loss: 0.480108  [35232/56940]\n",
      "loss: 0.236562  [38432/56940]\n",
      "loss: 0.166127  [41632/56940]\n",
      "loss: 0.603436  [44832/56940]\n",
      "loss: 0.374582  [48032/56940]\n",
      "loss: 0.472022  [51232/56940]\n",
      "loss: 0.203534  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.204610 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.333614  [   32/56940]\n",
      "loss: 0.272090  [ 3232/56940]\n",
      "loss: 0.175023  [ 6432/56940]\n",
      "loss: 0.228195  [ 9632/56940]\n",
      "loss: 0.302826  [12832/56940]\n",
      "loss: 0.157792  [16032/56940]\n",
      "loss: 0.183118  [19232/56940]\n",
      "loss: 0.273698  [22432/56940]\n",
      "loss: 0.278594  [25632/56940]\n",
      "loss: 0.213029  [28832/56940]\n",
      "loss: 0.155948  [32032/56940]\n",
      "loss: 0.242742  [35232/56940]\n",
      "loss: 0.210652  [38432/56940]\n",
      "loss: 0.100913  [41632/56940]\n",
      "loss: 0.301352  [44832/56940]\n",
      "loss: 0.132530  [48032/56940]\n",
      "loss: 0.286803  [51232/56940]\n",
      "loss: 0.087990  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.225819 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.384288  [   32/56940]\n",
      "loss: 0.298236  [ 3232/56940]\n",
      "loss: 0.358792  [ 6432/56940]\n",
      "loss: 0.191229  [ 9632/56940]\n",
      "loss: 0.125529  [12832/56940]\n",
      "loss: 0.327110  [16032/56940]\n",
      "loss: 0.221094  [19232/56940]\n",
      "loss: 0.258284  [22432/56940]\n",
      "loss: 0.109969  [25632/56940]\n",
      "loss: 0.577663  [28832/56940]\n",
      "loss: 0.206842  [32032/56940]\n",
      "loss: 0.097074  [35232/56940]\n",
      "loss: 0.276906  [38432/56940]\n",
      "loss: 0.079571  [41632/56940]\n",
      "loss: 0.147768  [44832/56940]\n",
      "loss: 0.224580  [48032/56940]\n",
      "loss: 0.415749  [51232/56940]\n",
      "loss: 0.129483  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.202170 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.470594  [   32/56940]\n",
      "loss: 0.222311  [ 3232/56940]\n",
      "loss: 0.334249  [ 6432/56940]\n",
      "loss: 0.278940  [ 9632/56940]\n",
      "loss: 0.143315  [12832/56940]\n",
      "loss: 0.278887  [16032/56940]\n",
      "loss: 0.228078  [19232/56940]\n",
      "loss: 0.470296  [22432/56940]\n",
      "loss: 0.297736  [25632/56940]\n",
      "loss: 0.082446  [28832/56940]\n",
      "loss: 0.277823  [32032/56940]\n",
      "loss: 0.107969  [35232/56940]\n",
      "loss: 0.224394  [38432/56940]\n",
      "loss: 0.342619  [41632/56940]\n",
      "loss: 0.154022  [44832/56940]\n",
      "loss: 0.323852  [48032/56940]\n",
      "loss: 0.283669  [51232/56940]\n",
      "loss: 0.144024  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.216311 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.204793  [   32/56940]\n",
      "loss: 0.523040  [ 3232/56940]\n",
      "loss: 0.182010  [ 6432/56940]\n",
      "loss: 0.545245  [ 9632/56940]\n",
      "loss: 0.223375  [12832/56940]\n",
      "loss: 0.107567  [16032/56940]\n",
      "loss: 0.374490  [19232/56940]\n",
      "loss: 0.268797  [22432/56940]\n",
      "loss: 0.309611  [25632/56940]\n",
      "loss: 0.181850  [28832/56940]\n",
      "loss: 0.180670  [32032/56940]\n",
      "loss: 0.218882  [35232/56940]\n",
      "loss: 0.268580  [38432/56940]\n",
      "loss: 0.294639  [41632/56940]\n",
      "loss: 0.261122  [44832/56940]\n",
      "loss: 0.204893  [48032/56940]\n",
      "loss: 0.241503  [51232/56940]\n",
      "loss: 0.213199  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.212587 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.164627  [   32/56940]\n",
      "loss: 0.140457  [ 3232/56940]\n",
      "loss: 0.276919  [ 6432/56940]\n",
      "loss: 0.171723  [ 9632/56940]\n",
      "loss: 0.319414  [12832/56940]\n",
      "loss: 0.206704  [16032/56940]\n",
      "loss: 0.160883  [19232/56940]\n",
      "loss: 0.092352  [22432/56940]\n",
      "loss: 0.353154  [25632/56940]\n",
      "loss: 0.401604  [28832/56940]\n",
      "loss: 0.172827  [32032/56940]\n",
      "loss: 0.121775  [35232/56940]\n",
      "loss: 0.332363  [38432/56940]\n",
      "loss: 0.196966  [41632/56940]\n",
      "loss: 0.406633  [44832/56940]\n",
      "loss: 0.171151  [48032/56940]\n",
      "loss: 0.216214  [51232/56940]\n",
      "loss: 0.432745  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.213828 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.221191  [   32/56940]\n",
      "loss: 0.108853  [ 3232/56940]\n",
      "loss: 0.297136  [ 6432/56940]\n",
      "loss: 0.125324  [ 9632/56940]\n",
      "loss: 0.276192  [12832/56940]\n",
      "loss: 0.284361  [16032/56940]\n",
      "loss: 0.181708  [19232/56940]\n",
      "loss: 0.180066  [22432/56940]\n",
      "loss: 0.250083  [25632/56940]\n",
      "loss: 0.129803  [28832/56940]\n",
      "loss: 0.223570  [32032/56940]\n",
      "loss: 0.145189  [35232/56940]\n",
      "loss: 0.322284  [38432/56940]\n",
      "loss: 0.423933  [41632/56940]\n",
      "loss: 0.299882  [44832/56940]\n",
      "loss: 0.188871  [48032/56940]\n",
      "loss: 0.120974  [51232/56940]\n",
      "loss: 0.249842  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.203857 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.411983  [   32/56940]\n",
      "loss: 0.216152  [ 3232/56940]\n",
      "loss: 0.236838  [ 6432/56940]\n",
      "loss: 0.243934  [ 9632/56940]\n",
      "loss: 0.364375  [12832/56940]\n",
      "loss: 0.271024  [16032/56940]\n",
      "loss: 0.231746  [19232/56940]\n",
      "loss: 0.282472  [22432/56940]\n",
      "loss: 0.181698  [25632/56940]\n",
      "loss: 0.179871  [28832/56940]\n",
      "loss: 0.367379  [32032/56940]\n",
      "loss: 0.185087  [35232/56940]\n",
      "loss: 0.195662  [38432/56940]\n",
      "loss: 0.395728  [41632/56940]\n",
      "loss: 0.305744  [44832/56940]\n",
      "loss: 0.184864  [48032/56940]\n",
      "loss: 0.125732  [51232/56940]\n",
      "loss: 0.292752  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.206310 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.181285  [   32/56940]\n",
      "loss: 0.153731  [ 3232/56940]\n",
      "loss: 0.079749  [ 6432/56940]\n",
      "loss: 0.318078  [ 9632/56940]\n",
      "loss: 0.096075  [12832/56940]\n",
      "loss: 0.352017  [16032/56940]\n",
      "loss: 0.247913  [19232/56940]\n",
      "loss: 0.274030  [22432/56940]\n",
      "loss: 0.252018  [25632/56940]\n",
      "loss: 0.294388  [28832/56940]\n",
      "loss: 0.134638  [32032/56940]\n",
      "loss: 0.072799  [35232/56940]\n",
      "loss: 0.146312  [38432/56940]\n",
      "loss: 0.201161  [41632/56940]\n",
      "loss: 0.247666  [44832/56940]\n",
      "loss: 0.120607  [48032/56940]\n",
      "loss: 0.167383  [51232/56940]\n",
      "loss: 0.312270  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.197887 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.100465  [   32/56940]\n",
      "loss: 0.253117  [ 3232/56940]\n",
      "loss: 0.227618  [ 6432/56940]\n",
      "loss: 0.143772  [ 9632/56940]\n",
      "loss: 0.398408  [12832/56940]\n",
      "loss: 0.190492  [16032/56940]\n",
      "loss: 0.185425  [19232/56940]\n",
      "loss: 0.219915  [22432/56940]\n",
      "loss: 0.165047  [25632/56940]\n",
      "loss: 0.278027  [28832/56940]\n",
      "loss: 0.202059  [32032/56940]\n",
      "loss: 0.203410  [35232/56940]\n",
      "loss: 0.742541  [38432/56940]\n",
      "loss: 0.248115  [41632/56940]\n",
      "loss: 0.351680  [44832/56940]\n",
      "loss: 0.421141  [48032/56940]\n",
      "loss: 0.488297  [51232/56940]\n",
      "loss: 0.283591  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.201676 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.182498  [   32/56940]\n",
      "loss: 0.268116  [ 3232/56940]\n",
      "loss: 0.185366  [ 6432/56940]\n",
      "loss: 0.353483  [ 9632/56940]\n",
      "loss: 0.321732  [12832/56940]\n",
      "loss: 0.291329  [16032/56940]\n",
      "loss: 0.191538  [19232/56940]\n",
      "loss: 0.244478  [22432/56940]\n",
      "loss: 0.294791  [25632/56940]\n",
      "loss: 0.193682  [28832/56940]\n",
      "loss: 0.506392  [32032/56940]\n",
      "loss: 0.178602  [35232/56940]\n",
      "loss: 0.243189  [38432/56940]\n",
      "loss: 0.202107  [41632/56940]\n",
      "loss: 0.241435  [44832/56940]\n",
      "loss: 0.388262  [48032/56940]\n",
      "loss: 0.241855  [51232/56940]\n",
      "loss: 0.353323  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.207523 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.122139  [   32/56940]\n",
      "loss: 0.328698  [ 3232/56940]\n",
      "loss: 0.324672  [ 6432/56940]\n",
      "loss: 0.234461  [ 9632/56940]\n",
      "loss: 0.153784  [12832/56940]\n",
      "loss: 0.407812  [16032/56940]\n",
      "loss: 0.121789  [19232/56940]\n",
      "loss: 0.250742  [22432/56940]\n",
      "loss: 0.149527  [25632/56940]\n",
      "loss: 0.269262  [28832/56940]\n",
      "loss: 0.333205  [32032/56940]\n",
      "loss: 0.349655  [35232/56940]\n",
      "loss: 0.174736  [38432/56940]\n",
      "loss: 0.177691  [41632/56940]\n",
      "loss: 0.168515  [44832/56940]\n",
      "loss: 0.326753  [48032/56940]\n",
      "loss: 0.242156  [51232/56940]\n",
      "loss: 0.080441  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.222895 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.229256  [   32/56940]\n",
      "loss: 0.124908  [ 3232/56940]\n",
      "loss: 0.143255  [ 6432/56940]\n",
      "loss: 0.444005  [ 9632/56940]\n",
      "loss: 0.313381  [12832/56940]\n",
      "loss: 0.189640  [16032/56940]\n",
      "loss: 0.146601  [19232/56940]\n",
      "loss: 0.255414  [22432/56940]\n",
      "loss: 0.270142  [25632/56940]\n",
      "loss: 0.253961  [28832/56940]\n",
      "loss: 0.270564  [32032/56940]\n",
      "loss: 0.237111  [35232/56940]\n",
      "loss: 0.315627  [38432/56940]\n",
      "loss: 0.192599  [41632/56940]\n",
      "loss: 0.168254  [44832/56940]\n",
      "loss: 0.290437  [48032/56940]\n",
      "loss: 0.381133  [51232/56940]\n",
      "loss: 0.166799  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.220975 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.163518  [   32/56940]\n",
      "loss: 0.070389  [ 3232/56940]\n",
      "loss: 0.730718  [ 6432/56940]\n",
      "loss: 0.191261  [ 9632/56940]\n",
      "loss: 0.301073  [12832/56940]\n",
      "loss: 0.154812  [16032/56940]\n",
      "loss: 0.288366  [19232/56940]\n",
      "loss: 0.204942  [22432/56940]\n",
      "loss: 0.114217  [25632/56940]\n",
      "loss: 0.460481  [28832/56940]\n",
      "loss: 0.165034  [32032/56940]\n",
      "loss: 0.185037  [35232/56940]\n",
      "loss: 0.266044  [38432/56940]\n",
      "loss: 0.381742  [41632/56940]\n",
      "loss: 0.312522  [44832/56940]\n",
      "loss: 0.247672  [48032/56940]\n",
      "loss: 0.316050  [51232/56940]\n",
      "loss: 0.139848  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.206305 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.237293  [   32/56940]\n",
      "loss: 0.122303  [ 3232/56940]\n",
      "loss: 0.191846  [ 6432/56940]\n",
      "loss: 0.303668  [ 9632/56940]\n",
      "loss: 0.120982  [12832/56940]\n",
      "loss: 0.236730  [16032/56940]\n",
      "loss: 0.294192  [19232/56940]\n",
      "loss: 0.187422  [22432/56940]\n",
      "loss: 0.213626  [25632/56940]\n",
      "loss: 0.204532  [28832/56940]\n",
      "loss: 0.224440  [32032/56940]\n",
      "loss: 0.137805  [35232/56940]\n",
      "loss: 0.324403  [38432/56940]\n",
      "loss: 0.184501  [41632/56940]\n",
      "loss: 0.140462  [44832/56940]\n",
      "loss: 0.131288  [48032/56940]\n",
      "loss: 0.223024  [51232/56940]\n",
      "loss: 0.074227  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.206909 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.249555  [   32/56940]\n",
      "loss: 0.244496  [ 3232/56940]\n",
      "loss: 0.277038  [ 6432/56940]\n",
      "loss: 0.247197  [ 9632/56940]\n",
      "loss: 0.186079  [12832/56940]\n",
      "loss: 0.203835  [16032/56940]\n",
      "loss: 0.365670  [19232/56940]\n",
      "loss: 0.254203  [22432/56940]\n",
      "loss: 0.313056  [25632/56940]\n",
      "loss: 0.333047  [28832/56940]\n",
      "loss: 0.531258  [32032/56940]\n",
      "loss: 0.190507  [35232/56940]\n",
      "loss: 0.209293  [38432/56940]\n",
      "loss: 0.303147  [41632/56940]\n",
      "loss: 0.252222  [44832/56940]\n",
      "loss: 0.213656  [48032/56940]\n",
      "loss: 0.259261  [51232/56940]\n",
      "loss: 0.208918  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.220086 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.289909  [   32/56940]\n",
      "loss: 0.092110  [ 3232/56940]\n",
      "loss: 0.442620  [ 6432/56940]\n",
      "loss: 0.174864  [ 9632/56940]\n",
      "loss: 0.069658  [12832/56940]\n",
      "loss: 0.161264  [16032/56940]\n",
      "loss: 0.243380  [19232/56940]\n",
      "loss: 0.314651  [22432/56940]\n",
      "loss: 0.374561  [25632/56940]\n",
      "loss: 0.232346  [28832/56940]\n",
      "loss: 0.180565  [32032/56940]\n",
      "loss: 0.175558  [35232/56940]\n",
      "loss: 0.240691  [38432/56940]\n",
      "loss: 0.066750  [41632/56940]\n",
      "loss: 0.229061  [44832/56940]\n",
      "loss: 0.161074  [48032/56940]\n",
      "loss: 0.127060  [51232/56940]\n",
      "loss: 0.176810  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.206880 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.194806  [   32/56940]\n",
      "loss: 0.277796  [ 3232/56940]\n",
      "loss: 0.113188  [ 6432/56940]\n",
      "loss: 0.131710  [ 9632/56940]\n",
      "loss: 0.158580  [12832/56940]\n",
      "loss: 0.274832  [16032/56940]\n",
      "loss: 0.142579  [19232/56940]\n",
      "loss: 0.400833  [22432/56940]\n",
      "loss: 0.292331  [25632/56940]\n",
      "loss: 0.148508  [28832/56940]\n",
      "loss: 0.133027  [32032/56940]\n",
      "loss: 0.259360  [35232/56940]\n",
      "loss: 0.208054  [38432/56940]\n",
      "loss: 0.195653  [41632/56940]\n",
      "loss: 0.625561  [44832/56940]\n",
      "loss: 0.274147  [48032/56940]\n",
      "loss: 0.190739  [51232/56940]\n",
      "loss: 0.245776  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.203802 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.271678  [   32/56940]\n",
      "loss: 0.109363  [ 3232/56940]\n",
      "loss: 0.439199  [ 6432/56940]\n",
      "loss: 0.405771  [ 9632/56940]\n",
      "loss: 0.363607  [12832/56940]\n",
      "loss: 0.197577  [16032/56940]\n",
      "loss: 0.211096  [19232/56940]\n",
      "loss: 0.330814  [22432/56940]\n",
      "loss: 0.374001  [25632/56940]\n",
      "loss: 0.244875  [28832/56940]\n",
      "loss: 0.267102  [32032/56940]\n",
      "loss: 0.178166  [35232/56940]\n",
      "loss: 0.210709  [38432/56940]\n",
      "loss: 0.206315  [41632/56940]\n",
      "loss: 0.337116  [44832/56940]\n",
      "loss: 0.348001  [48032/56940]\n",
      "loss: 0.160169  [51232/56940]\n",
      "loss: 0.147744  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.205304 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.246121  [   32/56940]\n",
      "loss: 0.173338  [ 3232/56940]\n",
      "loss: 0.462960  [ 6432/56940]\n",
      "loss: 0.157499  [ 9632/56940]\n",
      "loss: 0.119973  [12832/56940]\n",
      "loss: 0.504976  [16032/56940]\n",
      "loss: 0.194098  [19232/56940]\n",
      "loss: 0.170039  [22432/56940]\n",
      "loss: 0.281308  [25632/56940]\n",
      "loss: 0.295410  [28832/56940]\n",
      "loss: 0.143723  [32032/56940]\n",
      "loss: 0.198860  [35232/56940]\n",
      "loss: 0.116409  [38432/56940]\n",
      "loss: 0.263696  [41632/56940]\n",
      "loss: 0.486574  [44832/56940]\n",
      "loss: 0.167471  [48032/56940]\n",
      "loss: 0.290212  [51232/56940]\n",
      "loss: 0.227179  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.224334 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.269466  [   32/56940]\n",
      "loss: 0.265308  [ 3232/56940]\n",
      "loss: 0.284614  [ 6432/56940]\n",
      "loss: 0.128736  [ 9632/56940]\n",
      "loss: 0.156852  [12832/56940]\n",
      "loss: 0.128100  [16032/56940]\n",
      "loss: 0.323696  [19232/56940]\n",
      "loss: 0.151296  [22432/56940]\n",
      "loss: 0.155077  [25632/56940]\n",
      "loss: 0.169746  [28832/56940]\n",
      "loss: 0.163360  [32032/56940]\n",
      "loss: 0.339538  [35232/56940]\n",
      "loss: 0.077946  [38432/56940]\n",
      "loss: 0.548606  [41632/56940]\n",
      "loss: 0.253279  [44832/56940]\n",
      "loss: 0.294839  [48032/56940]\n",
      "loss: 0.120457  [51232/56940]\n",
      "loss: 0.431958  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.209678 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.257938  [   32/56940]\n",
      "loss: 0.567752  [ 3232/56940]\n",
      "loss: 0.142559  [ 6432/56940]\n",
      "loss: 0.308306  [ 9632/56940]\n",
      "loss: 0.193914  [12832/56940]\n",
      "loss: 0.195346  [16032/56940]\n",
      "loss: 0.134710  [19232/56940]\n",
      "loss: 0.280775  [22432/56940]\n",
      "loss: 0.188456  [25632/56940]\n",
      "loss: 0.389978  [28832/56940]\n",
      "loss: 0.452112  [32032/56940]\n",
      "loss: 0.315835  [35232/56940]\n",
      "loss: 0.159311  [38432/56940]\n",
      "loss: 0.168390  [41632/56940]\n",
      "loss: 0.162702  [44832/56940]\n",
      "loss: 0.199196  [48032/56940]\n",
      "loss: 0.150711  [51232/56940]\n",
      "loss: 0.276519  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.201396 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.286243  [   32/56940]\n",
      "loss: 0.251874  [ 3232/56940]\n",
      "loss: 0.195489  [ 6432/56940]\n",
      "loss: 0.224191  [ 9632/56940]\n",
      "loss: 0.317664  [12832/56940]\n",
      "loss: 0.278094  [16032/56940]\n",
      "loss: 0.427816  [19232/56940]\n",
      "loss: 0.274547  [22432/56940]\n",
      "loss: 0.116571  [25632/56940]\n",
      "loss: 0.370089  [28832/56940]\n",
      "loss: 0.214371  [32032/56940]\n",
      "loss: 0.258610  [35232/56940]\n",
      "loss: 0.169615  [38432/56940]\n",
      "loss: 0.360403  [41632/56940]\n",
      "loss: 0.248045  [44832/56940]\n",
      "loss: 0.221057  [48032/56940]\n",
      "loss: 0.164780  [51232/56940]\n",
      "loss: 0.267339  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.200610 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.166853  [   32/56940]\n",
      "loss: 0.261073  [ 3232/56940]\n",
      "loss: 0.475055  [ 6432/56940]\n",
      "loss: 0.191040  [ 9632/56940]\n",
      "loss: 0.433151  [12832/56940]\n",
      "loss: 0.156317  [16032/56940]\n",
      "loss: 0.222214  [19232/56940]\n",
      "loss: 0.336966  [22432/56940]\n",
      "loss: 0.207123  [25632/56940]\n",
      "loss: 0.420540  [28832/56940]\n",
      "loss: 0.242081  [32032/56940]\n",
      "loss: 0.233328  [35232/56940]\n",
      "loss: 0.477685  [38432/56940]\n",
      "loss: 0.197596  [41632/56940]\n",
      "loss: 0.235360  [44832/56940]\n",
      "loss: 0.217117  [48032/56940]\n",
      "loss: 0.205590  [51232/56940]\n",
      "loss: 0.117832  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.203463 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.274504  [   32/56940]\n",
      "loss: 0.253766  [ 3232/56940]\n",
      "loss: 0.126292  [ 6432/56940]\n",
      "loss: 0.290467  [ 9632/56940]\n",
      "loss: 0.266591  [12832/56940]\n",
      "loss: 0.327368  [16032/56940]\n",
      "loss: 0.282953  [19232/56940]\n",
      "loss: 0.161571  [22432/56940]\n",
      "loss: 0.182177  [25632/56940]\n",
      "loss: 0.223274  [28832/56940]\n",
      "loss: 0.187866  [32032/56940]\n",
      "loss: 0.137841  [35232/56940]\n",
      "loss: 0.276544  [38432/56940]\n",
      "loss: 0.198591  [41632/56940]\n",
      "loss: 0.132281  [44832/56940]\n",
      "loss: 0.094306  [48032/56940]\n",
      "loss: 0.335022  [51232/56940]\n",
      "loss: 0.273141  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.215352 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.162104  [   32/56940]\n",
      "loss: 0.412923  [ 3232/56940]\n",
      "loss: 0.394496  [ 6432/56940]\n",
      "loss: 0.159663  [ 9632/56940]\n",
      "loss: 0.195895  [12832/56940]\n",
      "loss: 0.423741  [16032/56940]\n",
      "loss: 0.283294  [19232/56940]\n",
      "loss: 0.269717  [22432/56940]\n",
      "loss: 0.229316  [25632/56940]\n",
      "loss: 0.170127  [28832/56940]\n",
      "loss: 0.229420  [32032/56940]\n",
      "loss: 0.114246  [35232/56940]\n",
      "loss: 0.272665  [38432/56940]\n",
      "loss: 0.214341  [41632/56940]\n",
      "loss: 0.436736  [44832/56940]\n",
      "loss: 0.166991  [48032/56940]\n",
      "loss: 0.227300  [51232/56940]\n",
      "loss: 0.315650  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.197721 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.149466  [   32/56940]\n",
      "loss: 0.249280  [ 3232/56940]\n",
      "loss: 0.085130  [ 6432/56940]\n",
      "loss: 0.221217  [ 9632/56940]\n",
      "loss: 0.506001  [12832/56940]\n",
      "loss: 0.261877  [16032/56940]\n",
      "loss: 0.222815  [19232/56940]\n",
      "loss: 0.190864  [22432/56940]\n",
      "loss: 0.153263  [25632/56940]\n",
      "loss: 0.181925  [28832/56940]\n",
      "loss: 0.232630  [32032/56940]\n",
      "loss: 0.220125  [35232/56940]\n",
      "loss: 0.368725  [38432/56940]\n",
      "loss: 0.154985  [41632/56940]\n",
      "loss: 0.295740  [44832/56940]\n",
      "loss: 0.180163  [48032/56940]\n",
      "loss: 0.132175  [51232/56940]\n",
      "loss: 0.151406  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.244681 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.290482  [   32/56940]\n",
      "loss: 0.175099  [ 3232/56940]\n",
      "loss: 0.357590  [ 6432/56940]\n",
      "loss: 0.132131  [ 9632/56940]\n",
      "loss: 0.197565  [12832/56940]\n",
      "loss: 0.273107  [16032/56940]\n",
      "loss: 0.287044  [19232/56940]\n",
      "loss: 0.250412  [22432/56940]\n",
      "loss: 0.247698  [25632/56940]\n",
      "loss: 0.286695  [28832/56940]\n",
      "loss: 0.291917  [32032/56940]\n",
      "loss: 0.233673  [35232/56940]\n",
      "loss: 0.346602  [38432/56940]\n",
      "loss: 0.158812  [41632/56940]\n",
      "loss: 0.183361  [44832/56940]\n",
      "loss: 0.262264  [48032/56940]\n",
      "loss: 0.257804  [51232/56940]\n",
      "loss: 0.179553  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.200353 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.186600  [   32/56940]\n",
      "loss: 0.258003  [ 3232/56940]\n",
      "loss: 0.137664  [ 6432/56940]\n",
      "loss: 0.174498  [ 9632/56940]\n",
      "loss: 0.184631  [12832/56940]\n",
      "loss: 0.335560  [16032/56940]\n",
      "loss: 0.155424  [19232/56940]\n",
      "loss: 0.134192  [22432/56940]\n",
      "loss: 0.218432  [25632/56940]\n",
      "loss: 0.256641  [28832/56940]\n",
      "loss: 0.179768  [32032/56940]\n",
      "loss: 0.324393  [35232/56940]\n",
      "loss: 0.156937  [38432/56940]\n",
      "loss: 0.212070  [41632/56940]\n",
      "loss: 0.087841  [44832/56940]\n",
      "loss: 0.118037  [48032/56940]\n",
      "loss: 0.225162  [51232/56940]\n",
      "loss: 0.109792  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.196793 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.304503  [   32/56940]\n",
      "loss: 0.211881  [ 3232/56940]\n",
      "loss: 0.229646  [ 6432/56940]\n",
      "loss: 0.169417  [ 9632/56940]\n",
      "loss: 0.336786  [12832/56940]\n",
      "loss: 0.198950  [16032/56940]\n",
      "loss: 0.248549  [19232/56940]\n",
      "loss: 0.145124  [22432/56940]\n",
      "loss: 0.164354  [25632/56940]\n",
      "loss: 0.409882  [28832/56940]\n",
      "loss: 0.104337  [32032/56940]\n",
      "loss: 0.128812  [35232/56940]\n",
      "loss: 0.153805  [38432/56940]\n",
      "loss: 0.183157  [41632/56940]\n",
      "loss: 0.220470  [44832/56940]\n",
      "loss: 0.293148  [48032/56940]\n",
      "loss: 0.278141  [51232/56940]\n",
      "loss: 0.359852  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.203766 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.318004  [   32/56940]\n",
      "loss: 0.371434  [ 3232/56940]\n",
      "loss: 0.266425  [ 6432/56940]\n",
      "loss: 0.288985  [ 9632/56940]\n",
      "loss: 0.200418  [12832/56940]\n",
      "loss: 0.293407  [16032/56940]\n",
      "loss: 0.355050  [19232/56940]\n",
      "loss: 0.404780  [22432/56940]\n",
      "loss: 0.134019  [25632/56940]\n",
      "loss: 0.167962  [28832/56940]\n",
      "loss: 0.395319  [32032/56940]\n",
      "loss: 0.333155  [35232/56940]\n",
      "loss: 0.723445  [38432/56940]\n",
      "loss: 0.304122  [41632/56940]\n",
      "loss: 0.182406  [44832/56940]\n",
      "loss: 0.297922  [48032/56940]\n",
      "loss: 0.237930  [51232/56940]\n",
      "loss: 0.237439  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.200305 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.396134  [   32/56940]\n",
      "loss: 0.205928  [ 3232/56940]\n",
      "loss: 0.207025  [ 6432/56940]\n",
      "loss: 0.214599  [ 9632/56940]\n",
      "loss: 0.155316  [12832/56940]\n",
      "loss: 0.387480  [16032/56940]\n",
      "loss: 0.258173  [19232/56940]\n",
      "loss: 0.244794  [22432/56940]\n",
      "loss: 0.417315  [25632/56940]\n",
      "loss: 0.461248  [28832/56940]\n",
      "loss: 0.326589  [32032/56940]\n",
      "loss: 0.337081  [35232/56940]\n",
      "loss: 0.260525  [38432/56940]\n",
      "loss: 0.267179  [41632/56940]\n",
      "loss: 0.162508  [44832/56940]\n",
      "loss: 0.309525  [48032/56940]\n",
      "loss: 0.356223  [51232/56940]\n",
      "loss: 0.369641  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.219729 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.334752  [   32/56940]\n",
      "loss: 0.176989  [ 3232/56940]\n",
      "loss: 0.238338  [ 6432/56940]\n",
      "loss: 0.129368  [ 9632/56940]\n",
      "loss: 0.119403  [12832/56940]\n",
      "loss: 0.557351  [16032/56940]\n",
      "loss: 0.201050  [19232/56940]\n",
      "loss: 0.330771  [22432/56940]\n",
      "loss: 0.295327  [25632/56940]\n",
      "loss: 0.211650  [28832/56940]\n",
      "loss: 0.360180  [32032/56940]\n",
      "loss: 0.248823  [35232/56940]\n",
      "loss: 0.285392  [38432/56940]\n",
      "loss: 0.177933  [41632/56940]\n",
      "loss: 0.082731  [44832/56940]\n",
      "loss: 0.154640  [48032/56940]\n",
      "loss: 0.143580  [51232/56940]\n",
      "loss: 0.287881  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.296163 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.223759  [   32/56940]\n",
      "loss: 0.120274  [ 3232/56940]\n",
      "loss: 0.398100  [ 6432/56940]\n",
      "loss: 0.193706  [ 9632/56940]\n",
      "loss: 0.168110  [12832/56940]\n",
      "loss: 0.183568  [16032/56940]\n",
      "loss: 0.385144  [19232/56940]\n",
      "loss: 0.167605  [22432/56940]\n",
      "loss: 0.201459  [25632/56940]\n",
      "loss: 0.123296  [28832/56940]\n",
      "loss: 0.356067  [32032/56940]\n",
      "loss: 0.151922  [35232/56940]\n",
      "loss: 0.118209  [38432/56940]\n",
      "loss: 0.330930  [41632/56940]\n",
      "loss: 0.147620  [44832/56940]\n",
      "loss: 0.149049  [48032/56940]\n",
      "loss: 0.067793  [51232/56940]\n",
      "loss: 0.188048  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.215462 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.209364  [   32/56940]\n",
      "loss: 0.086598  [ 3232/56940]\n",
      "loss: 0.193051  [ 6432/56940]\n",
      "loss: 0.262097  [ 9632/56940]\n",
      "loss: 0.266747  [12832/56940]\n",
      "loss: 0.368491  [16032/56940]\n",
      "loss: 0.361357  [19232/56940]\n",
      "loss: 0.183452  [22432/56940]\n",
      "loss: 0.277766  [25632/56940]\n",
      "loss: 0.151074  [28832/56940]\n",
      "loss: 0.173600  [32032/56940]\n",
      "loss: 0.210356  [35232/56940]\n",
      "loss: 0.251629  [38432/56940]\n",
      "loss: 0.106476  [41632/56940]\n",
      "loss: 0.260052  [44832/56940]\n",
      "loss: 0.221190  [48032/56940]\n",
      "loss: 0.228907  [51232/56940]\n",
      "loss: 0.357536  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.209166 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.239698  [   32/56940]\n",
      "loss: 0.172814  [ 3232/56940]\n",
      "loss: 0.758778  [ 6432/56940]\n",
      "loss: 0.144409  [ 9632/56940]\n",
      "loss: 0.126539  [12832/56940]\n",
      "loss: 0.319625  [16032/56940]\n",
      "loss: 0.393262  [19232/56940]\n",
      "loss: 0.304321  [22432/56940]\n",
      "loss: 0.219552  [25632/56940]\n",
      "loss: 0.440755  [28832/56940]\n",
      "loss: 0.144693  [32032/56940]\n",
      "loss: 0.241272  [35232/56940]\n",
      "loss: 0.406889  [38432/56940]\n",
      "loss: 0.246309  [41632/56940]\n",
      "loss: 0.087116  [44832/56940]\n",
      "loss: 0.178707  [48032/56940]\n",
      "loss: 0.199327  [51232/56940]\n",
      "loss: 0.305236  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.222137 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.204973  [   32/56940]\n",
      "loss: 0.486306  [ 3232/56940]\n",
      "loss: 0.094098  [ 6432/56940]\n",
      "loss: 0.115490  [ 9632/56940]\n",
      "loss: 0.357407  [12832/56940]\n",
      "loss: 0.101577  [16032/56940]\n",
      "loss: 0.103333  [19232/56940]\n",
      "loss: 0.301691  [22432/56940]\n",
      "loss: 0.169314  [25632/56940]\n",
      "loss: 0.223801  [28832/56940]\n",
      "loss: 0.360989  [32032/56940]\n",
      "loss: 0.192470  [35232/56940]\n",
      "loss: 0.075086  [38432/56940]\n",
      "loss: 0.273817  [41632/56940]\n",
      "loss: 0.194143  [44832/56940]\n",
      "loss: 0.266167  [48032/56940]\n",
      "loss: 0.350033  [51232/56940]\n",
      "loss: 0.281211  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.236355 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.191236  [   32/56940]\n",
      "loss: 0.140245  [ 3232/56940]\n",
      "loss: 0.087440  [ 6432/56940]\n",
      "loss: 0.161216  [ 9632/56940]\n",
      "loss: 0.276448  [12832/56940]\n",
      "loss: 0.176572  [16032/56940]\n",
      "loss: 0.149018  [19232/56940]\n",
      "loss: 0.140687  [22432/56940]\n",
      "loss: 0.310338  [25632/56940]\n",
      "loss: 0.069301  [28832/56940]\n",
      "loss: 0.135957  [32032/56940]\n",
      "loss: 0.324730  [35232/56940]\n",
      "loss: 0.113592  [38432/56940]\n",
      "loss: 0.302478  [41632/56940]\n",
      "loss: 0.185606  [44832/56940]\n",
      "loss: 0.068875  [48032/56940]\n",
      "loss: 0.147132  [51232/56940]\n",
      "loss: 0.196400  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.211007 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.150540  [   32/56940]\n",
      "loss: 0.383779  [ 3232/56940]\n",
      "loss: 0.211672  [ 6432/56940]\n",
      "loss: 0.246722  [ 9632/56940]\n",
      "loss: 0.495601  [12832/56940]\n",
      "loss: 0.202287  [16032/56940]\n",
      "loss: 0.397864  [19232/56940]\n",
      "loss: 0.262186  [22432/56940]\n",
      "loss: 0.175990  [25632/56940]\n",
      "loss: 0.206486  [28832/56940]\n",
      "loss: 0.179742  [32032/56940]\n",
      "loss: 0.163301  [35232/56940]\n",
      "loss: 0.241643  [38432/56940]\n",
      "loss: 0.282424  [41632/56940]\n",
      "loss: 0.180963  [44832/56940]\n",
      "loss: 0.177020  [48032/56940]\n",
      "loss: 0.181841  [51232/56940]\n",
      "loss: 0.286072  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.199962 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.321820  [   32/56940]\n",
      "loss: 0.244984  [ 3232/56940]\n",
      "loss: 0.104584  [ 6432/56940]\n",
      "loss: 0.158046  [ 9632/56940]\n",
      "loss: 0.213196  [12832/56940]\n",
      "loss: 0.400876  [16032/56940]\n",
      "loss: 0.346969  [19232/56940]\n",
      "loss: 0.329715  [22432/56940]\n",
      "loss: 0.150491  [25632/56940]\n",
      "loss: 0.237714  [28832/56940]\n",
      "loss: 0.144298  [32032/56940]\n",
      "loss: 0.055943  [35232/56940]\n",
      "loss: 0.315276  [38432/56940]\n",
      "loss: 0.154047  [41632/56940]\n",
      "loss: 0.215319  [44832/56940]\n",
      "loss: 0.234474  [48032/56940]\n",
      "loss: 0.089267  [51232/56940]\n",
      "loss: 0.180161  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.208611 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.311359  [   32/56940]\n",
      "loss: 0.274211  [ 3232/56940]\n",
      "loss: 0.267568  [ 6432/56940]\n",
      "loss: 0.363590  [ 9632/56940]\n",
      "loss: 0.166151  [12832/56940]\n",
      "loss: 0.481195  [16032/56940]\n",
      "loss: 0.156176  [19232/56940]\n",
      "loss: 0.194858  [22432/56940]\n",
      "loss: 0.271424  [25632/56940]\n",
      "loss: 0.117155  [28832/56940]\n",
      "loss: 0.276089  [32032/56940]\n",
      "loss: 0.115582  [35232/56940]\n",
      "loss: 0.083630  [38432/56940]\n",
      "loss: 0.309999  [41632/56940]\n",
      "loss: 0.118391  [44832/56940]\n",
      "loss: 0.211599  [48032/56940]\n",
      "loss: 0.318975  [51232/56940]\n",
      "loss: 0.172327  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.217584 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.081185  [   32/56940]\n",
      "loss: 0.392062  [ 3232/56940]\n",
      "loss: 0.495627  [ 6432/56940]\n",
      "loss: 0.260438  [ 9632/56940]\n",
      "loss: 0.356835  [12832/56940]\n",
      "loss: 0.140315  [16032/56940]\n",
      "loss: 0.190827  [19232/56940]\n",
      "loss: 0.451878  [22432/56940]\n",
      "loss: 0.198321  [25632/56940]\n",
      "loss: 0.200640  [28832/56940]\n",
      "loss: 0.137927  [32032/56940]\n",
      "loss: 0.511309  [35232/56940]\n",
      "loss: 0.328946  [38432/56940]\n",
      "loss: 0.393933  [41632/56940]\n",
      "loss: 0.157741  [44832/56940]\n",
      "loss: 0.280720  [48032/56940]\n",
      "loss: 0.161010  [51232/56940]\n",
      "loss: 0.796602  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.208987 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.263774  [   32/56940]\n",
      "loss: 0.295408  [ 3232/56940]\n",
      "loss: 0.183479  [ 6432/56940]\n",
      "loss: 0.275979  [ 9632/56940]\n",
      "loss: 0.152412  [12832/56940]\n",
      "loss: 0.066969  [16032/56940]\n",
      "loss: 0.091754  [19232/56940]\n",
      "loss: 0.311819  [22432/56940]\n",
      "loss: 0.198744  [25632/56940]\n",
      "loss: 0.209624  [28832/56940]\n",
      "loss: 0.305134  [32032/56940]\n",
      "loss: 0.163867  [35232/56940]\n",
      "loss: 0.130966  [38432/56940]\n",
      "loss: 0.255084  [41632/56940]\n",
      "loss: 0.508017  [44832/56940]\n",
      "loss: 0.171925  [48032/56940]\n",
      "loss: 0.259561  [51232/56940]\n",
      "loss: 0.232259  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.206027 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.376755  [   32/56940]\n",
      "loss: 0.268770  [ 3232/56940]\n",
      "loss: 0.239521  [ 6432/56940]\n",
      "loss: 0.220871  [ 9632/56940]\n",
      "loss: 0.502131  [12832/56940]\n",
      "loss: 0.182577  [16032/56940]\n",
      "loss: 0.176824  [19232/56940]\n",
      "loss: 0.299054  [22432/56940]\n",
      "loss: 0.085052  [25632/56940]\n",
      "loss: 0.389344  [28832/56940]\n",
      "loss: 0.340449  [32032/56940]\n",
      "loss: 0.299088  [35232/56940]\n",
      "loss: 0.063431  [38432/56940]\n",
      "loss: 0.222290  [41632/56940]\n",
      "loss: 0.087524  [44832/56940]\n",
      "loss: 0.197125  [48032/56940]\n",
      "loss: 0.216535  [51232/56940]\n",
      "loss: 0.278599  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.202360 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.722367  [   32/56940]\n",
      "loss: 0.273273  [ 3232/56940]\n",
      "loss: 0.250749  [ 6432/56940]\n",
      "loss: 0.166229  [ 9632/56940]\n",
      "loss: 0.272040  [12832/56940]\n",
      "loss: 0.255335  [16032/56940]\n",
      "loss: 0.122641  [19232/56940]\n",
      "loss: 0.301094  [22432/56940]\n",
      "loss: 0.258522  [25632/56940]\n",
      "loss: 0.309397  [28832/56940]\n",
      "loss: 0.182177  [32032/56940]\n",
      "loss: 0.247377  [35232/56940]\n",
      "loss: 0.295114  [38432/56940]\n",
      "loss: 0.109633  [41632/56940]\n",
      "loss: 0.318248  [44832/56940]\n",
      "loss: 0.283916  [48032/56940]\n",
      "loss: 0.174108  [51232/56940]\n",
      "loss: 0.292068  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.202111 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.308260  [   32/56940]\n",
      "loss: 0.189964  [ 3232/56940]\n",
      "loss: 0.227339  [ 6432/56940]\n",
      "loss: 0.278429  [ 9632/56940]\n",
      "loss: 0.235795  [12832/56940]\n",
      "loss: 0.518438  [16032/56940]\n",
      "loss: 0.349205  [19232/56940]\n",
      "loss: 0.140660  [22432/56940]\n",
      "loss: 0.257010  [25632/56940]\n",
      "loss: 0.175508  [28832/56940]\n",
      "loss: 0.332424  [32032/56940]\n",
      "loss: 0.193318  [35232/56940]\n",
      "loss: 0.204800  [38432/56940]\n",
      "loss: 0.285408  [41632/56940]\n",
      "loss: 0.159473  [44832/56940]\n",
      "loss: 0.212623  [48032/56940]\n",
      "loss: 0.359408  [51232/56940]\n",
      "loss: 0.206306  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.211470 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.611296  [   32/56940]\n",
      "loss: 0.207896  [ 3232/56940]\n",
      "loss: 0.110008  [ 6432/56940]\n",
      "loss: 0.125454  [ 9632/56940]\n",
      "loss: 0.248980  [12832/56940]\n",
      "loss: 0.253915  [16032/56940]\n",
      "loss: 0.565542  [19232/56940]\n",
      "loss: 0.206221  [22432/56940]\n",
      "loss: 0.330381  [25632/56940]\n",
      "loss: 0.195891  [28832/56940]\n",
      "loss: 0.502325  [32032/56940]\n",
      "loss: 0.137778  [35232/56940]\n",
      "loss: 0.198709  [38432/56940]\n",
      "loss: 0.288188  [41632/56940]\n",
      "loss: 0.249497  [44832/56940]\n",
      "loss: 0.250735  [48032/56940]\n",
      "loss: 0.454463  [51232/56940]\n",
      "loss: 0.334851  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.216763 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.157529  [   32/56940]\n",
      "loss: 0.213527  [ 3232/56940]\n",
      "loss: 0.193909  [ 6432/56940]\n",
      "loss: 0.159080  [ 9632/56940]\n",
      "loss: 0.170669  [12832/56940]\n",
      "loss: 0.438310  [16032/56940]\n",
      "loss: 0.226793  [19232/56940]\n",
      "loss: 0.198703  [22432/56940]\n",
      "loss: 0.089977  [25632/56940]\n",
      "loss: 0.334829  [28832/56940]\n",
      "loss: 0.312172  [32032/56940]\n",
      "loss: 0.215967  [35232/56940]\n",
      "loss: 0.228053  [38432/56940]\n",
      "loss: 0.153474  [41632/56940]\n",
      "loss: 0.321600  [44832/56940]\n",
      "loss: 0.275683  [48032/56940]\n",
      "loss: 0.127395  [51232/56940]\n",
      "loss: 0.233266  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.204293 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.218152  [   32/56940]\n",
      "loss: 0.227280  [ 3232/56940]\n",
      "loss: 0.191023  [ 6432/56940]\n",
      "loss: 0.469805  [ 9632/56940]\n",
      "loss: 0.266718  [12832/56940]\n",
      "loss: 0.295277  [16032/56940]\n",
      "loss: 0.217721  [19232/56940]\n",
      "loss: 0.489174  [22432/56940]\n",
      "loss: 0.372692  [25632/56940]\n",
      "loss: 0.363716  [28832/56940]\n",
      "loss: 0.160021  [32032/56940]\n",
      "loss: 0.082293  [35232/56940]\n",
      "loss: 0.285940  [38432/56940]\n",
      "loss: 0.266848  [41632/56940]\n",
      "loss: 0.381132  [44832/56940]\n",
      "loss: 0.260564  [48032/56940]\n",
      "loss: 0.439723  [51232/56940]\n",
      "loss: 0.152489  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.209835 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.284008  [   32/56940]\n",
      "loss: 0.182213  [ 3232/56940]\n",
      "loss: 0.207552  [ 6432/56940]\n",
      "loss: 0.318269  [ 9632/56940]\n",
      "loss: 0.301681  [12832/56940]\n",
      "loss: 0.331189  [16032/56940]\n",
      "loss: 0.394971  [19232/56940]\n",
      "loss: 0.456300  [22432/56940]\n",
      "loss: 0.332649  [25632/56940]\n",
      "loss: 0.363309  [28832/56940]\n",
      "loss: 0.259203  [32032/56940]\n",
      "loss: 0.173269  [35232/56940]\n",
      "loss: 0.083997  [38432/56940]\n",
      "loss: 0.198359  [41632/56940]\n",
      "loss: 0.196565  [44832/56940]\n",
      "loss: 0.284719  [48032/56940]\n",
      "loss: 0.328570  [51232/56940]\n",
      "loss: 0.505199  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.202152 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.169781  [   32/56940]\n",
      "loss: 0.182827  [ 3232/56940]\n",
      "loss: 0.458330  [ 6432/56940]\n",
      "loss: 0.279782  [ 9632/56940]\n",
      "loss: 0.196448  [12832/56940]\n",
      "loss: 0.216073  [16032/56940]\n",
      "loss: 0.166269  [19232/56940]\n",
      "loss: 0.177394  [22432/56940]\n",
      "loss: 0.136449  [25632/56940]\n",
      "loss: 0.200372  [28832/56940]\n",
      "loss: 0.247939  [32032/56940]\n",
      "loss: 0.203542  [35232/56940]\n",
      "loss: 0.405524  [38432/56940]\n",
      "loss: 0.129005  [41632/56940]\n",
      "loss: 0.407077  [44832/56940]\n",
      "loss: 0.229234  [48032/56940]\n",
      "loss: 0.294622  [51232/56940]\n",
      "loss: 0.138206  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.197307 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.133723  [   32/56940]\n",
      "loss: 0.114737  [ 3232/56940]\n",
      "loss: 0.220206  [ 6432/56940]\n",
      "loss: 0.220542  [ 9632/56940]\n",
      "loss: 0.312610  [12832/56940]\n",
      "loss: 0.253270  [16032/56940]\n",
      "loss: 0.368118  [19232/56940]\n",
      "loss: 0.338387  [22432/56940]\n",
      "loss: 0.124061  [25632/56940]\n",
      "loss: 0.191444  [28832/56940]\n",
      "loss: 0.192025  [32032/56940]\n",
      "loss: 0.183148  [35232/56940]\n",
      "loss: 0.265912  [38432/56940]\n",
      "loss: 0.180163  [41632/56940]\n",
      "loss: 0.391939  [44832/56940]\n",
      "loss: 0.066510  [48032/56940]\n",
      "loss: 0.150686  [51232/56940]\n",
      "loss: 0.252208  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.200254 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.294527  [   32/56940]\n",
      "loss: 0.169707  [ 3232/56940]\n",
      "loss: 0.224956  [ 6432/56940]\n",
      "loss: 0.166451  [ 9632/56940]\n",
      "loss: 0.258697  [12832/56940]\n",
      "loss: 0.138753  [16032/56940]\n",
      "loss: 0.128709  [19232/56940]\n",
      "loss: 0.340250  [22432/56940]\n",
      "loss: 0.173609  [25632/56940]\n",
      "loss: 0.139570  [28832/56940]\n",
      "loss: 0.107002  [32032/56940]\n",
      "loss: 0.218005  [35232/56940]\n",
      "loss: 0.139017  [38432/56940]\n",
      "loss: 0.237733  [41632/56940]\n",
      "loss: 0.225210  [44832/56940]\n",
      "loss: 0.166314  [48032/56940]\n",
      "loss: 0.317457  [51232/56940]\n",
      "loss: 0.068903  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.213487 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.155831  [   32/56940]\n",
      "loss: 0.361868  [ 3232/56940]\n",
      "loss: 0.642695  [ 6432/56940]\n",
      "loss: 0.333502  [ 9632/56940]\n",
      "loss: 0.431273  [12832/56940]\n",
      "loss: 0.124464  [16032/56940]\n",
      "loss: 0.219233  [19232/56940]\n",
      "loss: 0.248364  [22432/56940]\n",
      "loss: 0.230967  [25632/56940]\n",
      "loss: 0.609427  [28832/56940]\n",
      "loss: 0.162634  [32032/56940]\n",
      "loss: 0.352063  [35232/56940]\n",
      "loss: 0.195658  [38432/56940]\n",
      "loss: 0.410730  [41632/56940]\n",
      "loss: 0.286133  [44832/56940]\n",
      "loss: 0.077962  [48032/56940]\n",
      "loss: 0.338124  [51232/56940]\n",
      "loss: 0.213062  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.202758 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.237744  [   32/56940]\n",
      "loss: 0.399931  [ 3232/56940]\n",
      "loss: 0.223506  [ 6432/56940]\n",
      "loss: 0.156539  [ 9632/56940]\n",
      "loss: 0.132368  [12832/56940]\n",
      "loss: 0.218120  [16032/56940]\n",
      "loss: 0.104943  [19232/56940]\n",
      "loss: 0.282811  [22432/56940]\n",
      "loss: 0.278237  [25632/56940]\n",
      "loss: 0.301218  [28832/56940]\n",
      "loss: 0.174163  [32032/56940]\n",
      "loss: 0.316006  [35232/56940]\n",
      "loss: 0.481505  [38432/56940]\n",
      "loss: 0.434563  [41632/56940]\n",
      "loss: 0.173374  [44832/56940]\n",
      "loss: 0.236768  [48032/56940]\n",
      "loss: 0.296496  [51232/56940]\n",
      "loss: 0.251939  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.200027 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.196943  [   32/56940]\n",
      "loss: 0.243491  [ 3232/56940]\n",
      "loss: 0.318399  [ 6432/56940]\n",
      "loss: 0.141092  [ 9632/56940]\n",
      "loss: 0.141127  [12832/56940]\n",
      "loss: 0.229190  [16032/56940]\n",
      "loss: 0.247556  [19232/56940]\n",
      "loss: 0.370076  [22432/56940]\n",
      "loss: 0.113999  [25632/56940]\n",
      "loss: 0.278441  [28832/56940]\n",
      "loss: 0.174801  [32032/56940]\n",
      "loss: 0.352743  [35232/56940]\n",
      "loss: 0.191695  [38432/56940]\n",
      "loss: 0.370221  [41632/56940]\n",
      "loss: 0.183590  [44832/56940]\n",
      "loss: 0.176019  [48032/56940]\n",
      "loss: 0.223226  [51232/56940]\n",
      "loss: 0.157012  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.201636 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.087976  [   32/56940]\n",
      "loss: 0.262075  [ 3232/56940]\n",
      "loss: 0.162721  [ 6432/56940]\n",
      "loss: 0.144521  [ 9632/56940]\n",
      "loss: 0.218178  [12832/56940]\n",
      "loss: 0.206264  [16032/56940]\n",
      "loss: 0.176619  [19232/56940]\n",
      "loss: 0.216912  [22432/56940]\n",
      "loss: 0.185408  [25632/56940]\n",
      "loss: 0.287614  [28832/56940]\n",
      "loss: 0.286644  [32032/56940]\n",
      "loss: 0.348065  [35232/56940]\n",
      "loss: 0.398110  [38432/56940]\n",
      "loss: 0.247111  [41632/56940]\n",
      "loss: 0.249280  [44832/56940]\n",
      "loss: 0.370352  [48032/56940]\n",
      "loss: 0.092270  [51232/56940]\n",
      "loss: 0.250383  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.212469 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.138128  [   32/56940]\n",
      "loss: 0.286279  [ 3232/56940]\n",
      "loss: 0.147946  [ 6432/56940]\n",
      "loss: 0.224416  [ 9632/56940]\n",
      "loss: 0.078060  [12832/56940]\n",
      "loss: 0.328642  [16032/56940]\n",
      "loss: 0.481759  [19232/56940]\n",
      "loss: 0.358955  [22432/56940]\n",
      "loss: 0.290707  [25632/56940]\n",
      "loss: 0.095398  [28832/56940]\n",
      "loss: 0.363030  [32032/56940]\n",
      "loss: 0.358764  [35232/56940]\n",
      "loss: 0.226964  [38432/56940]\n",
      "loss: 0.199152  [41632/56940]\n",
      "loss: 0.383057  [44832/56940]\n",
      "loss: 0.155513  [48032/56940]\n",
      "loss: 0.241082  [51232/56940]\n",
      "loss: 0.135912  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.241493 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.338119  [   32/56940]\n",
      "loss: 0.280853  [ 3232/56940]\n",
      "loss: 0.267569  [ 6432/56940]\n",
      "loss: 0.169613  [ 9632/56940]\n",
      "loss: 0.130037  [12832/56940]\n",
      "loss: 0.126096  [16032/56940]\n",
      "loss: 0.278850  [19232/56940]\n",
      "loss: 0.108858  [22432/56940]\n",
      "loss: 0.326952  [25632/56940]\n",
      "loss: 0.281559  [28832/56940]\n",
      "loss: 0.096678  [32032/56940]\n",
      "loss: 0.277235  [35232/56940]\n",
      "loss: 0.266070  [38432/56940]\n",
      "loss: 0.197527  [41632/56940]\n",
      "loss: 0.389790  [44832/56940]\n",
      "loss: 0.243873  [48032/56940]\n",
      "loss: 0.197415  [51232/56940]\n",
      "loss: 0.246774  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.217405 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.181284  [   32/56940]\n",
      "loss: 0.106269  [ 3232/56940]\n",
      "loss: 0.202243  [ 6432/56940]\n",
      "loss: 0.291984  [ 9632/56940]\n",
      "loss: 0.283764  [12832/56940]\n",
      "loss: 0.300985  [16032/56940]\n",
      "loss: 0.214252  [19232/56940]\n",
      "loss: 0.295999  [22432/56940]\n",
      "loss: 0.430242  [25632/56940]\n",
      "loss: 0.154525  [28832/56940]\n",
      "loss: 0.298753  [32032/56940]\n",
      "loss: 0.243821  [35232/56940]\n",
      "loss: 0.220854  [38432/56940]\n",
      "loss: 0.270961  [41632/56940]\n",
      "loss: 0.178022  [44832/56940]\n",
      "loss: 0.237127  [48032/56940]\n",
      "loss: 0.467970  [51232/56940]\n",
      "loss: 0.114034  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.203920 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.218484  [   32/56940]\n",
      "loss: 0.103077  [ 3232/56940]\n",
      "loss: 0.388641  [ 6432/56940]\n",
      "loss: 0.254390  [ 9632/56940]\n",
      "loss: 0.175178  [12832/56940]\n",
      "loss: 0.203416  [16032/56940]\n",
      "loss: 0.169236  [19232/56940]\n",
      "loss: 0.279226  [22432/56940]\n",
      "loss: 0.469732  [25632/56940]\n",
      "loss: 0.239011  [28832/56940]\n",
      "loss: 0.171921  [32032/56940]\n",
      "loss: 0.371858  [35232/56940]\n",
      "loss: 0.302035  [38432/56940]\n",
      "loss: 0.211190  [41632/56940]\n",
      "loss: 0.214656  [44832/56940]\n",
      "loss: 0.184341  [48032/56940]\n",
      "loss: 0.312730  [51232/56940]\n",
      "loss: 0.463599  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.202206 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.183521  [   32/56940]\n",
      "loss: 0.238537  [ 3232/56940]\n",
      "loss: 0.128960  [ 6432/56940]\n",
      "loss: 0.354633  [ 9632/56940]\n",
      "loss: 0.218788  [12832/56940]\n",
      "loss: 0.213568  [16032/56940]\n",
      "loss: 0.210000  [19232/56940]\n",
      "loss: 0.305300  [22432/56940]\n",
      "loss: 0.178530  [25632/56940]\n",
      "loss: 0.428439  [28832/56940]\n",
      "loss: 0.193227  [32032/56940]\n",
      "loss: 0.316941  [35232/56940]\n",
      "loss: 0.224294  [38432/56940]\n",
      "loss: 0.244843  [41632/56940]\n",
      "loss: 0.303625  [44832/56940]\n",
      "loss: 0.171753  [48032/56940]\n",
      "loss: 0.238486  [51232/56940]\n",
      "loss: 0.281461  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.217969 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.238048  [   32/56940]\n",
      "loss: 0.219024  [ 3232/56940]\n",
      "loss: 0.138690  [ 6432/56940]\n",
      "loss: 0.218879  [ 9632/56940]\n",
      "loss: 0.255838  [12832/56940]\n",
      "loss: 0.111797  [16032/56940]\n",
      "loss: 0.123163  [19232/56940]\n",
      "loss: 0.180712  [22432/56940]\n",
      "loss: 0.113706  [25632/56940]\n",
      "loss: 0.350651  [28832/56940]\n",
      "loss: 0.269365  [32032/56940]\n",
      "loss: 0.788256  [35232/56940]\n",
      "loss: 0.253147  [38432/56940]\n",
      "loss: 0.431251  [41632/56940]\n",
      "loss: 0.436656  [44832/56940]\n",
      "loss: 0.196695  [48032/56940]\n",
      "loss: 0.469675  [51232/56940]\n",
      "loss: 0.141701  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.212066 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.314056  [   32/56940]\n",
      "loss: 0.313551  [ 3232/56940]\n",
      "loss: 0.109207  [ 6432/56940]\n",
      "loss: 0.304524  [ 9632/56940]\n",
      "loss: 0.245568  [12832/56940]\n",
      "loss: 0.273160  [16032/56940]\n",
      "loss: 0.216415  [19232/56940]\n",
      "loss: 0.615482  [22432/56940]\n",
      "loss: 0.261752  [25632/56940]\n",
      "loss: 0.289806  [28832/56940]\n",
      "loss: 0.494653  [32032/56940]\n",
      "loss: 0.247381  [35232/56940]\n",
      "loss: 0.160590  [38432/56940]\n",
      "loss: 0.116520  [41632/56940]\n",
      "loss: 0.315600  [44832/56940]\n",
      "loss: 0.269143  [48032/56940]\n",
      "loss: 0.403376  [51232/56940]\n",
      "loss: 0.159047  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.193968 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.312922  [   32/56940]\n",
      "loss: 0.225426  [ 3232/56940]\n",
      "loss: 0.150390  [ 6432/56940]\n",
      "loss: 0.322115  [ 9632/56940]\n",
      "loss: 0.324364  [12832/56940]\n",
      "loss: 0.201487  [16032/56940]\n",
      "loss: 0.279675  [19232/56940]\n",
      "loss: 0.263553  [22432/56940]\n",
      "loss: 0.272346  [25632/56940]\n",
      "loss: 0.587216  [28832/56940]\n",
      "loss: 0.175852  [32032/56940]\n",
      "loss: 0.192589  [35232/56940]\n",
      "loss: 0.209752  [38432/56940]\n",
      "loss: 0.301648  [41632/56940]\n",
      "loss: 0.260151  [44832/56940]\n",
      "loss: 0.257737  [48032/56940]\n",
      "loss: 0.440147  [51232/56940]\n",
      "loss: 0.271050  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.208088 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.187557  [   32/56940]\n",
      "loss: 0.132022  [ 3232/56940]\n",
      "loss: 0.238669  [ 6432/56940]\n",
      "loss: 0.297030  [ 9632/56940]\n",
      "loss: 0.217002  [12832/56940]\n",
      "loss: 0.299355  [16032/56940]\n",
      "loss: 0.192065  [19232/56940]\n",
      "loss: 0.205475  [22432/56940]\n",
      "loss: 0.201871  [25632/56940]\n",
      "loss: 0.159931  [28832/56940]\n",
      "loss: 0.338568  [32032/56940]\n",
      "loss: 0.215243  [35232/56940]\n",
      "loss: 0.252113  [38432/56940]\n",
      "loss: 0.165312  [41632/56940]\n",
      "loss: 0.354929  [44832/56940]\n",
      "loss: 0.178623  [48032/56940]\n",
      "loss: 0.265950  [51232/56940]\n",
      "loss: 0.388366  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.217148 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.193511  [   32/56940]\n",
      "loss: 0.119709  [ 3232/56940]\n",
      "loss: 0.323914  [ 6432/56940]\n",
      "loss: 0.174352  [ 9632/56940]\n",
      "loss: 0.291067  [12832/56940]\n",
      "loss: 0.343405  [16032/56940]\n",
      "loss: 0.119658  [19232/56940]\n",
      "loss: 0.242165  [22432/56940]\n",
      "loss: 0.436711  [25632/56940]\n",
      "loss: 0.254557  [28832/56940]\n",
      "loss: 0.169499  [32032/56940]\n",
      "loss: 0.432658  [35232/56940]\n",
      "loss: 0.200658  [38432/56940]\n",
      "loss: 0.215711  [41632/56940]\n",
      "loss: 0.177561  [44832/56940]\n",
      "loss: 0.193480  [48032/56940]\n",
      "loss: 0.182840  [51232/56940]\n",
      "loss: 0.244083  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.211635 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.200586  [   32/56940]\n",
      "loss: 0.219298  [ 3232/56940]\n",
      "loss: 0.172524  [ 6432/56940]\n",
      "loss: 0.302549  [ 9632/56940]\n",
      "loss: 0.399668  [12832/56940]\n",
      "loss: 0.205190  [16032/56940]\n",
      "loss: 0.297271  [19232/56940]\n",
      "loss: 0.214521  [22432/56940]\n",
      "loss: 0.310325  [25632/56940]\n",
      "loss: 0.196583  [28832/56940]\n",
      "loss: 0.164208  [32032/56940]\n",
      "loss: 0.298021  [35232/56940]\n",
      "loss: 0.128658  [38432/56940]\n",
      "loss: 0.284837  [41632/56940]\n",
      "loss: 0.175179  [44832/56940]\n",
      "loss: 0.396539  [48032/56940]\n",
      "loss: 0.273277  [51232/56940]\n",
      "loss: 0.213530  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.202103 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.147391  [   32/56940]\n",
      "loss: 0.147281  [ 3232/56940]\n",
      "loss: 0.080864  [ 6432/56940]\n",
      "loss: 0.210649  [ 9632/56940]\n",
      "loss: 0.303243  [12832/56940]\n",
      "loss: 0.286799  [16032/56940]\n",
      "loss: 0.305743  [19232/56940]\n",
      "loss: 0.346175  [22432/56940]\n",
      "loss: 0.125580  [25632/56940]\n",
      "loss: 0.195907  [28832/56940]\n",
      "loss: 0.342526  [32032/56940]\n",
      "loss: 0.252885  [35232/56940]\n",
      "loss: 0.392543  [38432/56940]\n",
      "loss: 0.184466  [41632/56940]\n",
      "loss: 0.301274  [44832/56940]\n",
      "loss: 0.183768  [48032/56940]\n",
      "loss: 0.195300  [51232/56940]\n",
      "loss: 0.302891  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.197994 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.207046  [   32/56940]\n",
      "loss: 0.295327  [ 3232/56940]\n",
      "loss: 0.210340  [ 6432/56940]\n",
      "loss: 0.253411  [ 9632/56940]\n",
      "loss: 0.135295  [12832/56940]\n",
      "loss: 0.284994  [16032/56940]\n",
      "loss: 0.148684  [19232/56940]\n",
      "loss: 0.355888  [22432/56940]\n",
      "loss: 0.362150  [25632/56940]\n",
      "loss: 0.331342  [28832/56940]\n",
      "loss: 0.151476  [32032/56940]\n",
      "loss: 0.425838  [35232/56940]\n",
      "loss: 0.465837  [38432/56940]\n",
      "loss: 0.133852  [41632/56940]\n",
      "loss: 0.247628  [44832/56940]\n",
      "loss: 0.293321  [48032/56940]\n",
      "loss: 0.137090  [51232/56940]\n",
      "loss: 0.201164  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.225882 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.192347  [   32/56940]\n",
      "loss: 0.532392  [ 3232/56940]\n",
      "loss: 0.202340  [ 6432/56940]\n",
      "loss: 0.206765  [ 9632/56940]\n",
      "loss: 0.117926  [12832/56940]\n",
      "loss: 0.180689  [16032/56940]\n",
      "loss: 0.350669  [19232/56940]\n",
      "loss: 0.269500  [22432/56940]\n",
      "loss: 0.187402  [25632/56940]\n",
      "loss: 0.163142  [28832/56940]\n",
      "loss: 0.144664  [32032/56940]\n",
      "loss: 0.211193  [35232/56940]\n",
      "loss: 0.398789  [38432/56940]\n",
      "loss: 0.201920  [41632/56940]\n",
      "loss: 0.401689  [44832/56940]\n",
      "loss: 0.246133  [48032/56940]\n",
      "loss: 0.307572  [51232/56940]\n",
      "loss: 0.082195  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.212527 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.305581  [   32/56940]\n",
      "loss: 0.460948  [ 3232/56940]\n",
      "loss: 0.157535  [ 6432/56940]\n",
      "loss: 0.204004  [ 9632/56940]\n",
      "loss: 0.164499  [12832/56940]\n",
      "loss: 0.194878  [16032/56940]\n",
      "loss: 0.109864  [19232/56940]\n",
      "loss: 0.115460  [22432/56940]\n",
      "loss: 0.199556  [25632/56940]\n",
      "loss: 0.236961  [28832/56940]\n",
      "loss: 0.229490  [32032/56940]\n",
      "loss: 0.446184  [35232/56940]\n",
      "loss: 0.307272  [38432/56940]\n",
      "loss: 0.328542  [41632/56940]\n",
      "loss: 0.461162  [44832/56940]\n",
      "loss: 0.309461  [48032/56940]\n",
      "loss: 0.334761  [51232/56940]\n",
      "loss: 0.362907  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.224582 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.378143  [   32/56940]\n",
      "loss: 0.268463  [ 3232/56940]\n",
      "loss: 0.469587  [ 6432/56940]\n",
      "loss: 0.434443  [ 9632/56940]\n",
      "loss: 0.198979  [12832/56940]\n",
      "loss: 0.181072  [16032/56940]\n",
      "loss: 0.167777  [19232/56940]\n",
      "loss: 0.234244  [22432/56940]\n",
      "loss: 0.147561  [25632/56940]\n",
      "loss: 0.244052  [28832/56940]\n",
      "loss: 0.456586  [32032/56940]\n",
      "loss: 0.245456  [35232/56940]\n",
      "loss: 0.320507  [38432/56940]\n",
      "loss: 0.191901  [41632/56940]\n",
      "loss: 0.365305  [44832/56940]\n",
      "loss: 0.406946  [48032/56940]\n",
      "loss: 0.397471  [51232/56940]\n",
      "loss: 0.173260  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.240287 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.181545  [   32/56940]\n",
      "loss: 0.216088  [ 3232/56940]\n",
      "loss: 0.227623  [ 6432/56940]\n",
      "loss: 0.198781  [ 9632/56940]\n",
      "loss: 0.207074  [12832/56940]\n",
      "loss: 0.396389  [16032/56940]\n",
      "loss: 0.138539  [19232/56940]\n",
      "loss: 0.364619  [22432/56940]\n",
      "loss: 0.143872  [25632/56940]\n",
      "loss: 0.235800  [28832/56940]\n",
      "loss: 0.323137  [32032/56940]\n",
      "loss: 0.128978  [35232/56940]\n",
      "loss: 0.258593  [38432/56940]\n",
      "loss: 0.213636  [41632/56940]\n",
      "loss: 0.231421  [44832/56940]\n",
      "loss: 0.235856  [48032/56940]\n",
      "loss: 0.180528  [51232/56940]\n",
      "loss: 0.296891  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.205974 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.136373  [   32/56940]\n",
      "loss: 0.266305  [ 3232/56940]\n",
      "loss: 0.207287  [ 6432/56940]\n",
      "loss: 0.339951  [ 9632/56940]\n",
      "loss: 0.137850  [12832/56940]\n",
      "loss: 0.288208  [16032/56940]\n",
      "loss: 0.209448  [19232/56940]\n",
      "loss: 0.113726  [22432/56940]\n",
      "loss: 0.430546  [25632/56940]\n",
      "loss: 0.323508  [28832/56940]\n",
      "loss: 0.147018  [32032/56940]\n",
      "loss: 0.403366  [35232/56940]\n",
      "loss: 0.211734  [38432/56940]\n",
      "loss: 0.133609  [41632/56940]\n",
      "loss: 0.321971  [44832/56940]\n",
      "loss: 0.124630  [48032/56940]\n",
      "loss: 0.651863  [51232/56940]\n",
      "loss: 0.207137  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.197692 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.399788  [   32/56940]\n",
      "loss: 0.116704  [ 3232/56940]\n",
      "loss: 0.237282  [ 6432/56940]\n",
      "loss: 0.253959  [ 9632/56940]\n",
      "loss: 0.227431  [12832/56940]\n",
      "loss: 0.265801  [16032/56940]\n",
      "loss: 0.226094  [19232/56940]\n",
      "loss: 0.270927  [22432/56940]\n",
      "loss: 0.216570  [25632/56940]\n",
      "loss: 0.291855  [28832/56940]\n",
      "loss: 0.143675  [32032/56940]\n",
      "loss: 0.418391  [35232/56940]\n",
      "loss: 0.124335  [38432/56940]\n",
      "loss: 0.229672  [41632/56940]\n",
      "loss: 0.137706  [44832/56940]\n",
      "loss: 0.212615  [48032/56940]\n",
      "loss: 0.262096  [51232/56940]\n",
      "loss: 0.243194  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.220401 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.213500  [   32/56940]\n",
      "loss: 0.243230  [ 3232/56940]\n",
      "loss: 0.157699  [ 6432/56940]\n",
      "loss: 0.194258  [ 9632/56940]\n",
      "loss: 0.081664  [12832/56940]\n",
      "loss: 0.328457  [16032/56940]\n",
      "loss: 0.146546  [19232/56940]\n",
      "loss: 0.165473  [22432/56940]\n",
      "loss: 0.174559  [25632/56940]\n",
      "loss: 0.194285  [28832/56940]\n",
      "loss: 0.186090  [32032/56940]\n",
      "loss: 0.195948  [35232/56940]\n",
      "loss: 0.428951  [38432/56940]\n",
      "loss: 0.259788  [41632/56940]\n",
      "loss: 0.239255  [44832/56940]\n",
      "loss: 0.204366  [48032/56940]\n",
      "loss: 0.248226  [51232/56940]\n",
      "loss: 0.271549  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.200239 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.154063  [   32/56940]\n",
      "loss: 0.092281  [ 3232/56940]\n",
      "loss: 0.371417  [ 6432/56940]\n",
      "loss: 0.122223  [ 9632/56940]\n",
      "loss: 0.203590  [12832/56940]\n",
      "loss: 0.229488  [16032/56940]\n",
      "loss: 0.200660  [19232/56940]\n",
      "loss: 0.169296  [22432/56940]\n",
      "loss: 0.222216  [25632/56940]\n",
      "loss: 0.252714  [28832/56940]\n",
      "loss: 0.271327  [32032/56940]\n",
      "loss: 0.178281  [35232/56940]\n",
      "loss: 0.250979  [38432/56940]\n",
      "loss: 0.188129  [41632/56940]\n",
      "loss: 0.204274  [44832/56940]\n",
      "loss: 0.205282  [48032/56940]\n",
      "loss: 0.235903  [51232/56940]\n",
      "loss: 0.177954  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.201762 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.123984  [   32/56940]\n",
      "loss: 0.189770  [ 3232/56940]\n",
      "loss: 0.232895  [ 6432/56940]\n",
      "loss: 0.096553  [ 9632/56940]\n",
      "loss: 0.248291  [12832/56940]\n",
      "loss: 0.173228  [16032/56940]\n",
      "loss: 0.231079  [19232/56940]\n",
      "loss: 0.367246  [22432/56940]\n",
      "loss: 0.149568  [25632/56940]\n",
      "loss: 0.235194  [28832/56940]\n",
      "loss: 0.334375  [32032/56940]\n",
      "loss: 0.371389  [35232/56940]\n",
      "loss: 0.195353  [38432/56940]\n",
      "loss: 0.354011  [41632/56940]\n",
      "loss: 0.184080  [44832/56940]\n",
      "loss: 0.174719  [48032/56940]\n",
      "loss: 0.155546  [51232/56940]\n",
      "loss: 0.240257  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.199409 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.325221  [   32/56940]\n",
      "loss: 0.581769  [ 3232/56940]\n",
      "loss: 0.150430  [ 6432/56940]\n",
      "loss: 0.163021  [ 9632/56940]\n",
      "loss: 0.241895  [12832/56940]\n",
      "loss: 0.130500  [16032/56940]\n",
      "loss: 0.259803  [19232/56940]\n",
      "loss: 0.155798  [22432/56940]\n",
      "loss: 0.431736  [25632/56940]\n",
      "loss: 0.273158  [28832/56940]\n",
      "loss: 0.160697  [32032/56940]\n",
      "loss: 0.256965  [35232/56940]\n",
      "loss: 0.262661  [38432/56940]\n",
      "loss: 0.278297  [41632/56940]\n",
      "loss: 0.185085  [44832/56940]\n",
      "loss: 0.158634  [48032/56940]\n",
      "loss: 0.294939  [51232/56940]\n",
      "loss: 0.188321  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.223335 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.158165  [   32/56940]\n",
      "loss: 0.140378  [ 3232/56940]\n",
      "loss: 0.205281  [ 6432/56940]\n",
      "loss: 0.143720  [ 9632/56940]\n",
      "loss: 0.366607  [12832/56940]\n",
      "loss: 0.354407  [16032/56940]\n",
      "loss: 0.103238  [19232/56940]\n",
      "loss: 0.225421  [22432/56940]\n",
      "loss: 0.277724  [25632/56940]\n",
      "loss: 0.233212  [28832/56940]\n",
      "loss: 0.229573  [32032/56940]\n",
      "loss: 0.172854  [35232/56940]\n",
      "loss: 0.359590  [38432/56940]\n",
      "loss: 0.156171  [41632/56940]\n",
      "loss: 0.199592  [44832/56940]\n",
      "loss: 0.219665  [48032/56940]\n",
      "loss: 0.161651  [51232/56940]\n",
      "loss: 0.309011  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.208683 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.358434  [   32/56940]\n",
      "loss: 0.244625  [ 3232/56940]\n",
      "loss: 0.261266  [ 6432/56940]\n",
      "loss: 0.266169  [ 9632/56940]\n",
      "loss: 0.155994  [12832/56940]\n",
      "loss: 0.354445  [16032/56940]\n",
      "loss: 0.215037  [19232/56940]\n",
      "loss: 0.123365  [22432/56940]\n",
      "loss: 0.063469  [25632/56940]\n",
      "loss: 0.248491  [28832/56940]\n",
      "loss: 0.205105  [32032/56940]\n",
      "loss: 0.311165  [35232/56940]\n",
      "loss: 0.150532  [38432/56940]\n",
      "loss: 0.373638  [41632/56940]\n",
      "loss: 0.188427  [44832/56940]\n",
      "loss: 0.207183  [48032/56940]\n",
      "loss: 0.237093  [51232/56940]\n",
      "loss: 0.276491  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.211389 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.300969  [   32/56940]\n",
      "loss: 0.420220  [ 3232/56940]\n",
      "loss: 0.125582  [ 6432/56940]\n",
      "loss: 0.251934  [ 9632/56940]\n",
      "loss: 0.168250  [12832/56940]\n",
      "loss: 0.322951  [16032/56940]\n",
      "loss: 0.190408  [19232/56940]\n",
      "loss: 0.309944  [22432/56940]\n",
      "loss: 0.281553  [25632/56940]\n",
      "loss: 0.200325  [28832/56940]\n",
      "loss: 0.801207  [32032/56940]\n",
      "loss: 0.365046  [35232/56940]\n",
      "loss: 0.192598  [38432/56940]\n",
      "loss: 0.179506  [41632/56940]\n",
      "loss: 0.116439  [44832/56940]\n",
      "loss: 0.170052  [48032/56940]\n",
      "loss: 0.393194  [51232/56940]\n",
      "loss: 0.330800  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.202182 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.174161  [   32/56940]\n",
      "loss: 0.209631  [ 3232/56940]\n",
      "loss: 0.264673  [ 6432/56940]\n",
      "loss: 0.438548  [ 9632/56940]\n",
      "loss: 0.261533  [12832/56940]\n",
      "loss: 0.104246  [16032/56940]\n",
      "loss: 0.206777  [19232/56940]\n",
      "loss: 0.436959  [22432/56940]\n",
      "loss: 0.201741  [25632/56940]\n",
      "loss: 0.254443  [28832/56940]\n",
      "loss: 0.101535  [32032/56940]\n",
      "loss: 0.232859  [35232/56940]\n",
      "loss: 0.326110  [38432/56940]\n",
      "loss: 0.274193  [41632/56940]\n",
      "loss: 0.079484  [44832/56940]\n",
      "loss: 0.424296  [48032/56940]\n",
      "loss: 0.178154  [51232/56940]\n",
      "loss: 0.178957  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.194853 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.111876  [   32/56940]\n",
      "loss: 0.251028  [ 3232/56940]\n",
      "loss: 0.151746  [ 6432/56940]\n",
      "loss: 0.450084  [ 9632/56940]\n",
      "loss: 0.253863  [12832/56940]\n",
      "loss: 0.177054  [16032/56940]\n",
      "loss: 0.205276  [19232/56940]\n",
      "loss: 0.069176  [22432/56940]\n",
      "loss: 0.250002  [25632/56940]\n",
      "loss: 0.153424  [28832/56940]\n",
      "loss: 0.520501  [32032/56940]\n",
      "loss: 0.417286  [35232/56940]\n",
      "loss: 0.498218  [38432/56940]\n",
      "loss: 0.189269  [41632/56940]\n",
      "loss: 0.100286  [44832/56940]\n",
      "loss: 0.268276  [48032/56940]\n",
      "loss: 0.109827  [51232/56940]\n",
      "loss: 0.147721  [54432/56940]\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.197631 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model, train_losses, val_losses = train_early_stopping(\n",
    "    train_loader, val_loader, model, loss_fn, optimizer, epochs=500, early_stopping=True,\n",
    "    threshold=0.2,\n",
    "    counter=True, clipping=True)\n",
    "\n",
    "# plot training and validation losses\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(val_losses, label='val')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'models/display-box-18-rolling-means-half-noise-binary.mdl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/gwjrml9d76v_zwbyb2x6yc0r0000gn/T/ipykernel_20880/2522857457.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_save_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 958,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CounterCNN().to(device)\n",
    "model.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.200771 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.20077107420212098, 0.9066385669125395)"
      ]
     },
     "execution_count": 959,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out of sample test\n",
    "model.eval()\n",
    "# test(test_loader, model, loss_fn)\n",
    "test_counter(test_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0, Actual label: tensor([1.])\n",
      "Predicted class: 0, Actual label: tensor([1.])\n",
      "Predicted class: 0, Actual label: tensor([1.])\n",
      "Predicted class: 0, Actual label: tensor([1.])\n",
      "Predicted class: 0, Actual label: tensor([0.])\n",
      "Predicted class: 0, Actual label: tensor([1.])\n",
      "Predicted class: 0, Actual label: tensor([1.])\n",
      "Predicted class: 0, Actual label: tensor([1.])\n",
      "Predicted class: 0, Actual label: tensor([0.])\n",
      "Predicted class: 0, Actual label: tensor([1.])\n",
      "Predicted class: 0, Actual label: tensor([1.])\n",
      "Predicted class: 0, Actual label: tensor([1.])\n",
      "Predicted class: 0, Actual label: tensor([1.])\n",
      "Predicted class: 0, Actual label: tensor([1.])\n",
      "Predicted class: 0, Actual label: tensor([0.])\n",
      "Predicted class: 0, Actual label: tensor([0.])\n",
      "Predicted class: 0, Actual label: tensor([0.])\n",
      "Predicted class: 0, Actual label: tensor([1.])\n",
      "Predicted class: 0, Actual label: tensor([1.])\n",
      "Predicted class: 0, Actual label: tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    # Get a single example from the test dataset\n",
    "    example_data, example_label = test_dataset[i]\n",
    "\n",
    "    # Move the example data to the appropriate device\n",
    "    example_data = example_data.unsqueeze(0).to(device)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Get the model's prediction\n",
    "    with torch.no_grad():\n",
    "        example_data = example_data.to(device)\n",
    "        output = model(example_data)\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class = output.argmax(dim=1).item()\n",
    "\n",
    "    # Print the predicted class and the actual label\n",
    "    print(f'Predicted class: {predicted_class}, Actual label: {example_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store predictions\n",
    "predictions = []\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    for X, _ in test_loader:\n",
    "        X = X.to(device)\n",
    "        output = model(X)\n",
    "        # predicted_classes = output.argmax(dim=1)\n",
    "        # predictions.extend(predicted_classes.cpu().numpy())\n",
    "        predicted_zones = torch.round(torch.clamp(output, min=0, max=1))\n",
    "        predictions.extend(predicted_zones.cpu().numpy())\n",
    "\n",
    "# Convert predictions to a numpy array\n",
    "y_preds = np.array(predictions)\n",
    "print(y_preds)\n",
    "\n",
    "y_test = np.array([y for _, y in test_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# FULL DATASET\n",
    "# Create a DataLoader for the entire dataset\n",
    "full_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store the predictions\n",
    "predictions = []\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    for X, _ in full_loader:\n",
    "        X = X.to(device)\n",
    "        output = model(X)\n",
    "        predicted_classes = output.argmax(dim=1)\n",
    "        predictions.extend(predicted_classes.cpu().numpy())\n",
    "\n",
    "# Convert outputs to a numpy array\n",
    "y_preds = np.array(predictions)\n",
    "print(y_preds)\n",
    "\n",
    "y_test = np.array([y for _, y in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test = np.array([y[0] for _, y in test_dataset]).astype(int)\n",
    "y_preds = np.array([p[0] for p in predictions]).astype(int)\n",
    "conf_matrix = confusion_matrix(y_test, y_preds)\n",
    "conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Change figure size and increase dpi for better resolution\n",
    "plt.figure(figsize=(8,6), dpi=100)\n",
    "# Scale up the size of all text\n",
    " \n",
    "# Plot Confusion Matrix using Seaborn heatmap()\n",
    "# Parameters:\n",
    "# first param - confusion matrix in array format   \n",
    "# annot = True: show the numbers in each heatmap cell\n",
    "# fmt = 'd': show numbers as integers. \n",
    "ax = sns.heatmap(conf_matrix_normalized, annot=True, fmt='.2f', )\n",
    " \n",
    "# set x-axis label and ticks. \n",
    "ax.set_xlabel(\"Predicted\", fontsize=14, labelpad=20)\n",
    "# tick_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
    "# tick_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "# tick_labels = [0, 1, 2, 3, 4, 5, 6]\n",
    "# tick_labels = [0, 1, 2]\n",
    "tick_labels = [0, 1]\n",
    "ax.xaxis.set_ticklabels(tick_labels)\n",
    " \n",
    "# set y-axis label and ticks\n",
    "ax.set_ylabel(\"Actual\", fontsize=14, labelpad=20)\n",
    "ax.yaxis.set_ticklabels(tick_labels)\n",
    " \n",
    "# set plot title\n",
    "ax.set_title(\"Confusion Matrix\", fontsize=14, pad=20)\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
